{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Intermediate Bash/Linux \u00b6 Course on intermediate Bash/Linux, with an estimated duration of 6 hours , given in two half-days. This course is given under NAISS , by staff working at the branches located at UPPMAX and HPC2N . In this 6-hour, 2-day ONLINE workshop you will learn how to work smarter from a command line. You can follow either day or both. Doing so, you will learn more Bash commands, scripting and some quality of life topics. NOTE: You can run on your own (Linux) computer or on your favorite HPC cluster (that you already have access to). At the end of each day, you should feel able to work smarter and able to avoid more grunt work (i.e. anything that involves repeated copypaste). Intended participants: The workshop is intended for users with some Linux experience, see the prerequisites. Eligibility: the NAISS course is open to current and future users in Swedish academia. Participation is free. Remote/online participation: The course will be completely online and we will use Zoom. The participants will use their own computer or a computer system they have access to. What are the learning outcomes ? See the learning outcomes of this course . The lectures will be recorded and uploaded to HPC2N\u2019s YouTube channel. You can find an overview at the course videos .","title":"Home"},{"location":"#intermediate__bashlinux","text":"Course on intermediate Bash/Linux, with an estimated duration of 6 hours , given in two half-days. This course is given under NAISS , by staff working at the branches located at UPPMAX and HPC2N . In this 6-hour, 2-day ONLINE workshop you will learn how to work smarter from a command line. You can follow either day or both. Doing so, you will learn more Bash commands, scripting and some quality of life topics. NOTE: You can run on your own (Linux) computer or on your favorite HPC cluster (that you already have access to). At the end of each day, you should feel able to work smarter and able to avoid more grunt work (i.e. anything that involves repeated copypaste). Intended participants: The workshop is intended for users with some Linux experience, see the prerequisites. Eligibility: the NAISS course is open to current and future users in Swedish academia. Participation is free. Remote/online participation: The course will be completely online and we will use Zoom. The participants will use their own computer or a computer system they have access to. What are the learning outcomes ? See the learning outcomes of this course . The lectures will be recorded and uploaded to HPC2N\u2019s YouTube channel. You can find an overview at the course videos .","title":"Intermediate Bash/Linux"},{"location":"course_dates/","text":"Course dates \u00b6 Where is the schedule? It is at Schedule :-) Week Date Time Registration closes 49 2025-12-04 and 2025-12-05 9:00-12:00 TBA ?23 Around 2026-06-02 and 2026-06-03 9:00-12:00 TBA ?49 Around 2026-12-04 and 2026-12-05 9:00-12:00 TBA","title":"Course dates"},{"location":"course_dates/#course__dates","text":"Where is the schedule? It is at Schedule :-) Week Date Time Registration closes 49 2025-12-04 and 2025-12-05 9:00-12:00 TBA ?23 Around 2026-06-02 and 2026-06-03 9:00-12:00 TBA ?49 Around 2026-12-04 and 2026-12-05 9:00-12:00 TBA","title":"Course dates"},{"location":"courses/","text":"Courses \u00b6 Here is an overview of the courses mentioned in this course. Using the programming language AWK Course Description To AWK or not 2 day course, by Pavlin Mitev AWK course 1 day course, by Rich\u00e8l Bilderbeek","title":"Courses"},{"location":"courses/#courses","text":"Here is an overview of the courses mentioned in this course. Using the programming language AWK Course Description To AWK or not 2 day course, by Pavlin Mitev AWK course 1 day course, by Rich\u00e8l Bilderbeek","title":"Courses"},{"location":"evaluation/","text":"Evaluation \u00b6 This is the page for evaluating the current iteration of the course. Where can I find the results of earlier evaluations? At the \u2018Evaluations\u2019 page . [Link to evaluation survey]","title":"Evaluation"},{"location":"evaluation/#evaluation","text":"This is the page for evaluating the current iteration of the course. Where can I find the results of earlier evaluations? At the \u2018Evaluations\u2019 page . [Link to evaluation survey]","title":"Evaluation"},{"location":"learning_outcomes/","text":"Learning outcomes \u00b6 Day 1: smarter command line \u00b6 Linux pipe Learners can chain commands using the Linux pipe wc and cut Learners can use wc Learners can use cut Regular expressions and grep Learners know there are multiple flavours of regular expressions Learners can use . , * , + , ? , [] , [^] , {} , () in regular expressions Learners can use grep Learners have practiced using the grep manual Learners can use grep to search for a regular expression Learners can send text to grep using a pipe (optional) Learners have seen the flexibility of grep Using the programming language AWK Learners can use awk Learners have practiced using a book on AWK Learners can use awk in pipes Learners can use awk to read a specific column Learners can use awk to transform text Learners can use regular expressions in awk Day 2: smarter Bash \u00b6 Bash scripting Learners can write Bash scripts Learners have practiced using a book on Bash scripting Learners can write Bash scripts that require user input Learners can use variables in Bash scripts Learners can use if statements in Bash scripts Learners can use for statements in Bash scripts Environment variables Learners can create, read and write to environment variables Advanced redirect Learners can redirect output between the standard, error and log output streams Links (hard/soft) Learners can create soft and hard symbolic links Quality of life Learners can start a background process with & and terminate it Terminal shortcuts/usage Editing a .bashrc Using aliases Archiving/Compressing data Archiving/Compressing data|Learners can compress and extract data, using (g)zip and tar Regular expressions and sed Learners can use sed for pattern matched replacing","title":"Learning outcomes"},{"location":"learning_outcomes/#learning__outcomes","text":"","title":"Learning outcomes"},{"location":"learning_outcomes/#day__1__smarter__command__line","text":"Linux pipe Learners can chain commands using the Linux pipe wc and cut Learners can use wc Learners can use cut Regular expressions and grep Learners know there are multiple flavours of regular expressions Learners can use . , * , + , ? , [] , [^] , {} , () in regular expressions Learners can use grep Learners have practiced using the grep manual Learners can use grep to search for a regular expression Learners can send text to grep using a pipe (optional) Learners have seen the flexibility of grep Using the programming language AWK Learners can use awk Learners have practiced using a book on AWK Learners can use awk in pipes Learners can use awk to read a specific column Learners can use awk to transform text Learners can use regular expressions in awk","title":"Day 1: smarter command line"},{"location":"learning_outcomes/#day__2__smarter__bash","text":"Bash scripting Learners can write Bash scripts Learners have practiced using a book on Bash scripting Learners can write Bash scripts that require user input Learners can use variables in Bash scripts Learners can use if statements in Bash scripts Learners can use for statements in Bash scripts Environment variables Learners can create, read and write to environment variables Advanced redirect Learners can redirect output between the standard, error and log output streams Links (hard/soft) Learners can create soft and hard symbolic links Quality of life Learners can start a background process with & and terminate it Terminal shortcuts/usage Editing a .bashrc Using aliases Archiving/Compressing data Archiving/Compressing data|Learners can compress and extract data, using (g)zip and tar Regular expressions and sed Learners can use sed for pattern matched replacing","title":"Day 2: smarter Bash"},{"location":"prerequisites/","text":"Prerequisites \u00b6 We decided to use The Command Line 101 course content as course prerequisite. We assume you know that: Tab autocompletes commands man shows a manual cat shows text less and more show scrollable text nano is a text editor find is used for file and directory search. sort is used to print the output of a file in given order head is used to print the first lines of a file tail prints the lines at the end of a file echo displays lines of text or strings that are passed as arguments","title":"Prerequisites"},{"location":"prerequisites/#prerequisites","text":"We decided to use The Command Line 101 course content as course prerequisite. We assume you know that: Tab autocompletes commands man shows a manual cat shows text less and more show scrollable text nano is a text editor find is used for file and directory search. sort is used to print the output of a file in given order head is used to print the first lines of a file tail prints the lines at the end of a file echo displays lines of text or strings that are passed as arguments","title":"Prerequisites"},{"location":"schedule/","text":"Schedule \u00b6 What are the course dates? See the course dates . Morning 1: smarter command-line \u00b6 Time Topic Teacher 9:00-9:10 Introduction B 9:10-10:05 Linux pipe , wc , cut B 10:05-10:20 Break . 10:20-11:05 Regular expressions, grep R 11:05-11:20 Break . 11:20-12:00 sed and mention of AWK R Teachers: B : Birgitte Bryds\u00f6, R : Rich\u00e8l Bilderbeek Morning 2: smarter bash \u00b6 Time Topic Teacher 9:00-10:00 Bash scripting R 10:00-10:15 Break . 10:15-11:00 Advanced redirect, environment variables, links B 11:00-11:15 Break . 11:15-11:53 Quality of life, compressing, B 11:53-12:00 Evaluation R Teachers: B : Birgitte Bryds\u00f6, R : Rich\u00e8l Bilderbeek","title":"Schedule"},{"location":"schedule/#schedule","text":"What are the course dates? See the course dates .","title":"Schedule"},{"location":"schedule/#morning__1__smarter__command-line","text":"Time Topic Teacher 9:00-9:10 Introduction B 9:10-10:05 Linux pipe , wc , cut B 10:05-10:20 Break . 10:20-11:05 Regular expressions, grep R 11:05-11:20 Break . 11:20-12:00 sed and mention of AWK R Teachers: B : Birgitte Bryds\u00f6, R : Rich\u00e8l Bilderbeek","title":"Morning 1: smarter command-line"},{"location":"schedule/#morning__2__smarter__bash","text":"Time Topic Teacher 9:00-10:00 Bash scripting R 10:00-10:15 Break . 10:15-11:00 Advanced redirect, environment variables, links B 11:00-11:15 Break . 11:15-11:53 Quality of life, compressing, B 11:53-12:00 Evaluation R Teachers: B : Birgitte Bryds\u00f6, R : Rich\u00e8l Bilderbeek","title":"Morning 2: smarter bash"},{"location":"videos/","text":"Videos \u00b6 Here is an overview of the videos in this course. Day 1: smarter command line \u00b6 Introduction Introduction to the course Linux \u2018pipe\u2019 Linux pipe Linux tools (\u2018wc\u2019, \u2018cut\u2019) Linux tools \u2018wc\u2019 Linux tools \u2018cut\u2019 Regular expressions and grep Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Feedback Conclusion Using the programming language AWK Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Feedback Conclusion Day 2: smarter Bash \u00b6 Bash scripting Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Exercise 5 Exercise 6 Exercise 7 Exercise 8 Exercise 9 Feedback Conclusion Or a playlist for the course \u00b6 https://www.youtube.com/watch?v=oT9VlB1-FeU&list=PL6jMHLEmPVLzPdi1CsGWFQETAHykdbf7B","title":"Videos"},{"location":"videos/#videos","text":"Here is an overview of the videos in this course.","title":"Videos"},{"location":"videos/#day__1__smarter__command__line","text":"Introduction Introduction to the course Linux \u2018pipe\u2019 Linux pipe Linux tools (\u2018wc\u2019, \u2018cut\u2019) Linux tools \u2018wc\u2019 Linux tools \u2018cut\u2019 Regular expressions and grep Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Feedback Conclusion Using the programming language AWK Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Feedback Conclusion","title":"Day 1: smarter command line"},{"location":"videos/#day__2__smarter__bash","text":"Bash scripting Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Exercise 5 Exercise 6 Exercise 7 Exercise 8 Exercise 9 Feedback Conclusion","title":"Day 2: smarter Bash"},{"location":"videos/#or__a__playlist__for__the__course","text":"https://www.youtube.com/watch?v=oT9VlB1-FeU&list=PL6jMHLEmPVLzPdi1CsGWFQETAHykdbf7B","title":"Or a playlist for the course"},{"location":"books/","text":"Books \u00b6 A practical guide to learning awk Advanced Bash Scripting Guide Bash Beginners Guide Gawk: Effective AWK Programming The Linux Command Line","title":"Books"},{"location":"books/#books","text":"A practical guide to learning awk Advanced Bash Scripting Guide Bash Beginners Guide Gawk: Effective AWK Programming The Linux Command Line","title":"Books"},{"location":"communication/","text":"Communication \u00b6 The communication with others. Course information : sent around a week before the course starts Course evaluation : sent after the course has ended","title":"Communication"},{"location":"communication/#communication","text":"The communication with others. Course information : sent around a week before the course starts Course evaluation : sent after the course has ended","title":"Communication"},{"location":"communication/course_evaluation/","text":"Course evaluation email \u00b6 Title: Evaluation survey and recordings from the course \u201cCommand Line 201\u201d, [dates] Hello! Thank you for participating in the NAISS course \u201cCommand Line 201\u201d! We have an evaluation survey for the course, which we would very much like you to fill in, if you have not already. It will be very helpful for us in planning and designing future courses, as well as adjusting this course before giving it again. We will post the results of the evaluation some time after the survey closes. The link will be found on the GitHub page for the course. Note, that if you watch the recordings afterwards during the rest of the week, you are also very welcome to answer the evaluation since it tells us something about how well (or not) we communicated the various subjects. Link to the evaluation survey: [survey_url] The evaluation survey is open until [survey_closing_date_and_time] . The recordings from the course have been processed and uploaded to HPC2N\u2019s YouTube channel, on a separate playlist here: https://www.youtube.com/playlist?list=PL6jMHLEmPVLzPdi1CsGWFQETAHykdbf7B The presentations for the course will remain available for the foreseeable future at: https://uppmax.github.io/linux-command-line-201/ The GitHub page for the course, with the rest of the material, including the tarball with the exercises, will also remain for the foreseeable future at: https://github.com/UPPMAX/linux-command-line-201 Best wishes, [teacher_names]","title":"Course evaluation email"},{"location":"communication/course_evaluation/#course__evaluation__email","text":"Title: Evaluation survey and recordings from the course \u201cCommand Line 201\u201d, [dates] Hello! Thank you for participating in the NAISS course \u201cCommand Line 201\u201d! We have an evaluation survey for the course, which we would very much like you to fill in, if you have not already. It will be very helpful for us in planning and designing future courses, as well as adjusting this course before giving it again. We will post the results of the evaluation some time after the survey closes. The link will be found on the GitHub page for the course. Note, that if you watch the recordings afterwards during the rest of the week, you are also very welcome to answer the evaluation since it tells us something about how well (or not) we communicated the various subjects. Link to the evaluation survey: [survey_url] The evaluation survey is open until [survey_closing_date_and_time] . The recordings from the course have been processed and uploaded to HPC2N\u2019s YouTube channel, on a separate playlist here: https://www.youtube.com/playlist?list=PL6jMHLEmPVLzPdi1CsGWFQETAHykdbf7B The presentations for the course will remain available for the foreseeable future at: https://uppmax.github.io/linux-command-line-201/ The GitHub page for the course, with the rest of the material, including the tarball with the exercises, will also remain for the foreseeable future at: https://github.com/UPPMAX/linux-command-line-201 Best wishes, [teacher_names]","title":"Course evaluation email"},{"location":"communication/course_information/","text":"Course information email \u00b6 Title: Important info: Intermediate Bash and Linux, [dates] Hello! This email contains information for the NAISS course \u201cCommand Line 201\u201d, which will be given [days, dates] , 9:00-12:00 both day. NOTE that the course starts at 9:00 not 9:15! See the schedule linked below. We will use Zoom for this online course. See below for the link (#6). Schedule: https://uppmax.github.io/linux-command-line-201/schedule/ Rendered presentations for the course: https://uppmax.github.io/linux-command-line-201/ Course GH repo: https://github.com/UPPMAX/linux-command-line-201 Important information about the course is gathered here: [shared_document_url] Questions and answers page for the course: [shared_document_url] Zoom info for the course: a) There will be a Zoom for the lectures. b) When you join the Zoom meeting, use your REAL NAME. c) Please MUTE your microphone when you are not speaking and use the \u201cRaise hand\u201d functionality under the \u201cParticipants\u201d window during the lecture. Please do not clutter the Zoom chat. Behave politely! d) If you have questions during the lectures, you can write them on this page: [shared_document_url] e) There may be breakout rooms used in the Zoom for the hands-ons and for discussions. f) The lectures and demos will be recorded, but not the hands-ons sessions. If you ask questions during the lectures, you may thus be recorded. If you do not wish to be recorded, then please keep your microphone muted and your camera off and write your questions in the Q/A document. ZOOM: Zoom: [room_url] Meeting ID: [meeting_id] Passcode: [passcode]","title":"Course information email"},{"location":"communication/course_information/#course__information__email","text":"Title: Important info: Intermediate Bash and Linux, [dates] Hello! This email contains information for the NAISS course \u201cCommand Line 201\u201d, which will be given [days, dates] , 9:00-12:00 both day. NOTE that the course starts at 9:00 not 9:15! See the schedule linked below. We will use Zoom for this online course. See below for the link (#6). Schedule: https://uppmax.github.io/linux-command-line-201/schedule/ Rendered presentations for the course: https://uppmax.github.io/linux-command-line-201/ Course GH repo: https://github.com/UPPMAX/linux-command-line-201 Important information about the course is gathered here: [shared_document_url] Questions and answers page for the course: [shared_document_url] Zoom info for the course: a) There will be a Zoom for the lectures. b) When you join the Zoom meeting, use your REAL NAME. c) Please MUTE your microphone when you are not speaking and use the \u201cRaise hand\u201d functionality under the \u201cParticipants\u201d window during the lecture. Please do not clutter the Zoom chat. Behave politely! d) If you have questions during the lectures, you can write them on this page: [shared_document_url] e) There may be breakout rooms used in the Zoom for the hands-ons and for discussions. f) The lectures and demos will be recorded, but not the hands-ons sessions. If you ask questions during the lectures, you may thus be recorded. If you do not wish to be recorded, then please keep your microphone muted and your camera off and write your questions in the Q/A document. ZOOM: Zoom: [room_url] Meeting ID: [meeting_id] Passcode: [passcode]","title":"Course information email"},{"location":"evaluations/","text":"Evaluations \u00b6 Where can I evaluate this course? Go to evaluation (singular) :-) Here are the evaluation results of this course: No Dates Evaluations Success score 1 2025-06-02 and 2025-06-03 Evaluation 77% 2 2025-12-04 and 2025-12-05 Evaluation . The \u2018Success score\u2019 is the average confidence the learners have on each of the learning outcomes of the course","title":"Evaluations"},{"location":"evaluations/#evaluations","text":"Where can I evaluate this course? Go to evaluation (singular) :-) Here are the evaluation results of this course: No Dates Evaluations Success score 1 2025-06-02 and 2025-06-03 Evaluation 77% 2 2025-12-04 and 2025-12-05 Evaluation . The \u2018Success score\u2019 is the average confidence the learners have on each of the learning outcomes of the course","title":"Evaluations"},{"location":"evaluations/20250602/","text":"Evaluation 2025-06-02 and 2025-06-03 \u00b6 Date: 2025-06-02 and 2025-06-02 Number of registrations: 40 Number of learners on Day 1: Showing up: 15 (38% showing up) Being present most of the time: 11 (28% actively participating) Number of filled-in evaluations: 11 (100%) Analysis \u00b6 Evaluation results (csv) Evaluation results (xlsx) Analysis script Average confidence per question (.csv) Success score : 77% Pace \u00b6 good, perhaps slightly quick It is balanced. I was good I think is good but I did not code along as I saw that then I catch less information today intensive and less time to do exercise Good! just tight for the exercises The pace was good, quite high but for this type of intermediate course I think that is not a problem. I can go back to the things I found the most interesting or difficult later. A little quick, some extra time would help particularly for Birgittes section The pace was excellent Ok on Monday, a bit rushed towards the end on Tuesday Maybe it was a bit quick? I mean, it was easy to follow and understand, but then there was very little time to actually practice the exercises properly. I think it\u2019s normal given that the course was short! Future topics \u00b6 python? why we have so many languages? what do they add ? Different file systems, efficient editing of text files using Vim e.g. multiline find and replace, substitution etc. I don\u00b4t think anything else can be provided same but advance and longer automating processes and more into .bashrc Perhaps showing real examples of these tools are used in research/scripts we may use Advanced Bash and Linux of course! :) R and machine learning Fortran course, Object-oriented-programming in Python course Other comments \u00b6 organization, hands-on exercises, material for consultation after course, engagement ;) I really liked the idea of asking questions to participants and involve them in discussions. More takeaway exercises Thanks The structure, materials, examples and tutors were great! Easy to follow either with the code-along or with the engaging questions. Training organization was also really good. It could be a bit longer to cover more aspects but as an intro to the concepts is adequate. All the teaching aids were well prepared. Hands-on and demos were fun and right amount! I specifically liked the first parts of each day, the second part seemed a bit more rushed, but still good. This was a great course! Since I have been working with bash for a few years I had come across most of the tools previously but now I have a much better understanding of what they do and how to use them. The length of the course was good and the content was perfect for my level. I liked the variation of code-along sessions mixed with more independent work in break-out rooms. It was great that we were invited to answer questions while it was respected that not everyone might want to. I appreciated that you kept to the schedule quite strictly, and that there was a clear structure both for the whole course and for each session. Enjoyed the break out rooms and having time to work through the examples in Rich\u00e8ls material. Think that some of the general concepts could be better explained from the start but did appreciate being shown how commands work in real time through the teachers command line. I think an extra hour of time for each day could improve the course to have more time to go through the examples in Birgittes material and discuss the answers together as only having a few minutes felt sometimes rushed. I overall found this course very useful and learned a lot of new commands but maybe would appreciate some examples of how I can use these in my own bioinformatics work. I think the selected material was good and represents a lot of the useful tools in Linux and the basics of Bash. When it said Intermediate Bash, I expected though that we would do a bit more advanced things, but given the time frame it was maybe not realistic. There was a good amount of hand-on vs demonstration I think. The supplementary material was nice, the quality of them is good and I will happily refer back to them. The main problem I have with the course is awk and sed were a bit rushed (too much content in too little time) compared to bash scripting being a bit superficial. Maybe it\u2019s better to raise prerequisites a bit, so that people should know the basics of Bash before starting. Then more time could be spent on awk and sed. I feel like I did not really learn how to use those any better than I knew before or see any really effective uses of them. An alternative could be an extra 3 hour session for those topics if you do not want to drop the introduction to Bash. I think both teachers were excellent and encouraged active participation, whether through breakout rooms or through encouraging exercises. The last session about QoL was also really useful and had some tips I did not know before. Thanks to everyone who organised it! The material was uneven - some parts are really good and can be reread when you are going through it yourself and reminding yourself how it was done, and other part was too sparse (lacked any theory). This was mainly a problem for the awk session which would have been easier to understand if there was a short text with some of the common commands and such. Reading a book is good, and might be how you learn well in a longer course, but it did not work for me for learning in a short course like this that should more be a help for us to do our research better. I think everything was great considering how short the training event was. I would maybe separate the two days next time: instead of Mon-Tue, you could try Mon-Wed or Tue-Thu so that there is one empty day in between, and you could assign some exercises to do in that empty day. I think this would give students more time to practice what they learn in the course Feedback in chat \u00b6 Hi, I\u2019m sorry but I need to leave! Thank you for the course, it was very useful. I look forward to the course evaluation. Bye!","title":"Evaluation 2025-06-02 and 2025-06-03"},{"location":"evaluations/20250602/#evaluation__2025-06-02__and__2025-06-03","text":"Date: 2025-06-02 and 2025-06-02 Number of registrations: 40 Number of learners on Day 1: Showing up: 15 (38% showing up) Being present most of the time: 11 (28% actively participating) Number of filled-in evaluations: 11 (100%)","title":"Evaluation 2025-06-02 and 2025-06-03"},{"location":"evaluations/20250602/#analysis","text":"Evaluation results (csv) Evaluation results (xlsx) Analysis script Average confidence per question (.csv) Success score : 77%","title":"Analysis"},{"location":"evaluations/20250602/#pace","text":"good, perhaps slightly quick It is balanced. I was good I think is good but I did not code along as I saw that then I catch less information today intensive and less time to do exercise Good! just tight for the exercises The pace was good, quite high but for this type of intermediate course I think that is not a problem. I can go back to the things I found the most interesting or difficult later. A little quick, some extra time would help particularly for Birgittes section The pace was excellent Ok on Monday, a bit rushed towards the end on Tuesday Maybe it was a bit quick? I mean, it was easy to follow and understand, but then there was very little time to actually practice the exercises properly. I think it\u2019s normal given that the course was short!","title":"Pace"},{"location":"evaluations/20250602/#future__topics","text":"python? why we have so many languages? what do they add ? Different file systems, efficient editing of text files using Vim e.g. multiline find and replace, substitution etc. I don\u00b4t think anything else can be provided same but advance and longer automating processes and more into .bashrc Perhaps showing real examples of these tools are used in research/scripts we may use Advanced Bash and Linux of course! :) R and machine learning Fortran course, Object-oriented-programming in Python course","title":"Future topics"},{"location":"evaluations/20250602/#other__comments","text":"organization, hands-on exercises, material for consultation after course, engagement ;) I really liked the idea of asking questions to participants and involve them in discussions. More takeaway exercises Thanks The structure, materials, examples and tutors were great! Easy to follow either with the code-along or with the engaging questions. Training organization was also really good. It could be a bit longer to cover more aspects but as an intro to the concepts is adequate. All the teaching aids were well prepared. Hands-on and demos were fun and right amount! I specifically liked the first parts of each day, the second part seemed a bit more rushed, but still good. This was a great course! Since I have been working with bash for a few years I had come across most of the tools previously but now I have a much better understanding of what they do and how to use them. The length of the course was good and the content was perfect for my level. I liked the variation of code-along sessions mixed with more independent work in break-out rooms. It was great that we were invited to answer questions while it was respected that not everyone might want to. I appreciated that you kept to the schedule quite strictly, and that there was a clear structure both for the whole course and for each session. Enjoyed the break out rooms and having time to work through the examples in Rich\u00e8ls material. Think that some of the general concepts could be better explained from the start but did appreciate being shown how commands work in real time through the teachers command line. I think an extra hour of time for each day could improve the course to have more time to go through the examples in Birgittes material and discuss the answers together as only having a few minutes felt sometimes rushed. I overall found this course very useful and learned a lot of new commands but maybe would appreciate some examples of how I can use these in my own bioinformatics work. I think the selected material was good and represents a lot of the useful tools in Linux and the basics of Bash. When it said Intermediate Bash, I expected though that we would do a bit more advanced things, but given the time frame it was maybe not realistic. There was a good amount of hand-on vs demonstration I think. The supplementary material was nice, the quality of them is good and I will happily refer back to them. The main problem I have with the course is awk and sed were a bit rushed (too much content in too little time) compared to bash scripting being a bit superficial. Maybe it\u2019s better to raise prerequisites a bit, so that people should know the basics of Bash before starting. Then more time could be spent on awk and sed. I feel like I did not really learn how to use those any better than I knew before or see any really effective uses of them. An alternative could be an extra 3 hour session for those topics if you do not want to drop the introduction to Bash. I think both teachers were excellent and encouraged active participation, whether through breakout rooms or through encouraging exercises. The last session about QoL was also really useful and had some tips I did not know before. Thanks to everyone who organised it! The material was uneven - some parts are really good and can be reread when you are going through it yourself and reminding yourself how it was done, and other part was too sparse (lacked any theory). This was mainly a problem for the awk session which would have been easier to understand if there was a short text with some of the common commands and such. Reading a book is good, and might be how you learn well in a longer course, but it did not work for me for learning in a short course like this that should more be a help for us to do our research better. I think everything was great considering how short the training event was. I would maybe separate the two days next time: instead of Mon-Tue, you could try Mon-Wed or Tue-Thu so that there is one empty day in between, and you could assign some exercises to do in that empty day. I think this would give students more time to practice what they learn in the course","title":"Other comments"},{"location":"evaluations/20250602/#feedback__in__chat","text":"Hi, I\u2019m sorry but I need to leave! Thank you for the course, it was very useful. I look forward to the course evaluation. Bye!","title":"Feedback in chat"},{"location":"evaluations/20251204/","text":"Evaluation 2025-12-04 and 2025-12-05 \u00b6","title":"Evaluation 2025-12-04 and 2025-12-05"},{"location":"evaluations/20251204/#evaluation__2025-12-04__and__2025-12-05","text":"","title":"Evaluation 2025-12-04 and 2025-12-05"},{"location":"lesson_plans/","text":"Lesson plans \u00b6 Here are the lesson plans of this course: No Date Lesson plans 1.1 2025-06-02, Day 1 Lesson plan 1.2 2025-06-03, Day 2 Lesson plan 2.1 2025-12-04, Day 1 Lesson plan 2.2 2025-12-05, Day 2 Lesson plan","title":"Lesson plans"},{"location":"lesson_plans/#lesson__plans","text":"Here are the lesson plans of this course: No Date Lesson plans 1.1 2025-06-02, Day 1 Lesson plan 1.2 2025-06-03, Day 2 Lesson plan 2.1 2025-12-04, Day 1 Lesson plan 2.2 2025-12-05, Day 2 Lesson plan","title":"Lesson plans"},{"location":"lesson_plans/20151204/","text":"2025-12-04 \u00b6","title":"2025-12-04"},{"location":"lesson_plans/20151204/#2025-12-04","text":"","title":"2025-12-04"},{"location":"lesson_plans/20241205/","text":"2025-12-05 \u00b6","title":"2025-12-05"},{"location":"lesson_plans/20241205/#2025-12-05","text":"","title":"2025-12-05"},{"location":"lesson_plans/20250602/","text":"Lesson plan 2025-06-02 by Richel \u00b6 Date: 2025-06-02 Author: Richel Lesson plan Evaluation Reflection Morning 1: smarter command-line \u00b6 I am scheduled second: Time Topic Teacher 9:00-10:00 Linux pipe, wc , cut BB 10:00-10:15 Break . 10:15-11:00 grep RB 11:00-11:15 Break . 11:15-12:00 awk RB I should assume the learners can use a pipe. grep \u00b6 My learning outcomes are: Learners can use . , * , + , ? , [] , [^] , {} , () in regular expressions Learners can use grep for pattern matching Learners have practiced using a book on bash/Linux Add LOs are: Learners have experienced that grep is a filter Learners have sent text to grep using a pipe, e.g. man grep | grep \"[^A-Z] Learners know there are multiple flavours of regular expressions: use grep and grep -E As sources of text, I consider to use: \u2018Frankenstein; Or, The Modern Prometheus\u2019, from a plain text file at Project Gutenberg man grep or yelp man:grep or man grep | grep \"^[A-Z]\" https://www.regexone.com/ [Shotts, 2024] download and can be found in this repository at books/the_linux_command_line.pdf man grep | grep \u201c^[[:upper:]]\u201d Using the grep manual and https://www.regexone.com/ felt like the best options. Fixing the layout is harder, e.g. getting mermaid to work, making the admonitions prettier (fails). I will give up on mermaid : I think this session is ready now, but I can imagine writing the next session may influence it, so let\u2019s write the next session first, before creating a video. awk \u00b6 It used to be sed and awk in an earlier schedule. Commit 7282e58552cdbeb7bf70b0f3133ac2bee7702a33 moved sed to Day 2. I will accept: we (me and BB) are probably both working in the weekend, so let\u2019s accept this change. My LOs are: I can use awk Learners have practiced using a book on bash/Linux I\u2019ve inherited the first one from BC and BB and is simple enough, unlike the ones for grep , where I added some details. I will add some LOs: I can use awk in pipes I can use regular expressions in awk I can use awk to read a specific column I can use awk to transform text Non-LOs: I can use awk to analyse a file: the day is called \u2018Smart command-line\u2019 Books to use: Bash Beginners Guide chapter 6 , from section 6.2 to section 6.2.3 seems to work in my context Advanced Bash Scripting Guide , page C2. Awk is a micro primer, with some usefulness A practical guide to learning awk : uses files, not pipes Gawk: Effective AWK Programming : too complex for the LOs The Linux Command Line : no chapter on AWK Introduction to Linux : no chapter on AWK Linux Fundamentals : no chapter on AWK Ultimate Linux Newbie Guide : no chapter on AWK Advanced Linux programming : no chapter on AWK Linux From Scratch : no chapter on AWK Beyond Linux From Scratch : no chapter on AWK I will use the Bash Beginners Guide. Mapping sessions to LOs: 6.2.1: I can use awk in pipes 6.2.1: I can use awk to read a specific column 6.2.2: I can use awk to transform text 6.2.3: I can use regular expressions in awk Seems this works! I will map these to exercises, and adding a \u2018Can awk do \u2026?\u2019 section. Teaching \u00b6 I want to practice my Mike Bell teaching cycles. I feel the Feedback phase is weakest, hence I added this explicitly to the materials and schedule time for it. I have written a schedule in my sessions and in my notebook: I intend to keep track of the actual timing. During Challenge, I will put them into breakout rooms of 2 or 3, as this is better for learning, as well as a better place to answer questions. My biggest worry is Zoom. I\u2019ve switched to a new computer, installed Zoom there, but it seems to prefer to work via the browser. I\u2019ve just checked it -and it was good I did!- as it required an update. After updating, I went through all the settings and I now have better settings, e.g. that sharing my screen only takes 1 instead of 3 dialogs (1 dialog asks to share a window or a screen: I\u2019ve set this to always share my screen)! Took me 10 minutes and I am happy I had the time to go through this. I predict there will not be time to let the learners do even the essential exercises. I will mention this to them, so they are less disappointed. I think this problem is worse for AWK, as it has less time and its video is longer: Session Scheduled time Video duration grep 45 minutes 27 minutes AWK 40 minutes 31 minutes I do think AWK is useless, so I hope we can remove this in the next course iteration. Instead, sed feels the more natural session after grep . [ ] In next meeting, suggest to remove AWK from the schedule There are 40 registrations, so I expect 27% (same as the NAISS File Transfer course) to show up, which is 11 learners. References \u00b6 [Shotts, 2024] Shotts, William. The Linux command line: a complete introduction. No Starch Press, 2024. (in books/the_linux_command_line.pdf )","title":"Lesson plan 2025-06-02 by Richel"},{"location":"lesson_plans/20250602/#lesson__plan__2025-06-02__by__richel","text":"Date: 2025-06-02 Author: Richel Lesson plan Evaluation Reflection","title":"Lesson plan 2025-06-02 by Richel"},{"location":"lesson_plans/20250602/#morning__1__smarter__command-line","text":"I am scheduled second: Time Topic Teacher 9:00-10:00 Linux pipe, wc , cut BB 10:00-10:15 Break . 10:15-11:00 grep RB 11:00-11:15 Break . 11:15-12:00 awk RB I should assume the learners can use a pipe.","title":"Morning 1: smarter command-line"},{"location":"lesson_plans/20250602/#grep","text":"My learning outcomes are: Learners can use . , * , + , ? , [] , [^] , {} , () in regular expressions Learners can use grep for pattern matching Learners have practiced using a book on bash/Linux Add LOs are: Learners have experienced that grep is a filter Learners have sent text to grep using a pipe, e.g. man grep | grep \"[^A-Z] Learners know there are multiple flavours of regular expressions: use grep and grep -E As sources of text, I consider to use: \u2018Frankenstein; Or, The Modern Prometheus\u2019, from a plain text file at Project Gutenberg man grep or yelp man:grep or man grep | grep \"^[A-Z]\" https://www.regexone.com/ [Shotts, 2024] download and can be found in this repository at books/the_linux_command_line.pdf man grep | grep \u201c^[[:upper:]]\u201d Using the grep manual and https://www.regexone.com/ felt like the best options. Fixing the layout is harder, e.g. getting mermaid to work, making the admonitions prettier (fails). I will give up on mermaid : I think this session is ready now, but I can imagine writing the next session may influence it, so let\u2019s write the next session first, before creating a video.","title":"grep"},{"location":"lesson_plans/20250602/#awk","text":"It used to be sed and awk in an earlier schedule. Commit 7282e58552cdbeb7bf70b0f3133ac2bee7702a33 moved sed to Day 2. I will accept: we (me and BB) are probably both working in the weekend, so let\u2019s accept this change. My LOs are: I can use awk Learners have practiced using a book on bash/Linux I\u2019ve inherited the first one from BC and BB and is simple enough, unlike the ones for grep , where I added some details. I will add some LOs: I can use awk in pipes I can use regular expressions in awk I can use awk to read a specific column I can use awk to transform text Non-LOs: I can use awk to analyse a file: the day is called \u2018Smart command-line\u2019 Books to use: Bash Beginners Guide chapter 6 , from section 6.2 to section 6.2.3 seems to work in my context Advanced Bash Scripting Guide , page C2. Awk is a micro primer, with some usefulness A practical guide to learning awk : uses files, not pipes Gawk: Effective AWK Programming : too complex for the LOs The Linux Command Line : no chapter on AWK Introduction to Linux : no chapter on AWK Linux Fundamentals : no chapter on AWK Ultimate Linux Newbie Guide : no chapter on AWK Advanced Linux programming : no chapter on AWK Linux From Scratch : no chapter on AWK Beyond Linux From Scratch : no chapter on AWK I will use the Bash Beginners Guide. Mapping sessions to LOs: 6.2.1: I can use awk in pipes 6.2.1: I can use awk to read a specific column 6.2.2: I can use awk to transform text 6.2.3: I can use regular expressions in awk Seems this works! I will map these to exercises, and adding a \u2018Can awk do \u2026?\u2019 section.","title":"awk"},{"location":"lesson_plans/20250602/#teaching","text":"I want to practice my Mike Bell teaching cycles. I feel the Feedback phase is weakest, hence I added this explicitly to the materials and schedule time for it. I have written a schedule in my sessions and in my notebook: I intend to keep track of the actual timing. During Challenge, I will put them into breakout rooms of 2 or 3, as this is better for learning, as well as a better place to answer questions. My biggest worry is Zoom. I\u2019ve switched to a new computer, installed Zoom there, but it seems to prefer to work via the browser. I\u2019ve just checked it -and it was good I did!- as it required an update. After updating, I went through all the settings and I now have better settings, e.g. that sharing my screen only takes 1 instead of 3 dialogs (1 dialog asks to share a window or a screen: I\u2019ve set this to always share my screen)! Took me 10 minutes and I am happy I had the time to go through this. I predict there will not be time to let the learners do even the essential exercises. I will mention this to them, so they are less disappointed. I think this problem is worse for AWK, as it has less time and its video is longer: Session Scheduled time Video duration grep 45 minutes 27 minutes AWK 40 minutes 31 minutes I do think AWK is useless, so I hope we can remove this in the next course iteration. Instead, sed feels the more natural session after grep . [ ] In next meeting, suggest to remove AWK from the schedule There are 40 registrations, so I expect 27% (same as the NAISS File Transfer course) to show up, which is 11 learners.","title":"Teaching"},{"location":"lesson_plans/20250602/#references","text":"[Shotts, 2024] Shotts, William. The Linux command line: a complete introduction. No Starch Press, 2024. (in books/the_linux_command_line.pdf )","title":"References"},{"location":"lesson_plans/20250603/","text":"Lesson plan 2025-06-03 by Richel \u00b6 Date: 2025-06-03 Author: Richel Morning 2: smarter bash \u00b6 I am at the middle of the schedule: Time Topic Teacher 9:00-10:00 Bash scripting RB 10:00-10:15 Break . 10:15-11:00 Advanced redirect, environment variables, links BB 11:00-11:15 Break . 11:15-12:00 Quality of life, compressing BC My learning outcomes are: Learners can write scripts that require user input Learners can use bash variables Learners can use bash if statements Learners can use bash if statements with the \u2018or\u2019 and \u2018and\u2019 symbols Learners can use bash for statements Learners have practiced using a book on bash/Linux As sources of text, I consider to use: man bash [Shotts, 2024] and can be found in this repository at books/the_linux_command_line.pdf [Iliev, 2020] Missing: dos2unix and unix2dos [ ] Suggest to add it to curriculum Teaching \u00b6 I want to do most of the things the same as yesterday. Yesterday, there were 11 learners (exactly as predicted!) I am unhappy about my Feedback phase, I consider doing quizzes next time instead. References \u00b6 [Iliev, 2020] Bobby Iliev. Introduction to bash scripting for developers. Site . [Shotts, 2024] Shotts, William. The Linux command line: a complete introduction. No Starch Press, 2024. Download (in books/the_linux_command_line.pdf )","title":"Lesson plan 2025-06-03 by Richel"},{"location":"lesson_plans/20250603/#lesson__plan__2025-06-03__by__richel","text":"Date: 2025-06-03 Author: Richel","title":"Lesson plan 2025-06-03 by Richel"},{"location":"lesson_plans/20250603/#morning__2__smarter__bash","text":"I am at the middle of the schedule: Time Topic Teacher 9:00-10:00 Bash scripting RB 10:00-10:15 Break . 10:15-11:00 Advanced redirect, environment variables, links BB 11:00-11:15 Break . 11:15-12:00 Quality of life, compressing BC My learning outcomes are: Learners can write scripts that require user input Learners can use bash variables Learners can use bash if statements Learners can use bash if statements with the \u2018or\u2019 and \u2018and\u2019 symbols Learners can use bash for statements Learners have practiced using a book on bash/Linux As sources of text, I consider to use: man bash [Shotts, 2024] and can be found in this repository at books/the_linux_command_line.pdf [Iliev, 2020] Missing: dos2unix and unix2dos [ ] Suggest to add it to curriculum","title":"Morning 2: smarter bash"},{"location":"lesson_plans/20250603/#teaching","text":"I want to do most of the things the same as yesterday. Yesterday, there were 11 learners (exactly as predicted!) I am unhappy about my Feedback phase, I consider doing quizzes next time instead.","title":"Teaching"},{"location":"lesson_plans/20250603/#references","text":"[Iliev, 2020] Bobby Iliev. Introduction to bash scripting for developers. Site . [Shotts, 2024] Shotts, William. The Linux command line: a complete introduction. No Starch Press, 2024. Download (in books/the_linux_command_line.pdf )","title":"References"},{"location":"lesson_plans/20251204/","text":"Lesson plan \u00b6 Date: 2025-12-04 Author: Richel Day: 1 From last course\u2019s reflection : Consider using real examples Use 1 session per page in my paper logbook","title":"Lesson plan"},{"location":"lesson_plans/20251204/#lesson__plan","text":"Date: 2025-12-04 Author: Richel Day: 1 From last course\u2019s reflection : Consider using real examples Use 1 session per page in my paper logbook","title":"Lesson plan"},{"location":"lesson_plans/20251205/","text":"Lesson plan \u00b6 Date: 2025-12-05 Author: Richel Day: 2","title":"Lesson plan"},{"location":"lesson_plans/20251205/#lesson__plan","text":"Date: 2025-12-05 Author: Richel Day: 2","title":"Lesson plan"},{"location":"meeting_notes/","text":"Meeting notes \u00b6 2025-04-03 2025-04-09","title":"Meeting notes"},{"location":"meeting_notes/#meeting__notes","text":"2025-04-03 2025-04-09","title":"Meeting notes"},{"location":"meeting_notes/20250403/","text":"Intermediate BASH and Linux \u00b6 Repository: https://github.com/UPPMAX/linux-command-line-201 Rendered material: https://uppmax.github.io/linux-command-line-201/ Meeting 3 April 13.00 \u00b6 Where do we meet online? [YES] the HPC Python meeting room: RB, BB, BC Someplace else: Decide on course name, UNDECIDED Linux command line 102: Linux command line 201: RB, BB Intermediate Bash/Linux: BB Intermediate Linux and Bash: RB, BB [your favorite] Basic Linux course: https://github.com/hpc2n/linux-command-line-101 Decide on MkDocs theme [DECIDED] ReadTheDocs: RB, BB, BC Materials: RB Materials with ReadTheDocs layout: BB Decide on using underscores or dashes in filename [DECIDED] Underscores: BB, BC, RB (also: the book, page 12]) Dashes: Vote on course duration and structure 6 hrs in one go: ILLEGAL 6 hrs in total: RB, BC, BB 3 hrs in total: RB [DECIDED, depends on Joachim] 2x 3 hours: BC, BB, RB 201, 202 ? Decide on a course date(s) [DECIDED] Week 23 (June 2 and June 3): MO + TU: BB, RB, BC [x] RB: Put on site MO June 2: RB TU June 3: RB WE June 4: RB TH June 5: RB MO June 16: RB TU June 17: RB WE June 18: RB MO June 23: RB TU June 24: RB [TOO LATE] WE June 25: RB [TOO LATE] TH June 27: RB [TOO LATE] FR June 28: RB Curriculum item Learning objective Volunteer(s) to teach this Bash scripting Learners can use bash variables RB Bash scripting Learners can use bash if statements RB Bash scripting Learners can use bash if statements with the \u2018or\u2019 and \u2018and\u2019 symbols RB Bash scripting Learners can use bash for statements RB Bash scripting Learners can write scripts that require user input RB Environment variables Learners can create, read and write to environment variables (e.g. [Shotts, 2024] , chapter 25, p390) BB Advanced redirect Learners can redirect output between the standard, error and log output streams BB Regular expressions Learners can use . , * , + , ? , [] , [^] , {} , () in regular expressions (19. What are Regular Expressions?, p266-onward)(or any regular expressions course) RB, ?BC Regular expressions Learners can use grep for pattern matching RB, ?BC Regular expressions Learners can use sed for pattern matched replacing BC Links (hard/soft) Learners can create soft and hard symbolic links (e.g. [Shotts, 2024] , \u20183. Symbolic Links\u2019, p24) BB Archiving/Compressing data Learners can compress and extract data, using (g)zip and tar BC Linux pipe Learners can chain commands using the Linux pipe (6. Pipelines, p63-p64) RB, BB Finding information Learners have practiced using a book on bash/Linux . Quality of life Learners can start a background process with & and terminate it BC Quality of life Terminal shortcuts/usage BC Quality of life Editing a .bashrc BC Quality of life Using aliases BC Linux tools cut RB, BC Linux tools dos2unix , unix2dos RB Linux tools wc RB, BC, BB Linux tools awk RB, BC [ ] BB: Contact Joachim Next meeting: [DECIDED] WE Apr 9 13:00-13:30: BB, BC, RB Welcome ad (Living document) \u00b6 In this Y-hour/X-day workshop you\u2019ll learn how to work smarter from a command line. To do so, you\u2019ll learn more Bash commands, scripting and some quality of life topics. You can run on your own (Linux) computer or on your favorite HPC cluster. At the end of the day, you should feel to be able to work smarter and able to avoid more grunt work (i.e. anything that involves repeated copypaste). The workshop is intended for users with some Linux experience, see the prerequisites . You do not need to be a member of a NAISS project in order to join the workshop, as we will provide one for you. Time: 2-3 June at 9-12 For more information and registration visit: XXX","title":"Intermediate BASH and Linux"},{"location":"meeting_notes/20250403/#intermediate__bash__and__linux","text":"Repository: https://github.com/UPPMAX/linux-command-line-201 Rendered material: https://uppmax.github.io/linux-command-line-201/","title":"Intermediate BASH and Linux"},{"location":"meeting_notes/20250403/#meeting__3__april__1300","text":"Where do we meet online? [YES] the HPC Python meeting room: RB, BB, BC Someplace else: Decide on course name, UNDECIDED Linux command line 102: Linux command line 201: RB, BB Intermediate Bash/Linux: BB Intermediate Linux and Bash: RB, BB [your favorite] Basic Linux course: https://github.com/hpc2n/linux-command-line-101 Decide on MkDocs theme [DECIDED] ReadTheDocs: RB, BB, BC Materials: RB Materials with ReadTheDocs layout: BB Decide on using underscores or dashes in filename [DECIDED] Underscores: BB, BC, RB (also: the book, page 12]) Dashes: Vote on course duration and structure 6 hrs in one go: ILLEGAL 6 hrs in total: RB, BC, BB 3 hrs in total: RB [DECIDED, depends on Joachim] 2x 3 hours: BC, BB, RB 201, 202 ? Decide on a course date(s) [DECIDED] Week 23 (June 2 and June 3): MO + TU: BB, RB, BC [x] RB: Put on site MO June 2: RB TU June 3: RB WE June 4: RB TH June 5: RB MO June 16: RB TU June 17: RB WE June 18: RB MO June 23: RB TU June 24: RB [TOO LATE] WE June 25: RB [TOO LATE] TH June 27: RB [TOO LATE] FR June 28: RB Curriculum item Learning objective Volunteer(s) to teach this Bash scripting Learners can use bash variables RB Bash scripting Learners can use bash if statements RB Bash scripting Learners can use bash if statements with the \u2018or\u2019 and \u2018and\u2019 symbols RB Bash scripting Learners can use bash for statements RB Bash scripting Learners can write scripts that require user input RB Environment variables Learners can create, read and write to environment variables (e.g. [Shotts, 2024] , chapter 25, p390) BB Advanced redirect Learners can redirect output between the standard, error and log output streams BB Regular expressions Learners can use . , * , + , ? , [] , [^] , {} , () in regular expressions (19. What are Regular Expressions?, p266-onward)(or any regular expressions course) RB, ?BC Regular expressions Learners can use grep for pattern matching RB, ?BC Regular expressions Learners can use sed for pattern matched replacing BC Links (hard/soft) Learners can create soft and hard symbolic links (e.g. [Shotts, 2024] , \u20183. Symbolic Links\u2019, p24) BB Archiving/Compressing data Learners can compress and extract data, using (g)zip and tar BC Linux pipe Learners can chain commands using the Linux pipe (6. Pipelines, p63-p64) RB, BB Finding information Learners have practiced using a book on bash/Linux . Quality of life Learners can start a background process with & and terminate it BC Quality of life Terminal shortcuts/usage BC Quality of life Editing a .bashrc BC Quality of life Using aliases BC Linux tools cut RB, BC Linux tools dos2unix , unix2dos RB Linux tools wc RB, BC, BB Linux tools awk RB, BC [ ] BB: Contact Joachim Next meeting: [DECIDED] WE Apr 9 13:00-13:30: BB, BC, RB","title":"Meeting 3 April 13.00"},{"location":"meeting_notes/20250403/#welcome__ad__living__document","text":"In this Y-hour/X-day workshop you\u2019ll learn how to work smarter from a command line. To do so, you\u2019ll learn more Bash commands, scripting and some quality of life topics. You can run on your own (Linux) computer or on your favorite HPC cluster. At the end of the day, you should feel to be able to work smarter and able to avoid more grunt work (i.e. anything that involves repeated copypaste). The workshop is intended for users with some Linux experience, see the prerequisites . You do not need to be a member of a NAISS project in order to join the workshop, as we will provide one for you. Time: 2-3 June at 9-12 For more information and registration visit: XXX","title":"Welcome ad (Living document)"},{"location":"meeting_notes/20250409/","text":"Meeting Wednesday 9 April 13:00-13:30 \u00b6 Status: did Joachim accept our course being two half-days? YES! Agree on welcome ad (see bottom of this document) DONE [DECIDED] One or several course pages (linked from NAISS training page): use links links from lunarc and uppmax to hpc2n? good registration method! or other center? Teaching schedule: Is just a suggestion for now We\u2019ll make teaching material and see if the schedule will work out What about of use 50 mins for teaching? Yes Also add evaluation ToDos [ ] BB: makes registration from HPC2N before tomorrow [ ] BC: course pages at center(s) Topic Estimated duration (minutes) Volunteer(s) to teach this Linux pipe 30 BB Linux tools, wc 15 BB Linux tools, cut 30 BC\u2013>BB grep 60 RB sed (2 advanced or QoL?, at least after scripting) 30 \u2013> 0 BC Linux tools, awk 30 BC Bash scripting 60 RB Advanced redirect (2 advanced?) 30 BB Environment variables 30 BB Links (hard/soft) 30 BB Archiving/Compressing 30 BC Quality of life (shorter) 60 \u2013> 45 (or ) BC Total 435 (= 7.25 hours) All Morning 1: smarter command-line \u00b6 Time Topic Teacher 9:00-10:00 Linux pipe, wc , cut BB 10:00-10:15 Break - 10:15-11:00 grep RB 11:00-11:15 Break - 11:15-12:00 sed and awk BC Morning 2: smarter bash \u00b6 Time Topic Teacher 9:00-10:00 Bash scripting RB 10:00-10:15 Break - 10:15-11:00 Advanced redirect, environment variables, links BB 11:00-11:15 Break - 11:15-12:00 Quality of life, compressing BC Previous meeting\u2019s notes Welcome ad (Living document) \u00b6 In this 6-hour 2-day workshop you\u2019ll learn how to work smarter from a command line. You can follow either day or both. To do so, you\u2019ll learn more Bash commands, scripting and some quality of life topics. You can run on your own (Linux) computer or on your favorite HPC cluster. At the end of each day, you should feel to be able to work smarter and able to avoid more grunt work (i.e. anything that involves repeated copypaste). The workshop is intended for users with some Linux experience, see the prerequisites . Time: 2 and 3 June, each day from 9-12 For more information and registration visit: XXX","title":"Meeting Wednesday 9 April 13:00-13:30"},{"location":"meeting_notes/20250409/#meeting__wednesday__9__april__1300-1330","text":"Status: did Joachim accept our course being two half-days? YES! Agree on welcome ad (see bottom of this document) DONE [DECIDED] One or several course pages (linked from NAISS training page): use links links from lunarc and uppmax to hpc2n? good registration method! or other center? Teaching schedule: Is just a suggestion for now We\u2019ll make teaching material and see if the schedule will work out What about of use 50 mins for teaching? Yes Also add evaluation ToDos [ ] BB: makes registration from HPC2N before tomorrow [ ] BC: course pages at center(s) Topic Estimated duration (minutes) Volunteer(s) to teach this Linux pipe 30 BB Linux tools, wc 15 BB Linux tools, cut 30 BC\u2013>BB grep 60 RB sed (2 advanced or QoL?, at least after scripting) 30 \u2013> 0 BC Linux tools, awk 30 BC Bash scripting 60 RB Advanced redirect (2 advanced?) 30 BB Environment variables 30 BB Links (hard/soft) 30 BB Archiving/Compressing 30 BC Quality of life (shorter) 60 \u2013> 45 (or ) BC Total 435 (= 7.25 hours) All","title":"Meeting Wednesday 9 April 13:00-13:30"},{"location":"meeting_notes/20250409/#morning__1__smarter__command-line","text":"Time Topic Teacher 9:00-10:00 Linux pipe, wc , cut BB 10:00-10:15 Break - 10:15-11:00 grep RB 11:00-11:15 Break - 11:15-12:00 sed and awk BC","title":"Morning 1: smarter command-line"},{"location":"meeting_notes/20250409/#morning__2__smarter__bash","text":"Time Topic Teacher 9:00-10:00 Bash scripting RB 10:00-10:15 Break - 10:15-11:00 Advanced redirect, environment variables, links BB 11:00-11:15 Break - 11:15-12:00 Quality of life, compressing BC Previous meeting\u2019s notes","title":"Morning 2: smarter bash"},{"location":"meeting_notes/20250409/#welcome__ad__living__document","text":"In this 6-hour 2-day workshop you\u2019ll learn how to work smarter from a command line. You can follow either day or both. To do so, you\u2019ll learn more Bash commands, scripting and some quality of life topics. You can run on your own (Linux) computer or on your favorite HPC cluster. At the end of each day, you should feel to be able to work smarter and able to avoid more grunt work (i.e. anything that involves repeated copypaste). The workshop is intended for users with some Linux experience, see the prerequisites . Time: 2 and 3 June, each day from 9-12 For more information and registration visit: XXX","title":"Welcome ad (Living document)"},{"location":"misc/test_admonitions/","text":"Admonition tests \u00b6 This page is to test which admonition do and do not work, by showing all admonitions in the documentation : My note note My seealso seealso My abstract abstract My tldr tldr My summary summary My info info My todo todo My tip tip My hint hint My important important My success success My check check My done done My question question My help help My faq faq My warning warning My caution caution My attention attention My failure failure My fail fail My missing missing My danger danger My error error My Bug bug My example example My quote quote My cite cite","title":"Admonition tests"},{"location":"misc/test_admonitions/#admonition__tests","text":"This page is to test which admonition do and do not work, by showing all admonitions in the documentation : My note note My seealso seealso My abstract abstract My tldr tldr My summary summary My info info My todo todo My tip tip My hint hint My important important My success success My check check My done done My question question My help help My faq faq My warning warning My caution caution My attention attention My failure failure My fail fail My missing missing My danger danger My error error My Bug bug My example example My quote quote My cite cite","title":"Admonition tests"},{"location":"misc/test_mermaid/","text":"mermaid tests \u00b6 This page is to test if mermaid works. Gantt chart \u00b6 gantt title Lesson plan dateFormat X axisFormat %s Prior : prior, 0, 10s Present: present, after prior, 5s Challenge: crit, challenge, after present, 20s Feedback: feedback, after challenge, 10s Flow chart \u00b6 flowchart TD complete_text[Any text] grep filter[Filter] filtered_text[The filtered text] grep --> |Regular expression| filter complete_text --> filter --> filtered_text","title":"mermaid tests"},{"location":"misc/test_mermaid/#mermaid__tests","text":"This page is to test if mermaid works.","title":"mermaid tests"},{"location":"misc/test_mermaid/#gantt__chart","text":"gantt title Lesson plan dateFormat X axisFormat %s Prior : prior, 0, 10s Present: present, after prior, 5s Challenge: crit, challenge, after present, 20s Feedback: feedback, after challenge, 10s","title":"Gantt chart"},{"location":"misc/test_mermaid/#flow__chart","text":"flowchart TD complete_text[Any text] grep filter[Filter] filtered_text[The filtered text] grep --> |Regular expression| filter complete_text --> filter --> filtered_text","title":"Flow chart"},{"location":"reflections/","text":"Reflections \u00b6 Here are the reflections of this course: No Date Reflections 1.1 2025-06-02, Day 1 Reflection 1.2 2025-06-03, Day 2 Reflection 1 2025-06-03, course Reflection 2.1 2025-12-04, Day 1 Reflection 2.2 2025-12-05, Day 2 Reflection","title":"Reflections"},{"location":"reflections/#reflections","text":"Here are the reflections of this course: No Date Reflections 1.1 2025-06-02, Day 1 Reflection 1.2 2025-06-03, Day 2 Reflection 1 2025-06-03, course Reflection 2.1 2025-12-04, Day 1 Reflection 2.2 2025-12-05, Day 2 Reflection","title":"Reflections"},{"location":"reflections/20241205/","text":"2025-12-05 \u00b6","title":"2025-12-05"},{"location":"reflections/20241205/#2025-12-05","text":"","title":"2025-12-05"},{"location":"reflections/20250602/","text":"Reflection 2025-06-02 \u00b6 Lesson plan Evaluation Reflection First hour \u00b6 The first hour I was a teacher in the back, helping out with the Zoom chat and the shared document. I was able to make an activity diagram: Time Activity 0 Lecture: Introduction 7 Lecture: Pipe 11 Start code-along 27 Start exercise, 1x interruption 31 Lecture: wc 42 Start exercise, 0x interruption 45 Answer question 47 Lecture: cut 60 Start exercise, 3x interruption 65 End Time spent on exercises: 18% Discussion from shared document, during the first hour \u00b6 Q: The sort command doesn\u2019t behave quite the same for me as in the example, could this be because I\u2019m using a Mac? (see answer below :-) ) A: [Richel] Yes: different unix-like systems have slightly different tools, with slightly different behavior. We\u2019ll all have to live with that :-). In the end, running \u2018man sort\u2019 to find how your sort works exactly is the only way to go. Q: What is the difference between \u201c| tee\u201d and > ? I\u2019ve been using > and it seems to do the same thing A: [Richel] Well spotted! Besides echoing, tee also produces a file as a by-product. tee is named after a T junction (imagine a river!), where \u2018water\u2019 (in this case: text) is going via two ways now. [Thanks!][Richel: You are welcome :-)] Second hour \u00b6 This session worked fine. The learners had 22 minutes for exercises. I put the learners in breakout rooms with 2-3 learners each. There were around 5 questions in total and around 10 other interactions. Before putting the learners in breakout rooms, my colleague reminded them about the shared Q&A document. I did not want to use the shared Q&A document: although there are some advantages (anybody can post anonymously, questions by others may inspire others), I feel the disadvantages (divide attention or need an extra volunteer for answering, No direct feedback, no interaction) outweigh these. Us teachers discussed about what the literature states. (note that in the third hour, the Q&A document effects my teaching because of the feedback feedback! I will always be up for a place to post anonymous feedback) After teaching, I\u2019ve searched the literature and the books in my possession for some wisdom. I found the following: \u2018Online teaching at its best\u2019, page 169, bottom, recommends a \u2018Question and answer space\u2019, as it fosters student interactions. We do not use this document for learners to interact with each other. \u2018Online teaching at its best\u2019, page 170, middle, does recommend to collect questions and their answers, without specifying how. I do see how the Q&A document would shape my course. However, I also see how the same effect is achieved by talking to learners in a breakout room. All my other books do not even mention a shared or Q&A document I conclude using a shared document for Q&A is not a thing, where having small group discussions is. Time scheduled Actual time Activity 0 0 Prior 10 ? Present 15 13 Challenge 35 35 Feedback and conclusion 45 43 Break Time spent on exercises: 22 / 45 = 49% I expected the break to be 5 minutes earlier, because I mistook my time schedule for this session with the next one in my (paper) logbook. [ ] Use 1 session per page Discussion from shared document, during the second hour \u00b6 Q: Is there any advantage to using egrep instead of grep \u2013E etc.? Why have both/teach us both? A: [Birgitte] they are equivalent, it is just personal preference. Some people would find it easier to remember/use egrep than grep \u2013E A: [Richel] if you start using tools that check for style, you will find out that egrep will be warned against. Q: Why do some of the options have more versions? Like, long recursive and short r? Also some are really not very easily named, like - - text is \u2013a A: [Birgitte] I guess again personal preference. The long version is usually a better mnemonic in the way it is named, while the short version may (as you say) not be, but it is quicker to write. Third hour \u00b6 During the break before this hour, I noticed my computer getting slower, with camera images of myself being shown around once per second. I\u2019ve seen this before and it causes Zoom to freeze. I decided to (1) use ethernet (I forgot!) and (2) restart Zoom. The Zoom was showing my camera well again. Due to this, I lost my co-host status. I forgot to ask my colleague on time to make me co-host again. When I asked, she was not there (which is fine: I encouraged her to do work!). This meant that I could not use breakout rooms. There is something joy in having 11 people work in silent in a Zoom room. However, there was no way I could see what they were doing. I was teaching in the blind and I missed seeing what they were doing exactly. In the shared document, there is just one discussion (see its below) in which two learners felt intimidated by the book. One can see in the lesson plan that I think (and I still do!) it is the best fitting book. But I am not too enthusiastic about it either. Next time, do something else: either use the awk manual or use material from my AWK course. Or (my favorite) drop awk altogether. [ ] Use man awk or use custom course materials or remove awk Time scheduled Actual time Activity 0 0 Prior 5 ? Present 10 ? Challenge 30 30 Feedback and conclusion 40 40 Break Time spent on exercises: 20 / 40 = 50% Discussion from shared document, during the third hour \u00b6 Q: Can you recommend a short online intro to awk (not a whole book) just like a couple pages with the most important? A [Richel]: I think this book is closest to that: it is not an AWK book at all. I have seen only one course that uses the one-liner approach (which happens to be mine :-)) at https://uppmax.github.io/awk_course/ . Does that answer your question? Thanks. I will read it! I meant something like what for the other section with pipe and wc/cut. [Richel] I don\u2019t make those cheat sheets on purpose : it takes away your learning. You are encouraged to make one: it is great for learning :-) Not sure that works for me. I\u2019ll check your other course, and do some googling. Thanks! [Richel] Great! Asking AIs is all the hype nowadays too \u2026 Tried it. Got like 8 wrong of 10 so wasn\u2019t cool :-( [Richel] Too bad it does not work! The book used, however, only shows 4 lines of AWK of which 3 are used. Maybe that is little enough\u2026 There is a cheat sheet here: AWK cheat sheet [Richel] Well done! Thanks for finding this! I also get intimidated having to look in a book for a short course like this, so prefer a short text like that. Would have preferred one styled to the course so I know what we are expected to know Conclusion \u00b6 In the second hour, I followed the teaching cycle well. Too bad I messed up the last minutes. Self-grade: 7 In the third hour, I feel bad about teaching in the dark, even though I agree with my choices in the moment. Self-grade: 6 The full course reflection","title":"Reflection 2025-06-02"},{"location":"reflections/20250602/#reflection__2025-06-02","text":"Lesson plan Evaluation Reflection","title":"Reflection 2025-06-02"},{"location":"reflections/20250602/#first__hour","text":"The first hour I was a teacher in the back, helping out with the Zoom chat and the shared document. I was able to make an activity diagram: Time Activity 0 Lecture: Introduction 7 Lecture: Pipe 11 Start code-along 27 Start exercise, 1x interruption 31 Lecture: wc 42 Start exercise, 0x interruption 45 Answer question 47 Lecture: cut 60 Start exercise, 3x interruption 65 End Time spent on exercises: 18%","title":"First hour"},{"location":"reflections/20250602/#discussion__from__shared__document__during__the__first__hour","text":"Q: The sort command doesn\u2019t behave quite the same for me as in the example, could this be because I\u2019m using a Mac? (see answer below :-) ) A: [Richel] Yes: different unix-like systems have slightly different tools, with slightly different behavior. We\u2019ll all have to live with that :-). In the end, running \u2018man sort\u2019 to find how your sort works exactly is the only way to go. Q: What is the difference between \u201c| tee\u201d and > ? I\u2019ve been using > and it seems to do the same thing A: [Richel] Well spotted! Besides echoing, tee also produces a file as a by-product. tee is named after a T junction (imagine a river!), where \u2018water\u2019 (in this case: text) is going via two ways now. [Thanks!][Richel: You are welcome :-)]","title":"Discussion from shared document, during the first hour"},{"location":"reflections/20250602/#second__hour","text":"This session worked fine. The learners had 22 minutes for exercises. I put the learners in breakout rooms with 2-3 learners each. There were around 5 questions in total and around 10 other interactions. Before putting the learners in breakout rooms, my colleague reminded them about the shared Q&A document. I did not want to use the shared Q&A document: although there are some advantages (anybody can post anonymously, questions by others may inspire others), I feel the disadvantages (divide attention or need an extra volunteer for answering, No direct feedback, no interaction) outweigh these. Us teachers discussed about what the literature states. (note that in the third hour, the Q&A document effects my teaching because of the feedback feedback! I will always be up for a place to post anonymous feedback) After teaching, I\u2019ve searched the literature and the books in my possession for some wisdom. I found the following: \u2018Online teaching at its best\u2019, page 169, bottom, recommends a \u2018Question and answer space\u2019, as it fosters student interactions. We do not use this document for learners to interact with each other. \u2018Online teaching at its best\u2019, page 170, middle, does recommend to collect questions and their answers, without specifying how. I do see how the Q&A document would shape my course. However, I also see how the same effect is achieved by talking to learners in a breakout room. All my other books do not even mention a shared or Q&A document I conclude using a shared document for Q&A is not a thing, where having small group discussions is. Time scheduled Actual time Activity 0 0 Prior 10 ? Present 15 13 Challenge 35 35 Feedback and conclusion 45 43 Break Time spent on exercises: 22 / 45 = 49% I expected the break to be 5 minutes earlier, because I mistook my time schedule for this session with the next one in my (paper) logbook. [ ] Use 1 session per page","title":"Second hour"},{"location":"reflections/20250602/#discussion__from__shared__document__during__the__second__hour","text":"Q: Is there any advantage to using egrep instead of grep \u2013E etc.? Why have both/teach us both? A: [Birgitte] they are equivalent, it is just personal preference. Some people would find it easier to remember/use egrep than grep \u2013E A: [Richel] if you start using tools that check for style, you will find out that egrep will be warned against. Q: Why do some of the options have more versions? Like, long recursive and short r? Also some are really not very easily named, like - - text is \u2013a A: [Birgitte] I guess again personal preference. The long version is usually a better mnemonic in the way it is named, while the short version may (as you say) not be, but it is quicker to write.","title":"Discussion from shared document, during the second hour"},{"location":"reflections/20250602/#third__hour","text":"During the break before this hour, I noticed my computer getting slower, with camera images of myself being shown around once per second. I\u2019ve seen this before and it causes Zoom to freeze. I decided to (1) use ethernet (I forgot!) and (2) restart Zoom. The Zoom was showing my camera well again. Due to this, I lost my co-host status. I forgot to ask my colleague on time to make me co-host again. When I asked, she was not there (which is fine: I encouraged her to do work!). This meant that I could not use breakout rooms. There is something joy in having 11 people work in silent in a Zoom room. However, there was no way I could see what they were doing. I was teaching in the blind and I missed seeing what they were doing exactly. In the shared document, there is just one discussion (see its below) in which two learners felt intimidated by the book. One can see in the lesson plan that I think (and I still do!) it is the best fitting book. But I am not too enthusiastic about it either. Next time, do something else: either use the awk manual or use material from my AWK course. Or (my favorite) drop awk altogether. [ ] Use man awk or use custom course materials or remove awk Time scheduled Actual time Activity 0 0 Prior 5 ? Present 10 ? Challenge 30 30 Feedback and conclusion 40 40 Break Time spent on exercises: 20 / 40 = 50%","title":"Third hour"},{"location":"reflections/20250602/#discussion__from__shared__document__during__the__third__hour","text":"Q: Can you recommend a short online intro to awk (not a whole book) just like a couple pages with the most important? A [Richel]: I think this book is closest to that: it is not an AWK book at all. I have seen only one course that uses the one-liner approach (which happens to be mine :-)) at https://uppmax.github.io/awk_course/ . Does that answer your question? Thanks. I will read it! I meant something like what for the other section with pipe and wc/cut. [Richel] I don\u2019t make those cheat sheets on purpose : it takes away your learning. You are encouraged to make one: it is great for learning :-) Not sure that works for me. I\u2019ll check your other course, and do some googling. Thanks! [Richel] Great! Asking AIs is all the hype nowadays too \u2026 Tried it. Got like 8 wrong of 10 so wasn\u2019t cool :-( [Richel] Too bad it does not work! The book used, however, only shows 4 lines of AWK of which 3 are used. Maybe that is little enough\u2026 There is a cheat sheet here: AWK cheat sheet [Richel] Well done! Thanks for finding this! I also get intimidated having to look in a book for a short course like this, so prefer a short text like that. Would have preferred one styled to the course so I know what we are expected to know","title":"Discussion from shared document, during the third hour"},{"location":"reflections/20250602/#conclusion","text":"In the second hour, I followed the teaching cycle well. Too bad I messed up the last minutes. Self-grade: 7 In the third hour, I feel bad about teaching in the dark, even though I agree with my choices in the moment. Self-grade: 6 The full course reflection","title":"Conclusion"},{"location":"reflections/20250603/","text":"Reflection 2025-06-03 \u00b6 Lesson plan Evaluation Reflection First hour \u00b6 The first hour went smoothly and followed the schedule smoothly: Scheduled time Actual time Phase 9:00 9:00 Prior 9:10 9:08 (-2) Present 9:15 9:11 (-4) Challenge 9:50 9:50 Feedback 10:00 10:00 Done 65% of the time spent on exercises I had 4 breakout rooms, with exactly 2 learners each. 3 out of 4 rooms were duos that were sharing their screen and had fun discussions, with the occasional question. 1 room has 1 learner that could not actually work: she uses Dardel and Dardel does not have nano installed \u2026? I recommended emacs , which she enjoyed much better than vi . I will ask PDC to add nano on Dardel. [ ] Ask PDC to install nano on Dardel I was unhappy with my Feedback yesterday, so I did it differently: I went through the answers of the questions. This felt way better! Instead of going through all answers, however, I got only to answer 4 of 9. I did sidetrack by choice, yet, I feel that next time, I should go through all the answers first, and only then ask the harder questions. Grade: 8.0 Second hour \u00b6 Directly after the break, 6 out of 11 learners turned on their camera. When the recording started, this turned into 1 learner that kept his camera on. I made an activity diagram: Time Activity 10:15 Lecturing 10:32 Exercise 10:36 Lecture 10:47 Exercise 10:50 Lecture 10:57 Code along 11:00 Break 16% of the time spent on exercises Shared document, of second hour \u00b6 Q: If the variables we create are not persistent, how do they work in the context of a script? Will they be persistent if we write the variable in the script? I guess so\u2026 A [Richel]: you are right :-): the variables in a script exist as long as the script runs. Is a hard link the same as copying? A [Richel]: No: it means that the same file is at two locations at the same time. For example, if you delete the file from any of the two locations, it will be gone at both locations. A. [Birgitte] Yes, and same if you edit one of them, then the other is also edited Can you explain the concept of \u201cstandard error\u201d? I am confused with the stats concept\u2026 A [Richel]: any program can create different types of output. Regular output goes to the standard output (also called stdout). In a similar fashion, programs can write their error messages to a different thing (called a stream ), called standard error or stderr . When this stream is displayed on screen, it sometimes is colored red, to indicate the text was sent to the standard error stream. Does that help? Yes thanks In uppmax we got a file with the error, to know if the script worked or not, do we have the same at dardel PDC, or we have to do the \u201csearch\u201d of the stderr as you guys just taught us? A [Richel]: as far as I know, this works exactly the same, where one uses $? To get the exit code of a previous command, e.g. #!/bin/bash ./run_something.sh if [[ $? -ne 0 ]] ; then echo \u201cERROR happened!\u201d fi Does that help you? If not, or there is another problem, you can always contact me at `[Richel's work email address]` :-) Third hour \u00b6 I made an activity diagram: Time Activity 11:15 Lecturing 11:57 Evaluation 0% of the time spent on exercises I did the evaluation here. Shared document, of third hour \u00b6 Why would you use tar to archive your files when you can just compress them with gzip? A [Richel]: both tools achieve similar results, so you can use either. It can be, however, that you want to uncompress a file on \u2013for example- an old version of windows that does not support tar out-of-the-box. In that case, you may prefer to use gzip. Similar to (11): why do we first use tar and then compress rather than compress a directory directly? Tar makes it into one file? A [Richel]: Yes, tar can compress multiple files into one. And you are right: it can also compress a folder with files. There is little difference: if you compress a folder (with files), then tar will re-create that folder (with files). Did that answer your question? Sort of. I just was wondering what is the functional difference. The procedure is different (first tar to make several files into one tarball , then compress, second using zip directly just directly compresses all the files in the folder). Does it is mean that zip directly applies compression on every file individually and tar + gzip would apply compression on the tarball (so only 1 file). Is there a performance difference there? [Answer is on next page :-) ] A [Richel]: I don`t know the exact technical details here. Sure, I can google :-). Maybe creating a script and measuring directly is easier. I would bet on timings being identical. I will look into it, maybe experiment a bit, thanks! A [Richel]: Fun! What is nohup doing along with & ? A [Richel]: nohup allows one to run something that continues after ending a terminal ( to hang up was how terminals one day were ended). & allows one to run something in the background, which means a terminal can be used for running commands wile a process is running. Together, they allow for commands that run in the background while you remain logged in to the computer. Could you \u201coverwrite\u201d existing commands (e.g. ls ) with an alias? If you prefer list format e.g. ls -l , might be nice to only have alias ls=/usr/bin/ls -l . Will the bash alias be prioritized over system\u2019s ls ? A [Richel]: yes. I just tried it and it works! alias ls = \"/usr/bin/ls -l\" Course reflection \u00b6 I think the course went well, although I\u2019ve not read the feedback of the learners yet. Here are my current ideas: [ ] Suggest to replace awk by sed : B will have more time for the quality of life session R thinks sed is a better follow-up after grep R thinks awk is useless The full course reflection","title":"Reflection 2025-06-03"},{"location":"reflections/20250603/#reflection__2025-06-03","text":"Lesson plan Evaluation Reflection","title":"Reflection 2025-06-03"},{"location":"reflections/20250603/#first__hour","text":"The first hour went smoothly and followed the schedule smoothly: Scheduled time Actual time Phase 9:00 9:00 Prior 9:10 9:08 (-2) Present 9:15 9:11 (-4) Challenge 9:50 9:50 Feedback 10:00 10:00 Done 65% of the time spent on exercises I had 4 breakout rooms, with exactly 2 learners each. 3 out of 4 rooms were duos that were sharing their screen and had fun discussions, with the occasional question. 1 room has 1 learner that could not actually work: she uses Dardel and Dardel does not have nano installed \u2026? I recommended emacs , which she enjoyed much better than vi . I will ask PDC to add nano on Dardel. [ ] Ask PDC to install nano on Dardel I was unhappy with my Feedback yesterday, so I did it differently: I went through the answers of the questions. This felt way better! Instead of going through all answers, however, I got only to answer 4 of 9. I did sidetrack by choice, yet, I feel that next time, I should go through all the answers first, and only then ask the harder questions. Grade: 8.0","title":"First hour"},{"location":"reflections/20250603/#second__hour","text":"Directly after the break, 6 out of 11 learners turned on their camera. When the recording started, this turned into 1 learner that kept his camera on. I made an activity diagram: Time Activity 10:15 Lecturing 10:32 Exercise 10:36 Lecture 10:47 Exercise 10:50 Lecture 10:57 Code along 11:00 Break 16% of the time spent on exercises","title":"Second hour"},{"location":"reflections/20250603/#shared__document__of__second__hour","text":"Q: If the variables we create are not persistent, how do they work in the context of a script? Will they be persistent if we write the variable in the script? I guess so\u2026 A [Richel]: you are right :-): the variables in a script exist as long as the script runs. Is a hard link the same as copying? A [Richel]: No: it means that the same file is at two locations at the same time. For example, if you delete the file from any of the two locations, it will be gone at both locations. A. [Birgitte] Yes, and same if you edit one of them, then the other is also edited Can you explain the concept of \u201cstandard error\u201d? I am confused with the stats concept\u2026 A [Richel]: any program can create different types of output. Regular output goes to the standard output (also called stdout). In a similar fashion, programs can write their error messages to a different thing (called a stream ), called standard error or stderr . When this stream is displayed on screen, it sometimes is colored red, to indicate the text was sent to the standard error stream. Does that help? Yes thanks In uppmax we got a file with the error, to know if the script worked or not, do we have the same at dardel PDC, or we have to do the \u201csearch\u201d of the stderr as you guys just taught us? A [Richel]: as far as I know, this works exactly the same, where one uses $? To get the exit code of a previous command, e.g. #!/bin/bash ./run_something.sh if [[ $? -ne 0 ]] ; then echo \u201cERROR happened!\u201d fi Does that help you? If not, or there is another problem, you can always contact me at `[Richel's work email address]` :-)","title":"Shared document, of second hour"},{"location":"reflections/20250603/#third__hour","text":"I made an activity diagram: Time Activity 11:15 Lecturing 11:57 Evaluation 0% of the time spent on exercises I did the evaluation here.","title":"Third hour"},{"location":"reflections/20250603/#shared__document__of__third__hour","text":"Why would you use tar to archive your files when you can just compress them with gzip? A [Richel]: both tools achieve similar results, so you can use either. It can be, however, that you want to uncompress a file on \u2013for example- an old version of windows that does not support tar out-of-the-box. In that case, you may prefer to use gzip. Similar to (11): why do we first use tar and then compress rather than compress a directory directly? Tar makes it into one file? A [Richel]: Yes, tar can compress multiple files into one. And you are right: it can also compress a folder with files. There is little difference: if you compress a folder (with files), then tar will re-create that folder (with files). Did that answer your question? Sort of. I just was wondering what is the functional difference. The procedure is different (first tar to make several files into one tarball , then compress, second using zip directly just directly compresses all the files in the folder). Does it is mean that zip directly applies compression on every file individually and tar + gzip would apply compression on the tarball (so only 1 file). Is there a performance difference there? [Answer is on next page :-) ] A [Richel]: I don`t know the exact technical details here. Sure, I can google :-). Maybe creating a script and measuring directly is easier. I would bet on timings being identical. I will look into it, maybe experiment a bit, thanks! A [Richel]: Fun! What is nohup doing along with & ? A [Richel]: nohup allows one to run something that continues after ending a terminal ( to hang up was how terminals one day were ended). & allows one to run something in the background, which means a terminal can be used for running commands wile a process is running. Together, they allow for commands that run in the background while you remain logged in to the computer. Could you \u201coverwrite\u201d existing commands (e.g. ls ) with an alias? If you prefer list format e.g. ls -l , might be nice to only have alias ls=/usr/bin/ls -l . Will the bash alias be prioritized over system\u2019s ls ? A [Richel]: yes. I just tried it and it works! alias ls = \"/usr/bin/ls -l\"","title":"Shared document, of third hour"},{"location":"reflections/20250603/#course__reflection","text":"I think the course went well, although I\u2019ve not read the feedback of the learners yet. Here are my current ideas: [ ] Suggest to replace awk by sed : B will have more time for the quality of life session R thinks sed is a better follow-up after grep R thinks awk is useless The full course reflection","title":"Course reflection"},{"location":"reflections/202506_course/","text":"Reflection 2025-06 course \u00b6 Lesson plan day 1 Lesson plan day 2 Evaluation Reflection day 1 Reflection day 2 Earlier reflection \u00b6 Day Hour Self grade Comment 1 2 7 Messed up the last 5 minutes 1 3 6 Teaching in the dark 2 1 8 Feedback was better Day Hour Time for exercises 1 1 18% 1 2 49% 1 3 50% 2 1 65% 2 2 16% 2 3 0% Day Average time for exercises B (18+16+0)/3=11% R (49+50+65)/3=55% [x] Use 1 session per page in my paper logbook Ask PDC to install nano on Dardel Suggest to replace awk by sed : B will have more time for the quality of life session R thinks sed is a better follow-up after grep R thinks awk is useless Would remove the weakest session (i.e. awk ) Would give more time to the one-but-weakest session (i.e. sed ) Evaluation results \u00b6 Confidence \u00b6 The weakest sessions were awk and sed . This matches my ideas and I already suggested to replace awk by sed . Question Mean confidence I can use awk 2.45 I can use sed 3 I can use regular expressions 3.45 I can use cut 3.64 I can write a bash script 3.82 I can make a symbolic link 3.9 I can use environment variables 3.91 I can use redirection 4 I can use tar 4 I can use grep 4.18 I can use gzip 4.18 I can use wc 4.18 I know what wc is 4.45 I can use pipe 4.64 Pace \u00b6 good, perhaps slightly quick It is balanced. I was good I think is good but I did not code along as I saw that then I catch less information Does not apply to me, as I do not do code-alongs. today intensive and less time to do exercise Does not apply to me, as I had 5x more time for exercises. Good! just tight for the exercises Does not apply to me, as I had 5x more time for exercises. The pace was good, quite high but for this type of intermediate course I think that is not a problem. I can go back to the things I found the most interesting or difficult later. A little quick, some extra time would help particularly for Birgittes section This matches my ideas and I already suggested to replace awk by sed . The pace was excellent Ok on Monday, a bit rushed towards the end on Tuesday Does not apply to me, as I was not teaching then. Maybe it was a bit quick? I mean, it was easy to follow and understand, but then there was very little time to actually practice the exercises properly. I think it\u2019s normal given that the course was short! The little time for exercises does not apply to me, as I had 5x more time for exercises. Future topics \u00b6 python? why we have so many languages? what do they add ? Python is not among the courses we link to , but it is mentioned in the same newsletter this course was part of (i.e. the NAISS newsletter). Different file systems, efficient editing of text files using Vim e.g. multiline find and replace, substitution etc. File transfer is not among the courses we link to , but it is mentioned in the same newsletter this course was part of (i.e. the NAISS newsletter). Efficient vim is not among the courses at all. Suggest to add course on efficient vim I don\u00b4t think anything else can be provided same but advance and longer automating processes and more into .bashrc This is not my session. Perhaps showing real examples of these tools are used in research/scripts we may use I agree it would be (even more) interesting to look at research scripts. [x] Consider using real examples Advanced Bash and Linux of course! :) Suggest to add \u2018Command Line 301\u2019 course R and machine learning R (and machine learning in R) is not among the courses we link to . I am unsure if the R-MATLAB-Julia course is part of the NAISS newsletter. Check if R-MATLAB-Julia course is part of the NAISS newsletter Fortran course, Object-oriented-programming in Python course Suggest to add course on FORTRAN Suggest to add course on OOP programming with Python Other comments \u00b6 organization, hands-on exercises, material for consultation after course, engagement ;) Great! I really liked the idea of asking questions to participants and involve them in discussions. Great! More takeaway exercises The little time for exercises does not apply to me, as I had 5x more time for exercises. Thanks Great! The structure, materials, examples and tutors were great! Easy to follow either with the code-along or with the engaging questions. Training organization was also really good. It could be a bit longer to cover more aspects but as an intro to the concepts is adequate. All the teaching aids were well prepared. Hands-on and demos were fun and right amount! I specifically liked the first parts of each day, the second part seemed a bit more rushed, but still good. This was a great course! Since I have been working with bash for a few years I had come across most of the tools previously but now I have a much better understanding of what they do and how to use them. The length of the course was good and the content was perfect for my level. I liked the variation of code-along sessions mixed with more independent work in break-out rooms. It was great that we were invited to answer questions while it was respected that not everyone might want to. I am happy that this is mentioned! [continue] I appreciated that you kept to the schedule quite strictly, and that there was a clear structure both for the whole course and for each session. Enjoyed the break out rooms and having time to work through the examples in Rich\u00e8ls material. Think that some of the general concepts could be better explained from the start but did appreciate being shown how commands work in real time through the teachers command line. I think an extra hour of time for each day could improve the course to have more time to go through the examples in Birgittes material and discuss the answers together as only having a few minutes felt sometimes rushed. I overall found this course very useful and learned a lot of new commands but maybe would appreciate some examples of how I can use these in my own bioinformatics work. I think the selected material was good and represents a lot of the useful tools in Linux and the basics of Bash. When it said Intermediate Bash, I expected though that we would do a bit more advanced things, but given the time frame it was maybe not realistic. There was a good amount of hand-on vs demonstration I think. The supplementary material was nice, the quality of them is good and I will happily refer back to them. The main problem I have with the course is awk and sed were a bit rushed (too much content in too little time) compared to bash scripting being a bit superficial. Maybe it\u2019s better to raise prerequisites a bit, so that people should know the basics of Bash before starting. Then more time could be spent on awk and sed. This matches my ideas and I already suggested to replace awk by sed . The Bash scripting being superficial is interesting feedback: is this learner one of the advanced ones, or would the regular learners agree with this too? I feel adding a new course, e.g. Command Line 301 will be a way forward here. [continue] I feel like I did not really learn how to use those any better than I knew before or see any really effective uses of them. An alternative could be an extra 3 hour session for those topics if you do not want to drop the introduction to Bash. I think both teachers were excellent and encouraged active participation, whether through breakout rooms or through encouraging exercises. The last session about QoL was also really useful and had some tips I did not know before. Thanks to everyone who organised it! The material was uneven - some parts are really good and can be reread when you are going through it yourself and reminding yourself how it was done, and other part was too sparse (lacked any theory). This was mainly a problem for the awk session which would have been easier to understand if there was a short text with some of the common commands and such. Reading a book is good, and might be how you learn well in a longer course, but it did not work for me for learning in a short course like this that should more be a help for us to do our research better. This matches my ideas and I already suggested to replace awk by sed . Else I would consider following up on this, as I am unsure if the AWK book is good enough to keep: maybe I will add the awk commands needed to my course material. I think everything was great considering how short the training event was. I would maybe separate the two days next time: instead of Mon-Tue, you could try Mon-Wed or Tue-Thu so that there is one empty day in between, and you could assign some exercises to do in that empty day. I think this would give students more time to practice what they learn in the course Interesting idea. Let\u2019s ask Suggest to add a empty day between the course days Feedback in chat \u00b6 Hi, I\u2019m sorry but I need to leave! Thank you for the course, it was very useful. I look forward to the course evaluation. Bye! Conclusion \u00b6 I think this course worked well and I will put these suggestions into issues and discuss these.","title":"Reflection 2025-06 course"},{"location":"reflections/202506_course/#reflection__2025-06__course","text":"Lesson plan day 1 Lesson plan day 2 Evaluation Reflection day 1 Reflection day 2","title":"Reflection 2025-06 course"},{"location":"reflections/202506_course/#earlier__reflection","text":"Day Hour Self grade Comment 1 2 7 Messed up the last 5 minutes 1 3 6 Teaching in the dark 2 1 8 Feedback was better Day Hour Time for exercises 1 1 18% 1 2 49% 1 3 50% 2 1 65% 2 2 16% 2 3 0% Day Average time for exercises B (18+16+0)/3=11% R (49+50+65)/3=55% [x] Use 1 session per page in my paper logbook Ask PDC to install nano on Dardel Suggest to replace awk by sed : B will have more time for the quality of life session R thinks sed is a better follow-up after grep R thinks awk is useless Would remove the weakest session (i.e. awk ) Would give more time to the one-but-weakest session (i.e. sed )","title":"Earlier reflection"},{"location":"reflections/202506_course/#evaluation__results","text":"","title":"Evaluation results"},{"location":"reflections/202506_course/#confidence","text":"The weakest sessions were awk and sed . This matches my ideas and I already suggested to replace awk by sed . Question Mean confidence I can use awk 2.45 I can use sed 3 I can use regular expressions 3.45 I can use cut 3.64 I can write a bash script 3.82 I can make a symbolic link 3.9 I can use environment variables 3.91 I can use redirection 4 I can use tar 4 I can use grep 4.18 I can use gzip 4.18 I can use wc 4.18 I know what wc is 4.45 I can use pipe 4.64","title":"Confidence"},{"location":"reflections/202506_course/#pace","text":"good, perhaps slightly quick It is balanced. I was good I think is good but I did not code along as I saw that then I catch less information Does not apply to me, as I do not do code-alongs. today intensive and less time to do exercise Does not apply to me, as I had 5x more time for exercises. Good! just tight for the exercises Does not apply to me, as I had 5x more time for exercises. The pace was good, quite high but for this type of intermediate course I think that is not a problem. I can go back to the things I found the most interesting or difficult later. A little quick, some extra time would help particularly for Birgittes section This matches my ideas and I already suggested to replace awk by sed . The pace was excellent Ok on Monday, a bit rushed towards the end on Tuesday Does not apply to me, as I was not teaching then. Maybe it was a bit quick? I mean, it was easy to follow and understand, but then there was very little time to actually practice the exercises properly. I think it\u2019s normal given that the course was short! The little time for exercises does not apply to me, as I had 5x more time for exercises.","title":"Pace"},{"location":"reflections/202506_course/#future__topics","text":"python? why we have so many languages? what do they add ? Python is not among the courses we link to , but it is mentioned in the same newsletter this course was part of (i.e. the NAISS newsletter). Different file systems, efficient editing of text files using Vim e.g. multiline find and replace, substitution etc. File transfer is not among the courses we link to , but it is mentioned in the same newsletter this course was part of (i.e. the NAISS newsletter). Efficient vim is not among the courses at all. Suggest to add course on efficient vim I don\u00b4t think anything else can be provided same but advance and longer automating processes and more into .bashrc This is not my session. Perhaps showing real examples of these tools are used in research/scripts we may use I agree it would be (even more) interesting to look at research scripts. [x] Consider using real examples Advanced Bash and Linux of course! :) Suggest to add \u2018Command Line 301\u2019 course R and machine learning R (and machine learning in R) is not among the courses we link to . I am unsure if the R-MATLAB-Julia course is part of the NAISS newsletter. Check if R-MATLAB-Julia course is part of the NAISS newsletter Fortran course, Object-oriented-programming in Python course Suggest to add course on FORTRAN Suggest to add course on OOP programming with Python","title":"Future topics"},{"location":"reflections/202506_course/#other__comments","text":"organization, hands-on exercises, material for consultation after course, engagement ;) Great! I really liked the idea of asking questions to participants and involve them in discussions. Great! More takeaway exercises The little time for exercises does not apply to me, as I had 5x more time for exercises. Thanks Great! The structure, materials, examples and tutors were great! Easy to follow either with the code-along or with the engaging questions. Training organization was also really good. It could be a bit longer to cover more aspects but as an intro to the concepts is adequate. All the teaching aids were well prepared. Hands-on and demos were fun and right amount! I specifically liked the first parts of each day, the second part seemed a bit more rushed, but still good. This was a great course! Since I have been working with bash for a few years I had come across most of the tools previously but now I have a much better understanding of what they do and how to use them. The length of the course was good and the content was perfect for my level. I liked the variation of code-along sessions mixed with more independent work in break-out rooms. It was great that we were invited to answer questions while it was respected that not everyone might want to. I am happy that this is mentioned! [continue] I appreciated that you kept to the schedule quite strictly, and that there was a clear structure both for the whole course and for each session. Enjoyed the break out rooms and having time to work through the examples in Rich\u00e8ls material. Think that some of the general concepts could be better explained from the start but did appreciate being shown how commands work in real time through the teachers command line. I think an extra hour of time for each day could improve the course to have more time to go through the examples in Birgittes material and discuss the answers together as only having a few minutes felt sometimes rushed. I overall found this course very useful and learned a lot of new commands but maybe would appreciate some examples of how I can use these in my own bioinformatics work. I think the selected material was good and represents a lot of the useful tools in Linux and the basics of Bash. When it said Intermediate Bash, I expected though that we would do a bit more advanced things, but given the time frame it was maybe not realistic. There was a good amount of hand-on vs demonstration I think. The supplementary material was nice, the quality of them is good and I will happily refer back to them. The main problem I have with the course is awk and sed were a bit rushed (too much content in too little time) compared to bash scripting being a bit superficial. Maybe it\u2019s better to raise prerequisites a bit, so that people should know the basics of Bash before starting. Then more time could be spent on awk and sed. This matches my ideas and I already suggested to replace awk by sed . The Bash scripting being superficial is interesting feedback: is this learner one of the advanced ones, or would the regular learners agree with this too? I feel adding a new course, e.g. Command Line 301 will be a way forward here. [continue] I feel like I did not really learn how to use those any better than I knew before or see any really effective uses of them. An alternative could be an extra 3 hour session for those topics if you do not want to drop the introduction to Bash. I think both teachers were excellent and encouraged active participation, whether through breakout rooms or through encouraging exercises. The last session about QoL was also really useful and had some tips I did not know before. Thanks to everyone who organised it! The material was uneven - some parts are really good and can be reread when you are going through it yourself and reminding yourself how it was done, and other part was too sparse (lacked any theory). This was mainly a problem for the awk session which would have been easier to understand if there was a short text with some of the common commands and such. Reading a book is good, and might be how you learn well in a longer course, but it did not work for me for learning in a short course like this that should more be a help for us to do our research better. This matches my ideas and I already suggested to replace awk by sed . Else I would consider following up on this, as I am unsure if the AWK book is good enough to keep: maybe I will add the awk commands needed to my course material. I think everything was great considering how short the training event was. I would maybe separate the two days next time: instead of Mon-Tue, you could try Mon-Wed or Tue-Thu so that there is one empty day in between, and you could assign some exercises to do in that empty day. I think this would give students more time to practice what they learn in the course Interesting idea. Let\u2019s ask Suggest to add a empty day between the course days","title":"Other comments"},{"location":"reflections/202506_course/#feedback__in__chat","text":"Hi, I\u2019m sorry but I need to leave! Thank you for the course, it was very useful. I look forward to the course evaluation. Bye!","title":"Feedback in chat"},{"location":"reflections/202506_course/#conclusion","text":"I think this course worked well and I will put these suggestions into issues and discuss these.","title":"Conclusion"},{"location":"reflections/20251204/","text":"Reflection \u00b6 Date: 2025-12-04 Author: Richel Day: 1","title":"Reflection"},{"location":"reflections/20251204/#reflection","text":"Date: 2025-12-04 Author: Richel Day: 1","title":"Reflection"},{"location":"reflections/20251205/","text":"Reflection \u00b6 Date: 2025-12-05 Author: Richel Day: 2","title":"Reflection"},{"location":"reflections/20251205/#reflection","text":"Date: 2025-12-05 Author: Richel Day: 2","title":"Reflection"},{"location":"sessions/arch/","text":"Archiving \u00b6 This section will cover compressing/decompressing files and directories. We will focus on (g)zip and tar. Objectives Questions How do I compress and decompress files and directories under Linux? How do I create an archive (tarball)? Learning objectives Learn about compressing and decompressing files and directories with gzip Learn about archiving (creating a tarball) with tar Compressing and decompressing - (g)zip \u00b6 Compressing files on Linux are generally done with utilities like gzip , bzip2 , or zip . gzip \u00b6 Compression utility designed as a replacement for compress, with much better compression and no patented algorithms. The standard compression system for all GNU software. Note gzip is the recommended compression system! Common options : -d : Decompress the file(s) instead of compressing them. Shortcut is gunzip -r : Recursively compress/decompress directories and their contents. -k : Keep the original file(s) after compression. -v : Display verbose output, showing the compression ratio and other details. Examples \u00b6 Tip Code along! Use the files and folders in the directory \u201cexercises\u201d -> \u201carch\u201d Compress a file (also removes the uncompressed file) gzip afile.txt How it looks for me: bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt -rw-r--r-- 1 bbrydsoe folk 229 May 28 13 :22 afile.txt bbrydsoe@enterprise:~/exercises/arch$ gzip afile.txt bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt.gz -rw-r--r-- 1 bbrydsoe folk 180 May 28 13 :22 afile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt ls: cannot access 'afile.txt' : No such file or directory bbrydsoe@enterprise:~/exercises/arch$ The file \u201cafile.txt\u201d was compressed and the uncompressed file is removed. Uncompress a file (also removes the compressed file) gunzip afile.txt.gz or gzip -d afile.txt.gz For me it looks like this (using gunzip): bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt.gz -rw-r--r-- 1 bbrydsoe folk 180 May 28 13 :22 afile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ gunzip afile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt -rw-r--r-- 1 bbrydsoe folk 229 May 28 13 :22 afile.txt bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt.gz ls: cannot access 'afile.txt.gz' : No such file or directory bbrydsoe@enterprise:~/exercises/arch$ Compress a file (and keep the uncompressed file) gzip -k afile.txt How it looks for me: bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt -rw-r--r-- 1 bbrydsoe folk 229 May 28 13 :22 afile.txt bbrydsoe@enterprise:~/exercises/arch$ gzip -k afile.txt bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt -rw-r--r-- 1 bbrydsoe folk 229 May 28 13 :22 afile.txt bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt.gz -rw-r--r-- 1 bbrydsoe folk 180 May 28 13 :22 afile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ Compress all files in a directory bbrydsoe@enterprise:~/exercises/arch$ ls dir2 dir4 myfile-new.txt testfile3.txt testfile4.txt bbrydsoe@enterprise:~/exercises/arch$ gzip -r dir2 bbrydsoe@enterprise:~/exercises/arch$ ls dir2 dir4 myfile-new.txt.gz testfile3.txt.gz testfile4.txt.gz bbrydsoe@enterprise:~/exercises/arch$ ls dir2/dir4/ bfile.txt.gz cfile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ gunzip -r dir2 would then un-gzip all the files again. Warning gzip does not archive the files into one file, just compress them! For archiving files, tar is your friend - often in combination with gzip . More about that soon! bzip (optional) \u00b6 bzip offers strong, lossless data compressor based on the Burrows-Wheeler transform. Also available as a library. May compress better than gzip, but is slower. Examples \u00b6 We are not going to cover bzip more than to briefly give the most common usage. Compress a file (also removes the uncompressed file) bzip2 afile.txt Uncompress a file (also removes the compressed file) bunzip2 afile.txt.bz2 zip (optional) \u00b6 zip is a simple compression and file packaging utility. Note The maximum size limit of a zip file is 4GB and if this size limit is exceeded, the file becomes prone to corruption. This further leads to failure of the extraction process and inaccessibility of your data. Examples \u00b6 Hint Code along! Again, use the files in \u201cexercises\u201d -> \u201carch\u201d Compressing afile.txt zip afile.zip afile.txt Output: bbrydsoe@enterprise:~/exercises/arch$ zip afile.zip afile.txt adding: afile.txt ( deflated 34 % ) Uncompressing afile.zip If the file already exists, zip will ask if you want to replace or rename unzip afile.zip Output: bbrydsoe@enterprise:~/exercises/arch$ unzip afile.zip Archive: afile.zip replace afile.txt? [ y ] es, [ n ] o, [ A ] ll, [ N ] one, [ r ] ename: r new name: afile-copy.txt inflating: afile-copy.txt Compress all files in one directory to a single archive file zip -r dir1.zip dir1/ Output: bbrydsoe@enterprise:~/exercises/arch$ zip -r dir1.zip dir1 adding: dir1/ ( stored 0 % ) adding: dir1/testfile ( stored 0 % ) adding: dir1/testfile.txt ( stored 0 % ) adding: dir1/testfile2.txt ( deflated 2 % ) bbrydsoe@enterprise:~/exercises/arch$ ls dir1.zip dir1.zip Compress all files of a certain type in the current directory (and in directories under this) to a single archive file In this example case for all .c files zip -r my_c_files.zip . -i \\* .c Output: bbrydsoe@enterprise:~/exercises/arch$ zip -r my_c_files.zip . -i \\* .c adding: morefile.c ( stored 0 % ) adding: C/Adding2.c ( deflated 31 % ) adding: C/Greeting.c ( stored 0 % ) adding: C/hello.c ( stored 0 % ) adding: C/mpi_greeting.c ( deflated 35 % ) adding: C/mpi_hello.c ( deflated 35 % ) adding: C/mpi_hi.c ( deflated 36 % ) adding: C/Mult2.c ( deflated 33 % ) adding: C/omp_hello.c ( deflated 58 % ) Archiving - tar \u00b6 Archiving is generally done with tar . This program saves many files together into a single archive file (concatenates them), and it also restores individual files from the archive. Automatic archive compression/decompression options exists (with various different compression utilities), as well as special features that allow tar to be used for incremental and full backups. The command tar --help will give the format (defaults to gnu). This is generally only important for files larger than 8 GB. tar was originally developed for magnetic tape storage \u2013 reading and writing data for a sequential I/O device with no file system, and the name is short for the format description \u201ctape archive\u201d. Note A tarball is a commonly used name to refer to an archive file in the tar (Tape Archive) format. A tarball can be compressed with something like gzip or bzip2 . There are options/flags to do this automatically with tar . Syntax \u00b6 tar [ -options ] <name of the tar archive> [ files or directories which to add into archive ] Basic options \u00b6 -c, \u2013create - create a new archive -a, \u2013auto-compress - additionally compress the archive with a compressor which will be automatically determined by the file name extension of the archive. If the archive\u2019s name ends with .tar.gz then use gzip, if .tar.xz then use xz, *.tar.zst for Zstandard etc. -r, \u2013append - append files to the end of an archive -x, \u2013extract, \u2013get - extract files from an archive -f, \u2013file - specify the archive\u2019s name -t, \u2013list - show a list of files and folders in the archive -v, \u2013verbose - show a list of processed files Examples \u00b6 Hint Code along! Again use the files and folders under \u201cexercises\u201d -> \u201carch\u201d Generate a tarball tar -cvf arch.tar arch/ Output: bbrydsoe@enterprise:~/exercises/arch$ cd .. bbrydsoe@enterprise:~/exercises$ tar -cvf arch.tar arch/ arch/ arch/myfile.txt arch/thisfile.txt arch/morefile.c arch/dir1/ arch/dir1/testfile arch/dir1/testfile.txt arch/dir1/testfile2.txt arch/dir2/ arch/dir2/dir4/ arch/dir2/dir4/bfile.txt arch/dir2/dir4/cfile.txt arch/dir2/testfile3.txt arch/dir2/myfile-new.txt arch/dir2/testfile4.txt arch/dir3/ arch/dir3/dfile.txt arch/dir3/efile.txt arch/dir3/ffile.txt arch/afile.txt arch/afile.zip arch/afile-copy.txt arch/dir1.zip arch/C/ arch/C/Adding2.c arch/C/Greeting.c arch/C/hello.c arch/C/mpi_greeting.c arch/C/mpi_hello.c arch/C/mpi_hi.c arch/C/Mult2.c arch/C/omp_hello.c arch/my_c_files.zip bbrydsoe@enterprise:~/exercises$ ls -al arch.tar -rw-r--r-- 1 bbrydsoe folk 40960 May 28 14 :27 arch.tar Extracting the files from a tarball tar -xvf arch.tar Warning! If there is already a directory with the same name in the directory you do this, it will overwrite without asking! Generate a tarball and compress it with gzip tar -zcvf arch.tar.gz arch/ Output: bbrydsoe@enterprise:~/exercises$ tar -zcvf arch.tar.gz arch/ arch/ arch/dir1/ arch/dir1/testfile arch/dir1/testfile.txt arch/dir1/testfile2.txt arch/dir2/ arch/dir2/dir4/ arch/dir2/dir4/bfile.txt arch/dir2/dir4/cfile.txt arch/dir2/testfile3.txt arch/dir2/myfile-new.txt arch/dir2/testfile4.txt arch/dir3/ arch/dir3/dfile.txt arch/dir3/efile.txt arch/dir3/ffile.txt arch/C/ arch/C/Adding2.c arch/C/Greeting.c arch/C/hello.c arch/C/mpi_greeting.c arch/C/mpi_hello.c arch/C/mpi_hi.c arch/C/Mult2.c arch/C/omp_hello.c arch/myfile.txt arch/thisfile.txt arch/morefile.c arch/afile.txt arch/afile.zip arch/afile-copy.txt arch/dir1.zip arch/my_c_files.zip bbrydsoe@enterprise:~/exercises$ ls -la arch.tar.gz -rw-r--r-- 1 bbrydsoe folk 4500 May 28 14 :44 arch.tar.gz Compared to the size of the uncompressed tarball: bbrydsoe@enterprise:~/exercises$ ls -al arch.tar -rw-r--r-- 1 bbrydsoe folk 40960 May 28 14 :27 arch.tar Uncompressing and extracting files from a tarball tar -zxvf arch.tar.gz Warning! If there is already a directory with the same name in the directory you do this, it will overwrite without asking! Summary \u00b6 Keypoints we learned about gzip, bzip2, and zip we learned about tarballs and compressed tarballs","title":"Archiving/compressing data"},{"location":"sessions/arch/#archiving","text":"This section will cover compressing/decompressing files and directories. We will focus on (g)zip and tar. Objectives Questions How do I compress and decompress files and directories under Linux? How do I create an archive (tarball)? Learning objectives Learn about compressing and decompressing files and directories with gzip Learn about archiving (creating a tarball) with tar","title":"Archiving"},{"location":"sessions/arch/#compressing__and__decompressing__-__gzip","text":"Compressing files on Linux are generally done with utilities like gzip , bzip2 , or zip .","title":"Compressing and decompressing - (g)zip"},{"location":"sessions/arch/#gzip","text":"Compression utility designed as a replacement for compress, with much better compression and no patented algorithms. The standard compression system for all GNU software. Note gzip is the recommended compression system! Common options : -d : Decompress the file(s) instead of compressing them. Shortcut is gunzip -r : Recursively compress/decompress directories and their contents. -k : Keep the original file(s) after compression. -v : Display verbose output, showing the compression ratio and other details.","title":"gzip"},{"location":"sessions/arch/#examples","text":"Tip Code along! Use the files and folders in the directory \u201cexercises\u201d -> \u201carch\u201d Compress a file (also removes the uncompressed file) gzip afile.txt How it looks for me: bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt -rw-r--r-- 1 bbrydsoe folk 229 May 28 13 :22 afile.txt bbrydsoe@enterprise:~/exercises/arch$ gzip afile.txt bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt.gz -rw-r--r-- 1 bbrydsoe folk 180 May 28 13 :22 afile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt ls: cannot access 'afile.txt' : No such file or directory bbrydsoe@enterprise:~/exercises/arch$ The file \u201cafile.txt\u201d was compressed and the uncompressed file is removed. Uncompress a file (also removes the compressed file) gunzip afile.txt.gz or gzip -d afile.txt.gz For me it looks like this (using gunzip): bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt.gz -rw-r--r-- 1 bbrydsoe folk 180 May 28 13 :22 afile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ gunzip afile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt -rw-r--r-- 1 bbrydsoe folk 229 May 28 13 :22 afile.txt bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt.gz ls: cannot access 'afile.txt.gz' : No such file or directory bbrydsoe@enterprise:~/exercises/arch$ Compress a file (and keep the uncompressed file) gzip -k afile.txt How it looks for me: bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt -rw-r--r-- 1 bbrydsoe folk 229 May 28 13 :22 afile.txt bbrydsoe@enterprise:~/exercises/arch$ gzip -k afile.txt bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt -rw-r--r-- 1 bbrydsoe folk 229 May 28 13 :22 afile.txt bbrydsoe@enterprise:~/exercises/arch$ ls -la afile.txt.gz -rw-r--r-- 1 bbrydsoe folk 180 May 28 13 :22 afile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ Compress all files in a directory bbrydsoe@enterprise:~/exercises/arch$ ls dir2 dir4 myfile-new.txt testfile3.txt testfile4.txt bbrydsoe@enterprise:~/exercises/arch$ gzip -r dir2 bbrydsoe@enterprise:~/exercises/arch$ ls dir2 dir4 myfile-new.txt.gz testfile3.txt.gz testfile4.txt.gz bbrydsoe@enterprise:~/exercises/arch$ ls dir2/dir4/ bfile.txt.gz cfile.txt.gz bbrydsoe@enterprise:~/exercises/arch$ gunzip -r dir2 would then un-gzip all the files again. Warning gzip does not archive the files into one file, just compress them! For archiving files, tar is your friend - often in combination with gzip . More about that soon!","title":"Examples"},{"location":"sessions/arch/#bzip__optional","text":"bzip offers strong, lossless data compressor based on the Burrows-Wheeler transform. Also available as a library. May compress better than gzip, but is slower.","title":"bzip (optional)"},{"location":"sessions/arch/#examples_1","text":"We are not going to cover bzip more than to briefly give the most common usage. Compress a file (also removes the uncompressed file) bzip2 afile.txt Uncompress a file (also removes the compressed file) bunzip2 afile.txt.bz2","title":"Examples"},{"location":"sessions/arch/#zip__optional","text":"zip is a simple compression and file packaging utility. Note The maximum size limit of a zip file is 4GB and if this size limit is exceeded, the file becomes prone to corruption. This further leads to failure of the extraction process and inaccessibility of your data.","title":"zip (optional)"},{"location":"sessions/arch/#examples_2","text":"Hint Code along! Again, use the files in \u201cexercises\u201d -> \u201carch\u201d Compressing afile.txt zip afile.zip afile.txt Output: bbrydsoe@enterprise:~/exercises/arch$ zip afile.zip afile.txt adding: afile.txt ( deflated 34 % ) Uncompressing afile.zip If the file already exists, zip will ask if you want to replace or rename unzip afile.zip Output: bbrydsoe@enterprise:~/exercises/arch$ unzip afile.zip Archive: afile.zip replace afile.txt? [ y ] es, [ n ] o, [ A ] ll, [ N ] one, [ r ] ename: r new name: afile-copy.txt inflating: afile-copy.txt Compress all files in one directory to a single archive file zip -r dir1.zip dir1/ Output: bbrydsoe@enterprise:~/exercises/arch$ zip -r dir1.zip dir1 adding: dir1/ ( stored 0 % ) adding: dir1/testfile ( stored 0 % ) adding: dir1/testfile.txt ( stored 0 % ) adding: dir1/testfile2.txt ( deflated 2 % ) bbrydsoe@enterprise:~/exercises/arch$ ls dir1.zip dir1.zip Compress all files of a certain type in the current directory (and in directories under this) to a single archive file In this example case for all .c files zip -r my_c_files.zip . -i \\* .c Output: bbrydsoe@enterprise:~/exercises/arch$ zip -r my_c_files.zip . -i \\* .c adding: morefile.c ( stored 0 % ) adding: C/Adding2.c ( deflated 31 % ) adding: C/Greeting.c ( stored 0 % ) adding: C/hello.c ( stored 0 % ) adding: C/mpi_greeting.c ( deflated 35 % ) adding: C/mpi_hello.c ( deflated 35 % ) adding: C/mpi_hi.c ( deflated 36 % ) adding: C/Mult2.c ( deflated 33 % ) adding: C/omp_hello.c ( deflated 58 % )","title":"Examples"},{"location":"sessions/arch/#archiving__-__tar","text":"Archiving is generally done with tar . This program saves many files together into a single archive file (concatenates them), and it also restores individual files from the archive. Automatic archive compression/decompression options exists (with various different compression utilities), as well as special features that allow tar to be used for incremental and full backups. The command tar --help will give the format (defaults to gnu). This is generally only important for files larger than 8 GB. tar was originally developed for magnetic tape storage \u2013 reading and writing data for a sequential I/O device with no file system, and the name is short for the format description \u201ctape archive\u201d. Note A tarball is a commonly used name to refer to an archive file in the tar (Tape Archive) format. A tarball can be compressed with something like gzip or bzip2 . There are options/flags to do this automatically with tar .","title":"Archiving - tar"},{"location":"sessions/arch/#syntax","text":"tar [ -options ] <name of the tar archive> [ files or directories which to add into archive ]","title":"Syntax"},{"location":"sessions/arch/#basic__options","text":"-c, \u2013create - create a new archive -a, \u2013auto-compress - additionally compress the archive with a compressor which will be automatically determined by the file name extension of the archive. If the archive\u2019s name ends with .tar.gz then use gzip, if .tar.xz then use xz, *.tar.zst for Zstandard etc. -r, \u2013append - append files to the end of an archive -x, \u2013extract, \u2013get - extract files from an archive -f, \u2013file - specify the archive\u2019s name -t, \u2013list - show a list of files and folders in the archive -v, \u2013verbose - show a list of processed files","title":"Basic options"},{"location":"sessions/arch/#examples_3","text":"Hint Code along! Again use the files and folders under \u201cexercises\u201d -> \u201carch\u201d Generate a tarball tar -cvf arch.tar arch/ Output: bbrydsoe@enterprise:~/exercises/arch$ cd .. bbrydsoe@enterprise:~/exercises$ tar -cvf arch.tar arch/ arch/ arch/myfile.txt arch/thisfile.txt arch/morefile.c arch/dir1/ arch/dir1/testfile arch/dir1/testfile.txt arch/dir1/testfile2.txt arch/dir2/ arch/dir2/dir4/ arch/dir2/dir4/bfile.txt arch/dir2/dir4/cfile.txt arch/dir2/testfile3.txt arch/dir2/myfile-new.txt arch/dir2/testfile4.txt arch/dir3/ arch/dir3/dfile.txt arch/dir3/efile.txt arch/dir3/ffile.txt arch/afile.txt arch/afile.zip arch/afile-copy.txt arch/dir1.zip arch/C/ arch/C/Adding2.c arch/C/Greeting.c arch/C/hello.c arch/C/mpi_greeting.c arch/C/mpi_hello.c arch/C/mpi_hi.c arch/C/Mult2.c arch/C/omp_hello.c arch/my_c_files.zip bbrydsoe@enterprise:~/exercises$ ls -al arch.tar -rw-r--r-- 1 bbrydsoe folk 40960 May 28 14 :27 arch.tar Extracting the files from a tarball tar -xvf arch.tar Warning! If there is already a directory with the same name in the directory you do this, it will overwrite without asking! Generate a tarball and compress it with gzip tar -zcvf arch.tar.gz arch/ Output: bbrydsoe@enterprise:~/exercises$ tar -zcvf arch.tar.gz arch/ arch/ arch/dir1/ arch/dir1/testfile arch/dir1/testfile.txt arch/dir1/testfile2.txt arch/dir2/ arch/dir2/dir4/ arch/dir2/dir4/bfile.txt arch/dir2/dir4/cfile.txt arch/dir2/testfile3.txt arch/dir2/myfile-new.txt arch/dir2/testfile4.txt arch/dir3/ arch/dir3/dfile.txt arch/dir3/efile.txt arch/dir3/ffile.txt arch/C/ arch/C/Adding2.c arch/C/Greeting.c arch/C/hello.c arch/C/mpi_greeting.c arch/C/mpi_hello.c arch/C/mpi_hi.c arch/C/Mult2.c arch/C/omp_hello.c arch/myfile.txt arch/thisfile.txt arch/morefile.c arch/afile.txt arch/afile.zip arch/afile-copy.txt arch/dir1.zip arch/my_c_files.zip bbrydsoe@enterprise:~/exercises$ ls -la arch.tar.gz -rw-r--r-- 1 bbrydsoe folk 4500 May 28 14 :44 arch.tar.gz Compared to the size of the uncompressed tarball: bbrydsoe@enterprise:~/exercises$ ls -al arch.tar -rw-r--r-- 1 bbrydsoe folk 40960 May 28 14 :27 arch.tar Uncompressing and extracting files from a tarball tar -zxvf arch.tar.gz Warning! If there is already a directory with the same name in the directory you do this, it will overwrite without asking!","title":"Examples"},{"location":"sessions/arch/#summary","text":"Keypoints we learned about gzip, bzip2, and zip we learned about tarballs and compressed tarballs","title":"Summary"},{"location":"sessions/env_vars/","text":"Environment variables \u00b6 Environment variables store data that is used by the operating system and other programs. Some are intrinsic to the operating system, some for a specific program/library/programming language, and some are created by the user. The variables can both be used in scripts and on the command line. Usually you reference them by putting a special symbol in front of or around the variable name. By convention, environment variable names are in UPPER CASE. Examples : $HOME Your home directory $PWD This variable points to your current directory $LD_LIBRARY_PATH a colon-separated list of directories that the dynamic linker should search for shared objects before searching in any other directories $OMP_NUM_THREADS Number of OpenMP threads $PYTHONPATH Path to the directory where your Python libraries and packages are installed To see the content of an environment variable named ENVIRONMENT-VARIABLE echo $ENVIRONMENT -VARIABLE Tip You will get a long list of all environment variables currently set with the command: env You could also use printenv In their default state they work the same. The difference is twofold. You can use printenv to request the value of individual variables: $ printenv VARIABLE You can use env to modify the environment that programs run in by passing a set of variable definitions into a command like this: $ env VARIABLE = \"value\" <command_to_run> <command_options> Some environment variables need to be exported in order to be used This is how you set the environment variable VARIABLE to value: For the bash (and related) shells: export VARIABLE = value For csh and related shells: setenv VARIABLE value You can create your own variables to use, for instance in scripts . Creating your own variable I create a variable called MINE and set it to /usr/bin/gcc export MINE = /usr/bin/gcc Check it is set: echo $MINE You can now (until you start a new session) use $MINE instead of gcc: $ $MINE hello.c $ ls a.out a.out $ ./a.out Hello World! $ Examples \u00b6 See the content of $PATH $ echo $PATH Setting the number of OpenMP threads to 8 in bash export OMP_NUM_THREADS = 8 !! note \u201cMore useful example of creating your own variable\u201d Assume you have a script you run in a different directory than where you have the datafiles. You could then use an environment variable to give the path to the data directory instead of each time writing the full path: ```bash $ export DATAPATH=/home/bbrydsoe/project/dataset1/ ``` Then you can refer to that directory with $DATAPATH in your script. Adding a new path to $LD_LIBRARY_PATH export LD_LIBRARY_PATH = $LD_LIBRARY_PATH :/your/custom/path/ Warning The environment variable set this way only retains the value you have set for the duration of the session . When you open a new terminal window or login again, you need to set it again . To avoid that, add the environment variable to your .bashrc file, but only do so if it should truly be persistent across many sessions (like adding a new directory to search to LD_LIBRARY_PATH for instance). Quickly add a new directory to LD_LIBRARY_PATH in your .bashrc echo \"export LD_LIBRARY_PATH= $LD_LIBRARY_PATH :/your/custom/path/\" >> ~/.bashrc Change /your/custom/path/ to the actual path to the directory for your library. Exercise \u00b6 Run env to see the environment variables that are set at your computer Use echo to see the content of $PWD - try change to another directory and run it again. Create your own variable. Set it to something (export) and use echo to see that it has the right value. Use printenv to tell you the value of an environment variable. Summary \u00b6 Keypoints environment variables are used to store data that is used by the operating system and other programs Some common environment variables are: $HOME Your home directory $PWD This variable points to your current directory $LD_LIBRARY_PATH a colon-separated list of directories that the dynamic linker should search for shared objects before searching in any other directories $OMP_NUM_THREADS Number of OpenMP threads $PYTHONPATH Path to the directory where your Python libraries and packages are installed You can create own environment variables env is useful printenv is useful","title":"Environment variables"},{"location":"sessions/env_vars/#environment__variables","text":"Environment variables store data that is used by the operating system and other programs. Some are intrinsic to the operating system, some for a specific program/library/programming language, and some are created by the user. The variables can both be used in scripts and on the command line. Usually you reference them by putting a special symbol in front of or around the variable name. By convention, environment variable names are in UPPER CASE. Examples : $HOME Your home directory $PWD This variable points to your current directory $LD_LIBRARY_PATH a colon-separated list of directories that the dynamic linker should search for shared objects before searching in any other directories $OMP_NUM_THREADS Number of OpenMP threads $PYTHONPATH Path to the directory where your Python libraries and packages are installed To see the content of an environment variable named ENVIRONMENT-VARIABLE echo $ENVIRONMENT -VARIABLE Tip You will get a long list of all environment variables currently set with the command: env You could also use printenv In their default state they work the same. The difference is twofold. You can use printenv to request the value of individual variables: $ printenv VARIABLE You can use env to modify the environment that programs run in by passing a set of variable definitions into a command like this: $ env VARIABLE = \"value\" <command_to_run> <command_options> Some environment variables need to be exported in order to be used This is how you set the environment variable VARIABLE to value: For the bash (and related) shells: export VARIABLE = value For csh and related shells: setenv VARIABLE value You can create your own variables to use, for instance in scripts . Creating your own variable I create a variable called MINE and set it to /usr/bin/gcc export MINE = /usr/bin/gcc Check it is set: echo $MINE You can now (until you start a new session) use $MINE instead of gcc: $ $MINE hello.c $ ls a.out a.out $ ./a.out Hello World! $","title":"Environment variables"},{"location":"sessions/env_vars/#examples","text":"See the content of $PATH $ echo $PATH Setting the number of OpenMP threads to 8 in bash export OMP_NUM_THREADS = 8 !! note \u201cMore useful example of creating your own variable\u201d Assume you have a script you run in a different directory than where you have the datafiles. You could then use an environment variable to give the path to the data directory instead of each time writing the full path: ```bash $ export DATAPATH=/home/bbrydsoe/project/dataset1/ ``` Then you can refer to that directory with $DATAPATH in your script. Adding a new path to $LD_LIBRARY_PATH export LD_LIBRARY_PATH = $LD_LIBRARY_PATH :/your/custom/path/ Warning The environment variable set this way only retains the value you have set for the duration of the session . When you open a new terminal window or login again, you need to set it again . To avoid that, add the environment variable to your .bashrc file, but only do so if it should truly be persistent across many sessions (like adding a new directory to search to LD_LIBRARY_PATH for instance). Quickly add a new directory to LD_LIBRARY_PATH in your .bashrc echo \"export LD_LIBRARY_PATH= $LD_LIBRARY_PATH :/your/custom/path/\" >> ~/.bashrc Change /your/custom/path/ to the actual path to the directory for your library.","title":"Examples"},{"location":"sessions/env_vars/#exercise","text":"Run env to see the environment variables that are set at your computer Use echo to see the content of $PWD - try change to another directory and run it again. Create your own variable. Set it to something (export) and use echo to see that it has the right value. Use printenv to tell you the value of an environment variable.","title":"Exercise"},{"location":"sessions/env_vars/#summary","text":"Keypoints environment variables are used to store data that is used by the operating system and other programs Some common environment variables are: $HOME Your home directory $PWD This variable points to your current directory $LD_LIBRARY_PATH a colon-separated list of directories that the dynamic linker should search for shared objects before searching in any other directories $OMP_NUM_THREADS Number of OpenMP threads $PYTHONPATH Path to the directory where your Python libraries and packages are installed You can create own environment variables env is useful printenv is useful","title":"Summary"},{"location":"sessions/intro/","text":"Introduction \u00b6 Welcome page and syllabus: https://uppmax.github.io/linux-command-line-201/ Also link at the House symbol at the top of the page. Most of the commands you learn in this course is agnostic and works on any Linux/Unix like system. Most HPC centers has bash as default. There are several reasons, but one is that it is what is compatible with SLURM - the batch scheduler used at most centers in Sweden. bash is also good for scripting. For many commands it does not matter which shell you are using, but there are several where it is relevant, particularly for scripting. We will therefore be using bash for this course. Important stuff \u00b6 We have a page with important information: https://umeauniversity.sharepoint.com/:w:/s/HPC2N630/ERcoEh5ywTFPjmdLmPvcDZoBdkWwHvAMAkyr7drLkxhD8g The Question and Answer page for questions to the instructors during the course: https://umeauniversity.sharepoint.com/:w:/s/HPC2N630/EU_ESLxmgMVPiNfwmoTF9LABFPGAgPtCkNs2GaTUKlbSlA Exercises \u00b6 The exercises are mostly on the pages, but you need some files to work with for several of the exercises. These files are in the \u201cexercises.tar.gz\u201d tarball. You get it with: wget https://github.com/UPPMAX/linux-command-line-201/raw/refs/heads/main/exercises.tar.gz Then you unpack it with: tar -zxvf exercises.tar.gz Evaluation \u00b6 This course is running for the first time and we would very much like some input on how we did so we can develop and improve the course. Here is the link to the evaluation survey: https://forms.office.com/e/dNviziEA6c","title":"Introduction"},{"location":"sessions/intro/#introduction","text":"Welcome page and syllabus: https://uppmax.github.io/linux-command-line-201/ Also link at the House symbol at the top of the page. Most of the commands you learn in this course is agnostic and works on any Linux/Unix like system. Most HPC centers has bash as default. There are several reasons, but one is that it is what is compatible with SLURM - the batch scheduler used at most centers in Sweden. bash is also good for scripting. For many commands it does not matter which shell you are using, but there are several where it is relevant, particularly for scripting. We will therefore be using bash for this course.","title":"Introduction"},{"location":"sessions/intro/#important__stuff","text":"We have a page with important information: https://umeauniversity.sharepoint.com/:w:/s/HPC2N630/ERcoEh5ywTFPjmdLmPvcDZoBdkWwHvAMAkyr7drLkxhD8g The Question and Answer page for questions to the instructors during the course: https://umeauniversity.sharepoint.com/:w:/s/HPC2N630/EU_ESLxmgMVPiNfwmoTF9LABFPGAgPtCkNs2GaTUKlbSlA","title":"Important stuff"},{"location":"sessions/intro/#exercises","text":"The exercises are mostly on the pages, but you need some files to work with for several of the exercises. These files are in the \u201cexercises.tar.gz\u201d tarball. You get it with: wget https://github.com/UPPMAX/linux-command-line-201/raw/refs/heads/main/exercises.tar.gz Then you unpack it with: tar -zxvf exercises.tar.gz","title":"Exercises"},{"location":"sessions/intro/#evaluation","text":"This course is running for the first time and we would very much like some input on how we did so we can develop and improve the course. Here is the link to the evaluation survey: https://forms.office.com/e/dNviziEA6c","title":"Evaluation"},{"location":"sessions/pipe/","text":"Pipe \u00b6 Learning objectives learn about the operator pipe when to use it how to use it try some examples with pipe Note The operator pipe (or pipeline) is used to chain commands; i.e. pipes are used when you want to take the output of one command and use it as input for another command. It is symbolized by a | between the commands. This is often called \u201cto pass output to another command\u201d. In many cases it is possible to do the same with an intermediate file (or more), but it is often better to just combine the commands with one or more pipes. Pipes are very useful, and will be used in several of the following sections! Syntax \u00b6 Using a pipe between two or more commands look like this: < command 1 > | < command 2 > | < command 3 > | ... | < command N> Some commands \u00b6 We will use a number of Linux commands in this section for illustrating how pipes work. They were all covered in the Basic Linux course and are listed in prerequisites, but here is a brief reminder of their function: Click to reveal less : forward and backward navigation and also has search options. Usage less FILE . Exit with: q more : forward navigation and limited backward navigation in a file named FILE. Usage: more FILE . Exit with: q cat : a tool for file-related operations (view, concatenate, create, copy, merge, and manipulate file contents). Usage: cat [option] FILE where option is various optional options find : The find command is used for file and directory search. You can search by name, size, modification time, or content. Usage: find [path] [options] [expression] where common options are -type f : only search for files -type d : only search for directories -name NAME : only search for files with a specific name NAME or pattern -size [+/-]n : Searches for files based on size. +n finds larger files, -n finds smaller files. \u2018n\u2018 measures size in characters. -mtime n : Finds files based on modification time. n represents the number of days ago. -exec command {} \\; : Executes a command on each file found. sort : The sort command is used in Linux to print the output of a file in given order. -n : compare according to string numerical value -f : ignore case -b : ignore leading blanks -k keydef : by size where keydef is start and stop position -r : reverse head : prints the first lines of a file. Usage: head -n FILE tail : prints the lines at the end of a file. Usage: tail -n FILE echo : displays lines of text or strings that are passed as arguments. Usage: echo [option] [string] tee : Copy standard input to each file and also to standard output. Usage: tee [option] ... [file1] [file2] ... Examples of piping \u00b6 Hint Type along! To run the examples, go to the \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d directory where there are files that are suitable to run these examples on. Using one pipe: List all files and directories and give as input to more This is useful if there are many files in the directory and you would like to see them/scroll through them. $ ls -l | more Output: Using one pipe: Sort a list of files by size $ ls -l | sort -k 5 Of course, sorting files by size could also be done with ls -l -S but then you would have less control of how it was sorted (largest file first, sorted in lexicographical order). If you want to sort file size in reverse order you can do it like this: $ ls -l -S | sort -k 5 n Using one pipe: echo and sort I write a couple lines which I echo, then I sort the output $ echo \"This is a line of text, which I am writing > I am continuing to write another line > and another line\" | sort It will look like this: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ echo \"This is a line of text, which I am writing > I am continuing to write another line > and another line\" | sort and another line I am continuing to write another line This is a line of text, which I am writing Using two pipes: head and tail to print lines in a specific range in a file $ cat newfile.txt | head -3 | tail -2 Output (also showing the output of cat itself so you can see the file content): Using two pipes: head and tail to print lines of the output from the ls command ls | head -3 | tail -1 Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ ls ada fil4.txt myfile0.txt thisfile0.txt thisfile7.txt afa file.c myfile1.txt thisfile1.txt thisfile8.txt aja file.dat myfile2.txt thisfile2.txt thisfile9.txt ama file_filtered.dat myfile3.txt thisfile3.txt thisfile.txt amina file.txt myfiles.txt thisfile4.txt fil2.txt fil.txt newfile.txt thisfile5.txt fil3.txt image numbers.txt thisfile6.txt bbrydsoe@enterprise:~/exercises/piping-wc-cut$ ls | head -3 | tail -1 aja bbrydsoe@enterprise:~/exercises/piping-wc-cut$ Using two pipes: sort the output of tail on ls $ ls -l | tail -14 | sort -n Using more pipes: find, sort, tail Here I find all the files with a name with suffix .txt, sort them, and then pick the last 4 in the sorted list: find . -type f -name \"*.txt\" | sort | tail -4 Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ find . -type f -name \"*.txt\" | sort | tail -4 ./thisfile7.txt ./thisfile8.txt ./thisfile9.txt ./thisfile.txt Using more pipes: find, sort, head, tee Here I find all the files with a name with suffix .txt, sort them, and then pick the first 4 in the sorted list, which I then use tee to send to a file (named list.txt) and also to output: find . -type f -name \"*.txt\" | sort | head -4 | tee list.txt Exercise \u00b6 Sort (string numerical, in reverse) files ending in .txt Print the 4 first lines of the list of files ending in .txt Print the last 5 lines of the list of files ending in .txt and sort them, then print the first line of the output Use echo to output 5 lines you write then use tail to print the last line. Summary \u00b6 As you have seen, pipe is a very useful operator, one which we will meet again in the later sections, combined with many commands and in scripts. Keypoints we learned about pipe we tried using one or more pipes to combine commands","title":"Linux pipe"},{"location":"sessions/pipe/#pipe","text":"Learning objectives learn about the operator pipe when to use it how to use it try some examples with pipe Note The operator pipe (or pipeline) is used to chain commands; i.e. pipes are used when you want to take the output of one command and use it as input for another command. It is symbolized by a | between the commands. This is often called \u201cto pass output to another command\u201d. In many cases it is possible to do the same with an intermediate file (or more), but it is often better to just combine the commands with one or more pipes. Pipes are very useful, and will be used in several of the following sections!","title":"Pipe"},{"location":"sessions/pipe/#syntax","text":"Using a pipe between two or more commands look like this: < command 1 > | < command 2 > | < command 3 > | ... | < command N>","title":"Syntax"},{"location":"sessions/pipe/#some__commands","text":"We will use a number of Linux commands in this section for illustrating how pipes work. They were all covered in the Basic Linux course and are listed in prerequisites, but here is a brief reminder of their function: Click to reveal less : forward and backward navigation and also has search options. Usage less FILE . Exit with: q more : forward navigation and limited backward navigation in a file named FILE. Usage: more FILE . Exit with: q cat : a tool for file-related operations (view, concatenate, create, copy, merge, and manipulate file contents). Usage: cat [option] FILE where option is various optional options find : The find command is used for file and directory search. You can search by name, size, modification time, or content. Usage: find [path] [options] [expression] where common options are -type f : only search for files -type d : only search for directories -name NAME : only search for files with a specific name NAME or pattern -size [+/-]n : Searches for files based on size. +n finds larger files, -n finds smaller files. \u2018n\u2018 measures size in characters. -mtime n : Finds files based on modification time. n represents the number of days ago. -exec command {} \\; : Executes a command on each file found. sort : The sort command is used in Linux to print the output of a file in given order. -n : compare according to string numerical value -f : ignore case -b : ignore leading blanks -k keydef : by size where keydef is start and stop position -r : reverse head : prints the first lines of a file. Usage: head -n FILE tail : prints the lines at the end of a file. Usage: tail -n FILE echo : displays lines of text or strings that are passed as arguments. Usage: echo [option] [string] tee : Copy standard input to each file and also to standard output. Usage: tee [option] ... [file1] [file2] ...","title":"Some commands"},{"location":"sessions/pipe/#examples__of__piping","text":"Hint Type along! To run the examples, go to the \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d directory where there are files that are suitable to run these examples on. Using one pipe: List all files and directories and give as input to more This is useful if there are many files in the directory and you would like to see them/scroll through them. $ ls -l | more Output: Using one pipe: Sort a list of files by size $ ls -l | sort -k 5 Of course, sorting files by size could also be done with ls -l -S but then you would have less control of how it was sorted (largest file first, sorted in lexicographical order). If you want to sort file size in reverse order you can do it like this: $ ls -l -S | sort -k 5 n Using one pipe: echo and sort I write a couple lines which I echo, then I sort the output $ echo \"This is a line of text, which I am writing > I am continuing to write another line > and another line\" | sort It will look like this: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ echo \"This is a line of text, which I am writing > I am continuing to write another line > and another line\" | sort and another line I am continuing to write another line This is a line of text, which I am writing Using two pipes: head and tail to print lines in a specific range in a file $ cat newfile.txt | head -3 | tail -2 Output (also showing the output of cat itself so you can see the file content): Using two pipes: head and tail to print lines of the output from the ls command ls | head -3 | tail -1 Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ ls ada fil4.txt myfile0.txt thisfile0.txt thisfile7.txt afa file.c myfile1.txt thisfile1.txt thisfile8.txt aja file.dat myfile2.txt thisfile2.txt thisfile9.txt ama file_filtered.dat myfile3.txt thisfile3.txt thisfile.txt amina file.txt myfiles.txt thisfile4.txt fil2.txt fil.txt newfile.txt thisfile5.txt fil3.txt image numbers.txt thisfile6.txt bbrydsoe@enterprise:~/exercises/piping-wc-cut$ ls | head -3 | tail -1 aja bbrydsoe@enterprise:~/exercises/piping-wc-cut$ Using two pipes: sort the output of tail on ls $ ls -l | tail -14 | sort -n Using more pipes: find, sort, tail Here I find all the files with a name with suffix .txt, sort them, and then pick the last 4 in the sorted list: find . -type f -name \"*.txt\" | sort | tail -4 Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ find . -type f -name \"*.txt\" | sort | tail -4 ./thisfile7.txt ./thisfile8.txt ./thisfile9.txt ./thisfile.txt Using more pipes: find, sort, head, tee Here I find all the files with a name with suffix .txt, sort them, and then pick the first 4 in the sorted list, which I then use tee to send to a file (named list.txt) and also to output: find . -type f -name \"*.txt\" | sort | head -4 | tee list.txt","title":"Examples of piping"},{"location":"sessions/pipe/#exercise","text":"Sort (string numerical, in reverse) files ending in .txt Print the 4 first lines of the list of files ending in .txt Print the last 5 lines of the list of files ending in .txt and sort them, then print the first line of the output Use echo to output 5 lines you write then use tail to print the last line.","title":"Exercise"},{"location":"sessions/pipe/#summary","text":"As you have seen, pipe is a very useful operator, one which we will meet again in the later sections, combined with many commands and in scripts. Keypoints we learned about pipe we tried using one or more pipes to combine commands","title":"Summary"},{"location":"sessions/qual/","text":"Quality of Life \u00b6 This chapter is a little different to the others. It is not about a tool or an operator, but about some things that can help you make it nicer to use Linux/Bash on the command line. What\u2019s in here \u00b6 We will talk about background processes, learning how to start them with & and terminate them We will look at some useful terminal shortcuts and their usage We will learn how to edit a \u201c.bashrc\u201d file We will learn about using aliases Background processes \u00b6 Usually, if you start some program (perhaps with an input), it will start processing it and then give the output, perhaps to screen. In many cases the terminal will then be unable to accept new commands while the processes is running. On the other hand, Linux can do multi-tasking, so how do you get to a situation where you can start another application from your terminal? The answer to this is foreground and background processes. Normally, the process you start in a terminal runs in the foreground and you cannot do anything else in the terminal until it completes. With the bash feature of job control you can move processes to the background and also back to the foreground. It is also possible to start a job directly in the background. Start a background job/process \u00b6 This is done by adding an & at the end of the command, like this: <command> <options> <input> ... & Example : tar -zcvf mydir.tar.gz LOTS-FILE-DIR/ & The job keeps running in the background. Suspend a foreground job \u00b6 You can normally suspend a foreground job with the command CTRL-Z . When you do that the shell tells you the job is suspended and it also gives the job a job ID. No processing happens on the job while it is suspended. Move a foreground job to the background \u00b6 Assume you have started a program/job, like normal, in the foreground and you want to move it to the background. The steps to do that are: Suspend the job with CTRL-Z to release the terminal Give the command bg to put the suspended job to the background It will then start running again, but now in the background You can check that it is running with the command jobs Example : bbrydsoe@enterprise:~$ tar -zcvf Downloads.tar.gz Downloads/ Downloads/ Downloads/IMG_20250509_211952.jpg Downloads/add2 ( 1 ) .m Downloads/lstopo_lspci ( 1 ) .txt Downloads/teamviewer_15.44.5_amd64.deb ^Z [ 1 ] + Stopped tar -zcvf Downloads.tar.gz Downloads/ bbrydsoe@enterprise:~$ bg [ 1 ] + tar -zcvf Downloads.tar.gz Downloads/ & bbrydsoe@enterprise:~$ jobs [ 1 ] + Running tar -zcvf Downloads.tar.gz Downloads/ & Move a background job to the foreground \u00b6 To get the job running in the background back to the foreground you can give the command fg %JOBID Example for above job : fg %1 If you do not give a JOBID, then fg will assume the current suspended job. Restart a suspended job \u00b6 You can restart a suspended job in either: the background: bg %JOBID or foreground: fg %JOBID Remember, you can get the JOBID with the command jobs . Terminating a job \u00b6 You can terminate a foreground job with CTRL-C or a background job by sending it to the foreground and then do CTRL-C . There are other ways of killing a job, with the command kill and the process ID (PID), but we will not cover that here other than saying that you can get process IDs from ps -efH | grep <suitable string> and then kill PID or kill -9 PID if nothing else works. Useful terminal shortcuts and their usage \u00b6 TAB : autocomplete a file/directory or command CTRL-C : kill the current foreground process CTRL-Z : suspend the current foreground process CTRL-A : move the cursor to the beginning of the line CTRL-E : move the cursor to the end of the line CTRL-L : clear the screen (same as typing clear ) CTRL-K : delete the line after the cursor CTRL-Y : paste the most recent thing cut or copied CTRL-D : delete a character at the cursor\u2019s position CTRL-U : delete the whole line CTRL-W : delete the word before the cursor CTRL-P : go to the previous command in your command history (same as \u201carrow up\u201d, you can see the saved history with history ) CTRL-N : go to the next command in your command history (same as \u201carrow down\u201d) CTRL-R : search for a command in your command history How to edit a \u201c.bashrc\u201d file \u00b6 The file \u201c.bashrc\u201d is in your home directory ($HOME) and is a script file that is executed on login. It contains some configurations for the terminal session and can be used to modify how i.e. shell history, aliases, paths, and other things are configured. First and foremost; \u201c.bashrc\u201d is a \u201chidden\u201d file. To see those, add the flag/option -a to ls. ls -a If you just want to see what is in it, you can use cat: cat $HOME /.bashrc To edit it, use your favourite (command-line) editor. Here vi / vim or nano are common. nano $HOME /.bashrc Warning If you are editing your \u201c.bashrc\u201d file at one of the HPC centres in Sweden, it is usually a bad idea to add any module load <software to the \u201c.bashrc\u201d. A few months on you may have forgotten about it and now you want to use another module which does not load correctly or the program does not run as expected because you have already loaded another version in your \u201c.bashrc\u201d. In general, it is a good idea to make a backup of your \u201c.bashrc\u201d file if you are doing something that might break things. Do cp $HOME/.bashrc $HOME/.bashrc.bak or similar first. Otherwise, there are usually \u201cskeleton versions\u201d of these files in /etc/skel/ . Useful suggestions \u00b6 So what should you put in the \u201c.bashrc\u201d? It depends on your work style of course, and what you are working with, but these are some suggestions: Aliases (see next part, very soon) Environment variables, Python environments PATHs and library paths to own-installed software Customization of the terminal Anything you need persistent between sessions Important Any changes you make to \u201c.bashrc\u201d will not be active until you have done one of: logged out and in again source .bashrc . .bashrc Examples \u00b6 Setting the path in .bashrc Assuming you have installed some software and now need to set the path to libraries and binaries. In this example the new software is installed in /opt/SOFTWARE/ and we add the new path to the old, which included OTHERSOFTWARE installed in your homedirectory (for user username): export PATH = $PATH :/home/username/OTHERSOFTWARE/bin:opt/SOFTWARE/bin We sometimes also need to set the path to the softwares libraries: export LD_LIBRARY_PATH = $LD_LIBRARY_PATH :/home/username/OTHERSOFTWARE/lib:/opt/SOFTWARE/lib Customizing the terminal These includes a comment before that says what they do. Always good to put! # Change number of commands stored in memory during running to 1000 (those you can access with arrow-up or CTRL-P) HISTSIZE = 1000 # Change number of commands stored on disk to 2000 (you can see them with \"history\") HISTFILESIZE = 2000 # Append to the history file, don't overwrite it** shopt -s histappend # make less more friendly for non-text input files** [ -x /usr/bin/lesspipe ] && eval \" $( SHELL = /bin/sh lesspipe ) \" # set variable identifying the chroot you work in (used in the prompt below)** if [ -z \" ${ debian_chroot :- } \" ] && [ -r /etc/debian_chroot ] ; then debian_chroot = $( cat /etc/debian_chroot ) fi # set a fancy prompt (non-color, unless we know we \"want\" color) case \" $TERM \" in xterm-color | *-256color ) color_prompt = yes ;; esac # If this is an xterm set the title to user@host:dir case \" $TERM \" in xterm* | rxvt* ) PS1 = \"\\[\\e]0; ${ debian_chroot :+( $debian_chroot ) } \\u@\\h: \\w\\a\\] $PS1 \" ;; * ) ;; esac # enable color support of ls if [ -x /usr/bin/dircolors ] ; then test -r ~/.dircolors && eval \" $( dircolors -b ~/.dircolors ) \" || eval \" $( dircolors -b ) \" alias ls = 'ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' alias grep = 'grep --color=auto' alias fgrep = 'fgrep --color=auto' alias egrep = 'egrep --color=auto' fi # colored GCC warnings and errors - uncomment to use #export GCC_COLORS='error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01' Aliases \u00b6 An alias for a command means that there are two commands for the same action. The reason to make an alias is usually to get something that is shorter and/or easier to remember. Aliases can be persistent or non-persistent. Non-persistent aliases \u00b6 These are aliases you just need for a short time, during that specific session. They will go away next time you logout and login, and they will not be available in another shell. They are easy to create: alias ALIASNAME = \"command\" Example Making it easier to list all files with info, including hidden files alias lah = \"ls -lah\" It looks like this: bbrydsoe@enterprise:~/exercises/awk-qol$ lah Command 'lah' not found, did you mean: command 'lha' from deb jlha-utils ( 0 .1.6-4.1 ) command 'lha' from deb lhasa ( 0 .3.1-4 ) command 'lsh' from deb lsh-client ( 2 .1-13 ) Try: sudo apt install <deb name> bbrydsoe@enterprise:~/exercises/awk-qol$ alias lah = \"ls -lah\" bbrydsoe@enterprise:~/exercises/awk-qol$ lah total 16K drwxrwxr-x 2 bbrydsoe bbrydsoe 4 ,0K maj 26 16 :15 . drwxr-xr-x 8 bbrydsoe bbrydsoe 4 ,0K maj 26 19 :41 .. -rw-rw-r-- 1 bbrydsoe bbrydsoe 182 maj 26 15 :43 file.dat -rw-rw-r-- 1 bbrydsoe bbrydsoe 224 maj 26 15 :45 myfile.txt Persistent aliases \u00b6 So what do you do if you want to keep the aliases more permanently, and can use them from session to session? Add them to \u201c.bashrc\u201d Possibly add them to a file you create, \u201c.bash_aliases\u201d and then let \u201c.bashrc\u201d load \u201c.bash_aliases\u201d if [ -f ~/.bash_aliases ] ; then . ~/.bash_aliases fi Here we are just going to add them to \u201c.bashrc\u201d. Examples Open \u201c$HOME/.bashrc\u201d with nano or vi / vim or similar. If you already have some aliases there, just add new ones after, otherwise scroll to the bottom and make a comment # Aliases then add your aliases after. Common aliases are: alias .. = 'cd ..' alias ... = 'cd ../..' alias .... = 'cd ../../..' alias .4 = 'cd ../../../../' alias .5 = 'cd ../../../../..' alias la = 'ls -a' alias sl = \"ls\" alias l = \"ls\" alias s = \"ls\" alias rm = 'rm -i' #-i prompts user before deletion alias cp = 'cp -i' #-i prompts user before overwriting # If you have some environments you often use alias env1 = \"source ~/project1/env/bin/activate\" Exercises \u00b6 Start a job in the background with & Start a job that takes some time to run. Suspend it. Send it to the background. Look that it runs. Return it to the foreground. Suggestion: Make a tarball of a directory with many files in. If you do not have a suitable directory, you can instead run the script slowcommand.sh in \u201cexercises\u201d -> \u201cawk-qol\u201d (make sure it is executable, chmod +x slowcommand.sh ) Try out several of the terminal shortcuts Create a couple aliases (non-persistent) and try them out Add some nice aliases to your \u201c.bashrc\u201d, source the \u201c.bashrc\u201d and try the aliases! Summary \u00b6 Keypoints we learned about foreground and background processes we tried some terminal short-cuts we learned about alias we learned about \u201c.bashrc\u201d","title":"Quality of life"},{"location":"sessions/qual/#quality__of__life","text":"This chapter is a little different to the others. It is not about a tool or an operator, but about some things that can help you make it nicer to use Linux/Bash on the command line.","title":"Quality of Life"},{"location":"sessions/qual/#whats__in__here","text":"We will talk about background processes, learning how to start them with & and terminate them We will look at some useful terminal shortcuts and their usage We will learn how to edit a \u201c.bashrc\u201d file We will learn about using aliases","title":"What&rsquo;s in here"},{"location":"sessions/qual/#background__processes","text":"Usually, if you start some program (perhaps with an input), it will start processing it and then give the output, perhaps to screen. In many cases the terminal will then be unable to accept new commands while the processes is running. On the other hand, Linux can do multi-tasking, so how do you get to a situation where you can start another application from your terminal? The answer to this is foreground and background processes. Normally, the process you start in a terminal runs in the foreground and you cannot do anything else in the terminal until it completes. With the bash feature of job control you can move processes to the background and also back to the foreground. It is also possible to start a job directly in the background.","title":"Background processes"},{"location":"sessions/qual/#start__a__background__jobprocess","text":"This is done by adding an & at the end of the command, like this: <command> <options> <input> ... & Example : tar -zcvf mydir.tar.gz LOTS-FILE-DIR/ & The job keeps running in the background.","title":"Start a background job/process"},{"location":"sessions/qual/#suspend__a__foreground__job","text":"You can normally suspend a foreground job with the command CTRL-Z . When you do that the shell tells you the job is suspended and it also gives the job a job ID. No processing happens on the job while it is suspended.","title":"Suspend a foreground job"},{"location":"sessions/qual/#move__a__foreground__job__to__the__background","text":"Assume you have started a program/job, like normal, in the foreground and you want to move it to the background. The steps to do that are: Suspend the job with CTRL-Z to release the terminal Give the command bg to put the suspended job to the background It will then start running again, but now in the background You can check that it is running with the command jobs Example : bbrydsoe@enterprise:~$ tar -zcvf Downloads.tar.gz Downloads/ Downloads/ Downloads/IMG_20250509_211952.jpg Downloads/add2 ( 1 ) .m Downloads/lstopo_lspci ( 1 ) .txt Downloads/teamviewer_15.44.5_amd64.deb ^Z [ 1 ] + Stopped tar -zcvf Downloads.tar.gz Downloads/ bbrydsoe@enterprise:~$ bg [ 1 ] + tar -zcvf Downloads.tar.gz Downloads/ & bbrydsoe@enterprise:~$ jobs [ 1 ] + Running tar -zcvf Downloads.tar.gz Downloads/ &","title":"Move a foreground job to the background"},{"location":"sessions/qual/#move__a__background__job__to__the__foreground","text":"To get the job running in the background back to the foreground you can give the command fg %JOBID Example for above job : fg %1 If you do not give a JOBID, then fg will assume the current suspended job.","title":"Move a background job to the foreground"},{"location":"sessions/qual/#restart__a__suspended__job","text":"You can restart a suspended job in either: the background: bg %JOBID or foreground: fg %JOBID Remember, you can get the JOBID with the command jobs .","title":"Restart a suspended job"},{"location":"sessions/qual/#terminating__a__job","text":"You can terminate a foreground job with CTRL-C or a background job by sending it to the foreground and then do CTRL-C . There are other ways of killing a job, with the command kill and the process ID (PID), but we will not cover that here other than saying that you can get process IDs from ps -efH | grep <suitable string> and then kill PID or kill -9 PID if nothing else works.","title":"Terminating a job"},{"location":"sessions/qual/#useful__terminal__shortcuts__and__their__usage","text":"TAB : autocomplete a file/directory or command CTRL-C : kill the current foreground process CTRL-Z : suspend the current foreground process CTRL-A : move the cursor to the beginning of the line CTRL-E : move the cursor to the end of the line CTRL-L : clear the screen (same as typing clear ) CTRL-K : delete the line after the cursor CTRL-Y : paste the most recent thing cut or copied CTRL-D : delete a character at the cursor\u2019s position CTRL-U : delete the whole line CTRL-W : delete the word before the cursor CTRL-P : go to the previous command in your command history (same as \u201carrow up\u201d, you can see the saved history with history ) CTRL-N : go to the next command in your command history (same as \u201carrow down\u201d) CTRL-R : search for a command in your command history","title":"Useful terminal shortcuts and their usage"},{"location":"sessions/qual/#how__to__edit__a__bashrc__file","text":"The file \u201c.bashrc\u201d is in your home directory ($HOME) and is a script file that is executed on login. It contains some configurations for the terminal session and can be used to modify how i.e. shell history, aliases, paths, and other things are configured. First and foremost; \u201c.bashrc\u201d is a \u201chidden\u201d file. To see those, add the flag/option -a to ls. ls -a If you just want to see what is in it, you can use cat: cat $HOME /.bashrc To edit it, use your favourite (command-line) editor. Here vi / vim or nano are common. nano $HOME /.bashrc Warning If you are editing your \u201c.bashrc\u201d file at one of the HPC centres in Sweden, it is usually a bad idea to add any module load <software to the \u201c.bashrc\u201d. A few months on you may have forgotten about it and now you want to use another module which does not load correctly or the program does not run as expected because you have already loaded another version in your \u201c.bashrc\u201d. In general, it is a good idea to make a backup of your \u201c.bashrc\u201d file if you are doing something that might break things. Do cp $HOME/.bashrc $HOME/.bashrc.bak or similar first. Otherwise, there are usually \u201cskeleton versions\u201d of these files in /etc/skel/ .","title":"How to edit a &ldquo;.bashrc&rdquo; file"},{"location":"sessions/qual/#useful__suggestions","text":"So what should you put in the \u201c.bashrc\u201d? It depends on your work style of course, and what you are working with, but these are some suggestions: Aliases (see next part, very soon) Environment variables, Python environments PATHs and library paths to own-installed software Customization of the terminal Anything you need persistent between sessions Important Any changes you make to \u201c.bashrc\u201d will not be active until you have done one of: logged out and in again source .bashrc . .bashrc","title":"Useful suggestions"},{"location":"sessions/qual/#examples","text":"Setting the path in .bashrc Assuming you have installed some software and now need to set the path to libraries and binaries. In this example the new software is installed in /opt/SOFTWARE/ and we add the new path to the old, which included OTHERSOFTWARE installed in your homedirectory (for user username): export PATH = $PATH :/home/username/OTHERSOFTWARE/bin:opt/SOFTWARE/bin We sometimes also need to set the path to the softwares libraries: export LD_LIBRARY_PATH = $LD_LIBRARY_PATH :/home/username/OTHERSOFTWARE/lib:/opt/SOFTWARE/lib Customizing the terminal These includes a comment before that says what they do. Always good to put! # Change number of commands stored in memory during running to 1000 (those you can access with arrow-up or CTRL-P) HISTSIZE = 1000 # Change number of commands stored on disk to 2000 (you can see them with \"history\") HISTFILESIZE = 2000 # Append to the history file, don't overwrite it** shopt -s histappend # make less more friendly for non-text input files** [ -x /usr/bin/lesspipe ] && eval \" $( SHELL = /bin/sh lesspipe ) \" # set variable identifying the chroot you work in (used in the prompt below)** if [ -z \" ${ debian_chroot :- } \" ] && [ -r /etc/debian_chroot ] ; then debian_chroot = $( cat /etc/debian_chroot ) fi # set a fancy prompt (non-color, unless we know we \"want\" color) case \" $TERM \" in xterm-color | *-256color ) color_prompt = yes ;; esac # If this is an xterm set the title to user@host:dir case \" $TERM \" in xterm* | rxvt* ) PS1 = \"\\[\\e]0; ${ debian_chroot :+( $debian_chroot ) } \\u@\\h: \\w\\a\\] $PS1 \" ;; * ) ;; esac # enable color support of ls if [ -x /usr/bin/dircolors ] ; then test -r ~/.dircolors && eval \" $( dircolors -b ~/.dircolors ) \" || eval \" $( dircolors -b ) \" alias ls = 'ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' alias grep = 'grep --color=auto' alias fgrep = 'fgrep --color=auto' alias egrep = 'egrep --color=auto' fi # colored GCC warnings and errors - uncomment to use #export GCC_COLORS='error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01'","title":"Examples"},{"location":"sessions/qual/#aliases","text":"An alias for a command means that there are two commands for the same action. The reason to make an alias is usually to get something that is shorter and/or easier to remember. Aliases can be persistent or non-persistent.","title":"Aliases"},{"location":"sessions/qual/#non-persistent__aliases","text":"These are aliases you just need for a short time, during that specific session. They will go away next time you logout and login, and they will not be available in another shell. They are easy to create: alias ALIASNAME = \"command\" Example Making it easier to list all files with info, including hidden files alias lah = \"ls -lah\" It looks like this: bbrydsoe@enterprise:~/exercises/awk-qol$ lah Command 'lah' not found, did you mean: command 'lha' from deb jlha-utils ( 0 .1.6-4.1 ) command 'lha' from deb lhasa ( 0 .3.1-4 ) command 'lsh' from deb lsh-client ( 2 .1-13 ) Try: sudo apt install <deb name> bbrydsoe@enterprise:~/exercises/awk-qol$ alias lah = \"ls -lah\" bbrydsoe@enterprise:~/exercises/awk-qol$ lah total 16K drwxrwxr-x 2 bbrydsoe bbrydsoe 4 ,0K maj 26 16 :15 . drwxr-xr-x 8 bbrydsoe bbrydsoe 4 ,0K maj 26 19 :41 .. -rw-rw-r-- 1 bbrydsoe bbrydsoe 182 maj 26 15 :43 file.dat -rw-rw-r-- 1 bbrydsoe bbrydsoe 224 maj 26 15 :45 myfile.txt","title":"Non-persistent aliases"},{"location":"sessions/qual/#persistent__aliases","text":"So what do you do if you want to keep the aliases more permanently, and can use them from session to session? Add them to \u201c.bashrc\u201d Possibly add them to a file you create, \u201c.bash_aliases\u201d and then let \u201c.bashrc\u201d load \u201c.bash_aliases\u201d if [ -f ~/.bash_aliases ] ; then . ~/.bash_aliases fi Here we are just going to add them to \u201c.bashrc\u201d. Examples Open \u201c$HOME/.bashrc\u201d with nano or vi / vim or similar. If you already have some aliases there, just add new ones after, otherwise scroll to the bottom and make a comment # Aliases then add your aliases after. Common aliases are: alias .. = 'cd ..' alias ... = 'cd ../..' alias .... = 'cd ../../..' alias .4 = 'cd ../../../../' alias .5 = 'cd ../../../../..' alias la = 'ls -a' alias sl = \"ls\" alias l = \"ls\" alias s = \"ls\" alias rm = 'rm -i' #-i prompts user before deletion alias cp = 'cp -i' #-i prompts user before overwriting # If you have some environments you often use alias env1 = \"source ~/project1/env/bin/activate\"","title":"Persistent aliases"},{"location":"sessions/qual/#exercises","text":"Start a job in the background with & Start a job that takes some time to run. Suspend it. Send it to the background. Look that it runs. Return it to the foreground. Suggestion: Make a tarball of a directory with many files in. If you do not have a suitable directory, you can instead run the script slowcommand.sh in \u201cexercises\u201d -> \u201cawk-qol\u201d (make sure it is executable, chmod +x slowcommand.sh ) Try out several of the terminal shortcuts Create a couple aliases (non-persistent) and try them out Add some nice aliases to your \u201c.bashrc\u201d, source the \u201c.bashrc\u201d and try the aliases!","title":"Exercises"},{"location":"sessions/qual/#summary","text":"Keypoints we learned about foreground and background processes we tried some terminal short-cuts we learned about alias we learned about \u201c.bashrc\u201d","title":"Summary"},{"location":"sessions/redirects/","text":"Redirects \u00b6 I/O redirection: Usually, standard input comes from the keyboard etc. and the standard output goes to the screen. There is also standard error. All of these can be redirected with Linux commands. Objectives Learn about redirection standard input standard output standard error When running a command which can take input, give output, or do both, redirection lets us redirect the input and output to any files or folders we want to. It is also possible to redirect any errors specifically, instead of together with regular output, so you get errors and other output to different files. As default, standard output and standard error are sent to the screen and standard input comes from the keyboard/mouse. Example : You run a command, for instance ls ; it throws the output to the screen. However, if you want to save it to a file instead you could use output redirection . Redirects are particularly useful if we are working with large outputs/inputs, multiple outputs/inputs, or wish to save the output for later. It may also be that we want to use the output from one command as input for another command - this can be solved with pipes as we saw yesterday, but saving the intermittent result to file is also an option. There are different types of redirection: overwrite redirection append redirection merge redirection Let us look at them one at a time and see some examples. Overwrite redirection \u00b6 Let us assume you want to save the output of a command to a file and that you do not mind that the existing content of that file is overwritten (or you create a new file). In this situation, overwrite redirection is useful. > - standard output < - standard input Note Whenever a new program is run, the kernel creates a table of file descriptors for the program. File descriptors are pointers to files. By convention, the first 3 entries in the table (descriptors 0, 1, and 2) are used as standard input (stdin), standard output (stdout), and standard error (stderr). The full syntax of the redirection operator includes an optional file descriptor: command > file could be written command 1> file command < file could be written command 0< file Examples \u00b6 Hint Code along! The files used in the examples are either created during the examples or can be found in the directory \u201cexercises\u201d -> \u201credirects-env-link\u201d. Output of ls to file mylsoutput.txt ls > mylsoutput.txt Anything written after \u201c>\u201d is written to myfile.txt - end with CTRL-D bbrydsoe@enterprise:~$ cat > myfile.txt This text will go to the file myfile.txt bbrydsoe@enterprise:~$ This gives the input of \u201cmyfile.txt\u201d to cat, which prints the content to screen cat < myfile.txt Splitting standard error and standard output - send standard error to file \u201cerror-log\u201d ./myprogram 2 > error.log It will tell you (in error.log) that there is no such file or directory. Try instead running it with the program imagefind.sh . It will put a different message in the error.log file. Append redirection \u00b6 It is also possible to append to a file with redirection, instead of overwriting. This is done with: >> - standard output << - standard input Examples \u00b6 Hint Code along! The files used in the examples are either created during the examples or can be found in the directory \u201cexercises\u201d -> \u201credirects-env-link\u201d. Add more text to an existing file echo 'text to append_add_here' >> myfile.txt Another way to add more text to an existing file printf \"text to append\\n\" >> myfile.txt Append one existing file to another cat file1.txt >> file2.txt Take a look inside file2.txt and see that the content of file1.txt has been added. Append one existing file to another and also throw the content of the file being added to screen cat file1.txt 0 >> file2.txt What about standard input, << ? \u00b6 A common way to use << is to let a program know what the ending text is (use it as a delimiter). For instance, the program reads everything you gives to the program as input until it sees the delimiter. Then it performs its tasks on it. Example - count lines/words/characters on several lines of input $ wc << EOF > Here are some words > More words > Yet more words > It is just one more line > EOF 4 15 71 Merge redirection \u00b6 With merge redirection you can redirect the output of a command or a program to a file descriptor instead of to standard output. Syntax stream1 >& stream2 - merge output from stream1 with stream2 stream1 <& stream2 - merge input from stream1 with stream2 Remember file descriptor 0: standard input file descriptor 1: standard output file descriptor 2: standard error So, sometimes you want to write more than one output stream to the same file. Commonly, standard output and standard error. This could be done like this: command > file 2>&1 This is the same as that but longer, but maybe more descriptive: - ``command 1> file 2>&1`` Examples \u00b6 Example: Send both standard output and standard error to file \u201cmylog.log\u201d ./myprogram.sh > mylog.log 2 > & 1 It should throw some errors and also some output to a file mylog.log . 2>&1 means that \u201cstandard error\u201d (STDERR) are redirected to whatever the target is of \u201cstandard output\u201d (STDOUT). What happens more precisely is that the error message that is generated by \u201cstandard error\u201d/\u201d2\u201d gets merged with the \u201cstandard output\u201d/\u201d1\u201d. Exercise \u00b6 Use \u201coverwrite redirection\u201d to send standard output of ls -lart of the directory \u201cexercises\u201d -> \u201credirects-env-link\u201d to a file named \u201cmyfiles-list.txt\u201d Use \u201cappend redirection\u201d and echo to add a line of text to one of the files in the directory \u201cexercises\u201d -> \u201credirects-env-link\u201d. Use \u201cmerge redirection\u201d and \u201cpipe\u201d as well as any commands you want to generate some output and errors and throw them to the same file. Summary \u00b6 keypoints We learned about redirection overwrite append merge","title":"Redirects"},{"location":"sessions/redirects/#redirects","text":"I/O redirection: Usually, standard input comes from the keyboard etc. and the standard output goes to the screen. There is also standard error. All of these can be redirected with Linux commands. Objectives Learn about redirection standard input standard output standard error When running a command which can take input, give output, or do both, redirection lets us redirect the input and output to any files or folders we want to. It is also possible to redirect any errors specifically, instead of together with regular output, so you get errors and other output to different files. As default, standard output and standard error are sent to the screen and standard input comes from the keyboard/mouse. Example : You run a command, for instance ls ; it throws the output to the screen. However, if you want to save it to a file instead you could use output redirection . Redirects are particularly useful if we are working with large outputs/inputs, multiple outputs/inputs, or wish to save the output for later. It may also be that we want to use the output from one command as input for another command - this can be solved with pipes as we saw yesterday, but saving the intermittent result to file is also an option. There are different types of redirection: overwrite redirection append redirection merge redirection Let us look at them one at a time and see some examples.","title":"Redirects"},{"location":"sessions/redirects/#overwrite__redirection","text":"Let us assume you want to save the output of a command to a file and that you do not mind that the existing content of that file is overwritten (or you create a new file). In this situation, overwrite redirection is useful. > - standard output < - standard input Note Whenever a new program is run, the kernel creates a table of file descriptors for the program. File descriptors are pointers to files. By convention, the first 3 entries in the table (descriptors 0, 1, and 2) are used as standard input (stdin), standard output (stdout), and standard error (stderr). The full syntax of the redirection operator includes an optional file descriptor: command > file could be written command 1> file command < file could be written command 0< file","title":"Overwrite redirection"},{"location":"sessions/redirects/#examples","text":"Hint Code along! The files used in the examples are either created during the examples or can be found in the directory \u201cexercises\u201d -> \u201credirects-env-link\u201d. Output of ls to file mylsoutput.txt ls > mylsoutput.txt Anything written after \u201c>\u201d is written to myfile.txt - end with CTRL-D bbrydsoe@enterprise:~$ cat > myfile.txt This text will go to the file myfile.txt bbrydsoe@enterprise:~$ This gives the input of \u201cmyfile.txt\u201d to cat, which prints the content to screen cat < myfile.txt Splitting standard error and standard output - send standard error to file \u201cerror-log\u201d ./myprogram 2 > error.log It will tell you (in error.log) that there is no such file or directory. Try instead running it with the program imagefind.sh . It will put a different message in the error.log file.","title":"Examples"},{"location":"sessions/redirects/#append__redirection","text":"It is also possible to append to a file with redirection, instead of overwriting. This is done with: >> - standard output << - standard input","title":"Append redirection"},{"location":"sessions/redirects/#examples_1","text":"Hint Code along! The files used in the examples are either created during the examples or can be found in the directory \u201cexercises\u201d -> \u201credirects-env-link\u201d. Add more text to an existing file echo 'text to append_add_here' >> myfile.txt Another way to add more text to an existing file printf \"text to append\\n\" >> myfile.txt Append one existing file to another cat file1.txt >> file2.txt Take a look inside file2.txt and see that the content of file1.txt has been added. Append one existing file to another and also throw the content of the file being added to screen cat file1.txt 0 >> file2.txt","title":"Examples"},{"location":"sessions/redirects/#what__about__standard__input","text":"A common way to use << is to let a program know what the ending text is (use it as a delimiter). For instance, the program reads everything you gives to the program as input until it sees the delimiter. Then it performs its tasks on it. Example - count lines/words/characters on several lines of input $ wc << EOF > Here are some words > More words > Yet more words > It is just one more line > EOF 4 15 71","title":"What about standard input, &lt;&lt; ?"},{"location":"sessions/redirects/#merge__redirection","text":"With merge redirection you can redirect the output of a command or a program to a file descriptor instead of to standard output. Syntax stream1 >& stream2 - merge output from stream1 with stream2 stream1 <& stream2 - merge input from stream1 with stream2 Remember file descriptor 0: standard input file descriptor 1: standard output file descriptor 2: standard error So, sometimes you want to write more than one output stream to the same file. Commonly, standard output and standard error. This could be done like this: command > file 2>&1 This is the same as that but longer, but maybe more descriptive: - ``command 1> file 2>&1``","title":"Merge redirection"},{"location":"sessions/redirects/#examples_2","text":"Example: Send both standard output and standard error to file \u201cmylog.log\u201d ./myprogram.sh > mylog.log 2 > & 1 It should throw some errors and also some output to a file mylog.log . 2>&1 means that \u201cstandard error\u201d (STDERR) are redirected to whatever the target is of \u201cstandard output\u201d (STDOUT). What happens more precisely is that the error message that is generated by \u201cstandard error\u201d/\u201d2\u201d gets merged with the \u201cstandard output\u201d/\u201d1\u201d.","title":"Examples"},{"location":"sessions/redirects/#exercise","text":"Use \u201coverwrite redirection\u201d to send standard output of ls -lart of the directory \u201cexercises\u201d -> \u201credirects-env-link\u201d to a file named \u201cmyfiles-list.txt\u201d Use \u201cappend redirection\u201d and echo to add a line of text to one of the files in the directory \u201cexercises\u201d -> \u201credirects-env-link\u201d. Use \u201cmerge redirection\u201d and \u201cpipe\u201d as well as any commands you want to generate some output and errors and throw them to the same file.","title":"Exercise"},{"location":"sessions/redirects/#summary","text":"keypoints We learned about redirection overwrite append merge","title":"Summary"},{"location":"sessions/sed/","text":"sed \u00b6 The command sed (stream editor) is one of the most powerful commands. It is used for textual processing - parsing and transforming text. It uses a simple, but compact programming language. After the programming language AWK was developed, sed and awk are often used together, particularly in scripts. Together they are commonly considered progenitors and inspiration for Perl. Syntax \u00b6 sed [ options ] 'command' [ inputfile... ] where options are optional flags that modify the behavior of the sed command command is a command or sequence of commands to execute on the inputfile(s) inputfile is one or more inputfiles that is to be processed Common sed options \u00b6 -i - Edit the file in place without printing to the console (overwrite the file). -n - Suppress automatic printing of lines. -e - Allows multiple commands to be executed. -f - Reads sed commands from a file instead of the command line. -r - Enables extended regular expressions. Commonly used regular expression meta characters \u00b6 caret (^) matches the beginning of the line. dollar sign ($) matches the end of the line. asterisk (*) matches zero or more occurrences of the previous character. plus (+) matches one or more occurrence(s) of the previous character. question mark (?) matches zero or one occurrence of the previous character. dot (.) matches exactly one character. Some examples inspired by: https://www.geeksforgeeks.org/sed-command-in-linux-unix-with-examples/ https://en.wikipedia.org/wiki/Sed Substitution command \u00b6 This is probably what sed is most commonly used for: substitution. It is also the original motivation for creating it. Syntax sed 's/regexp/replacement/g' inputFileName > outputFileName regexp is a regular expression (pattern) to be searched, including a text. replacement is what should be replaced for the matched patterns - literal text or format string the characters & for \u201centire match\u201d or the special escape sequences \\1 through \\9 for the nth saved sub-expression. inputFileName is the file(s) to be searched outputFileName is the name(s) of the changed files - if not given the changed content is just shown on screen. s stands for substitute, g for global (all instances), and / is the conventional delimiting symbol used. Examples \u00b6 Replace all instances of \u2018cat\u2019 with \u2018ferret\u2019 and send to screen Use the file \u201cfile1.txt\u201d in \u201cexercises -> \u201csed\u201d sed 's/cat/ferret/g' file1.txt Replace all instances of \u2018cat\u2019 with \u2018ferret\u2019 and write to a file Use the file \u201cfile1.txt\u201d in \u201cexercises -> \u201csed\u201d sed 's/cat/ferret/g' file1.txt > output.txt Replace the nth occurrence of a pattern in a line Let us change the 3rd occurrence in the same line of word to book in file3.txt sed 's/word/book/3' file3.txt Replace occurrences from n and the rest of the way Here from 3rd occurrence sed 's/word/book/3g' file3.txt Replace only the occurrence of a string on a specific line This for line 3 sed '3 s/word/book/' file3.txt Put a parentheses around the first character of each word echo \"Hello I am learning more Linux\" | sed 's/\\(\\b[A-Z]\\)/\\(\\1\\)/g' Replace all instances of \u2018cat\u2019 or \u2018dog\u2019 with \u2018cats\u2019 or \u2018dogs\u2019 - do not duplicate existing plurals Use all files named starting with \u201cfile\u201d in the \u201cexercises\u201d -> \u201csed\u201d folder (but not subdirs). Here the changed text is just thrown to screen. sed -r \"s/(cat|dog)s?/\\1s/g\" file* (cat|dog) is the 1st (and only) saved sub-expression in the regexp, and \\1 in the format string substitutes this into the output. You can see in the output that i.e. \u201cdogs\u201d did not get turned into \u201cdogss\u201d However, it did not catch things were for instance \u201ccat\u201d is in the middle of a word, like \u201clocated\u201d which did get changed to \u201clocatsed\u201d This could be fixed with sed -r \"s/(' cat '|dog)s?/\\1s/g\" file* Other common commands \u00b6 Besides substitution, sed can do many other things. There are around 25 sed commands. Here we will only look at the command to filter out specific lines. Using the d command to filter out specific lines \u00b6 filter lines that only contain spaces, or only contain the end of line character sed '/^ *$/d' inputFile Deleting a specific line from a specific file Delete line 4 sed '4d' file1.txt Delete a line containing a matching pattern Lines matching the string \u201ccat\u201d sed '/cat/d' file1.txt Filtering \u00b6 It is also common to use sed as a filter, as part of a \u201cpipeline\u201d. In this example, the program \u201cdata-generating-program\u201d is creating some data, but you named something wrong perhaps, and now you need to replace all instances of \u201cright\u201d with \u201cleft\u201d: data-generating-program | sed 's/right/left/g' In-place editing \u00b6 Using the -i option allows \u201cin-place\u201d editing instead of creating a new file with the editions (though in reality a temporary file is created in the background and then the original file is replaced by the temporary file). Example - change cat to dog sed -i 's/cat/dog/' file1.txt Summary \u00b6 Keypoints we have learned about sed and some of its common commands we have used sed to replace strings matching a pattern we have used sed to delete specific lines we have learned about sed for filtering we have learned about sed in-place editing","title":"Linux tools (sed)"},{"location":"sessions/sed/#sed","text":"The command sed (stream editor) is one of the most powerful commands. It is used for textual processing - parsing and transforming text. It uses a simple, but compact programming language. After the programming language AWK was developed, sed and awk are often used together, particularly in scripts. Together they are commonly considered progenitors and inspiration for Perl.","title":"sed"},{"location":"sessions/sed/#syntax","text":"sed [ options ] 'command' [ inputfile... ] where options are optional flags that modify the behavior of the sed command command is a command or sequence of commands to execute on the inputfile(s) inputfile is one or more inputfiles that is to be processed","title":"Syntax"},{"location":"sessions/sed/#common__sed__options","text":"-i - Edit the file in place without printing to the console (overwrite the file). -n - Suppress automatic printing of lines. -e - Allows multiple commands to be executed. -f - Reads sed commands from a file instead of the command line. -r - Enables extended regular expressions.","title":"Common sed options"},{"location":"sessions/sed/#commonly__used__regular__expression__meta__characters","text":"caret (^) matches the beginning of the line. dollar sign ($) matches the end of the line. asterisk (*) matches zero or more occurrences of the previous character. plus (+) matches one or more occurrence(s) of the previous character. question mark (?) matches zero or one occurrence of the previous character. dot (.) matches exactly one character. Some examples inspired by: https://www.geeksforgeeks.org/sed-command-in-linux-unix-with-examples/ https://en.wikipedia.org/wiki/Sed","title":"Commonly used regular expression meta characters"},{"location":"sessions/sed/#substitution__command","text":"This is probably what sed is most commonly used for: substitution. It is also the original motivation for creating it. Syntax sed 's/regexp/replacement/g' inputFileName > outputFileName regexp is a regular expression (pattern) to be searched, including a text. replacement is what should be replaced for the matched patterns - literal text or format string the characters & for \u201centire match\u201d or the special escape sequences \\1 through \\9 for the nth saved sub-expression. inputFileName is the file(s) to be searched outputFileName is the name(s) of the changed files - if not given the changed content is just shown on screen. s stands for substitute, g for global (all instances), and / is the conventional delimiting symbol used.","title":"Substitution command"},{"location":"sessions/sed/#examples","text":"Replace all instances of \u2018cat\u2019 with \u2018ferret\u2019 and send to screen Use the file \u201cfile1.txt\u201d in \u201cexercises -> \u201csed\u201d sed 's/cat/ferret/g' file1.txt Replace all instances of \u2018cat\u2019 with \u2018ferret\u2019 and write to a file Use the file \u201cfile1.txt\u201d in \u201cexercises -> \u201csed\u201d sed 's/cat/ferret/g' file1.txt > output.txt Replace the nth occurrence of a pattern in a line Let us change the 3rd occurrence in the same line of word to book in file3.txt sed 's/word/book/3' file3.txt Replace occurrences from n and the rest of the way Here from 3rd occurrence sed 's/word/book/3g' file3.txt Replace only the occurrence of a string on a specific line This for line 3 sed '3 s/word/book/' file3.txt Put a parentheses around the first character of each word echo \"Hello I am learning more Linux\" | sed 's/\\(\\b[A-Z]\\)/\\(\\1\\)/g' Replace all instances of \u2018cat\u2019 or \u2018dog\u2019 with \u2018cats\u2019 or \u2018dogs\u2019 - do not duplicate existing plurals Use all files named starting with \u201cfile\u201d in the \u201cexercises\u201d -> \u201csed\u201d folder (but not subdirs). Here the changed text is just thrown to screen. sed -r \"s/(cat|dog)s?/\\1s/g\" file* (cat|dog) is the 1st (and only) saved sub-expression in the regexp, and \\1 in the format string substitutes this into the output. You can see in the output that i.e. \u201cdogs\u201d did not get turned into \u201cdogss\u201d However, it did not catch things were for instance \u201ccat\u201d is in the middle of a word, like \u201clocated\u201d which did get changed to \u201clocatsed\u201d This could be fixed with sed -r \"s/(' cat '|dog)s?/\\1s/g\" file*","title":"Examples"},{"location":"sessions/sed/#other__common__commands","text":"Besides substitution, sed can do many other things. There are around 25 sed commands. Here we will only look at the command to filter out specific lines.","title":"Other common commands"},{"location":"sessions/sed/#using__the__d__command__to__filter__out__specific__lines","text":"filter lines that only contain spaces, or only contain the end of line character sed '/^ *$/d' inputFile Deleting a specific line from a specific file Delete line 4 sed '4d' file1.txt Delete a line containing a matching pattern Lines matching the string \u201ccat\u201d sed '/cat/d' file1.txt","title":"Using the d command to filter out specific lines"},{"location":"sessions/sed/#filtering","text":"It is also common to use sed as a filter, as part of a \u201cpipeline\u201d. In this example, the program \u201cdata-generating-program\u201d is creating some data, but you named something wrong perhaps, and now you need to replace all instances of \u201cright\u201d with \u201cleft\u201d: data-generating-program | sed 's/right/left/g'","title":"Filtering"},{"location":"sessions/sed/#in-place__editing","text":"Using the -i option allows \u201cin-place\u201d editing instead of creating a new file with the editions (though in reality a temporary file is created in the background and then the original file is replaced by the temporary file). Example - change cat to dog sed -i 's/cat/dog/' file1.txt","title":"In-place editing"},{"location":"sessions/sed/#summary","text":"Keypoints we have learned about sed and some of its common commands we have used sed to replace strings matching a pattern we have used sed to delete specific lines we have learned about sed for filtering we have learned about sed in-place editing","title":"Summary"},{"location":"sessions/symlinks/","text":"Symbolic links \u00b6 Symbolic links are also called soft links, or just symlinks. It is a pointer to another file or directory (called the \u201ctarget\u201d). It is useful both for ease you avoid using a long path each time you change to a directory, like your project directory As well as to avoid changing hard links within other scripts or programs. This is good if you for instance install a program or use a script that assumes the library it uses is called libcoolness.a and not libcoolness.2.0.a . You can then just update the symlink instead of renaming the library or updating potentially many instances where it is mentioned in the program. Hard links and soft links You may have heard symbolic links referred to as \u201csoft links\u201d. So what is a hard link? Hard links are also shortcuts for files (not directories), but a hard link cannot be created for a file in a different file system. Syntax \u00b6 Soft link/symbolic link: ln -s real-file-folder-or-lib link-name Hard link: ln source-file linked-file Verify \u00b6 To verify a soft or hard link, run: ls -l source link Examples \u00b6 Hint You can type along to most of this! Use the files in \u201cexercises\u201d -> \u201credirects-env-links\u201d for examples. Hard links \u00b6 Hint You can code along! Either use one of the files/directories in \u201cexercises\u201d -> \u201credirect-env-link\u201d or create a file to play with. This should work: echo 'This is my test file' > testfile Create a hard link, files ln testfile linkfile To check what happened, do this: ls -li testfile linkfile My output: $ ls -li total 8 808864781 -rw-r--r-- 2 bbrydsoe folk 21 May 27 16 :36 linkfile 808864781 -rw-r--r-- 2 bbrydsoe folk 21 May 27 16 :36 testfile 808864781 is the inode, which is identical. An inode (index node) is a concept in Linux/Unix. Each object in a filesystem is represented by an inode. It is a data structure which stores basic info about files, directories, or other file system objects. More here if you are interested: Understanding UNIX / Linux filesystem Inodes . Soft/symbolic links \u00b6 Create a symbolic link to a directory ln -s /path/to/home/exercises/redirects-env-link $HOME /exer This creates a symbolic link named \u201cexer\u201d in the home directory, pointing to the location /path/to/home/exercises/redirects-env-link. For me, this would look like this: bbrydsoe@enterprise:~/exercises/redirects-env-link$ pwd /home/bbrydsoe/exercises/redirects-env-link bbrydsoe@enterprise:~/exercises/redirects-env-link$ ln -s /home/bbrydsoe/exercises/redirects-env-link $HOME /exer bbrydsoe@enterprise:~$ cd bbrydsoe@enterprise:~$ ls -l ... drwxrwxr-x 6 bbrydsoe bbrydsoe 4096 nov 13 2023 course-intro-git drwxr-xr-x 8 bbrydsoe bbrydsoe 4096 maj 25 14 :53 Desktop drwxr-xr-x 6 bbrydsoe bbrydsoe 4096 jun 20 2024 Documents drwxr-xr-x 22 bbrydsoe bbrydsoe 20480 maj 26 15 :13 Downloads drwxrwxr-x 2 bbrydsoe bbrydsoe 4096 maj 21 09 :10 examples lrwxrwxrwx 1 bbrydsoe bbrydsoe 43 maj 26 19 :36 exer -> /home/bbrydsoe/exercises/redirects-env-link drwxr-xr-x 8 bbrydsoe bbrydsoe 4096 maj 26 15 :43 exercises -rw-rw-r-- 1 bbrydsoe bbrydsoe 296399 jan 16 23 :33 exercises.tar.gz drwxrwxr-x 31 bbrydsoe bbrydsoe 4096 maj 23 10 :54 hpc2n drwxrwxr-x 5 bbrydsoe bbrydsoe 4096 apr 5 12 :56 HPC2Ndocs -rw-rw-r-- 1 bbrydsoe bbrydsoe 85 okt 23 2023 hpc2n-faktura.txt ... Create a symbolic link to a file in the same directory as the file ln -s /path/to/file/the-file /path/to/file/<new-name> Create a symbolic link to a library This is to give the library the name is is presumably assumed to have in some program that uses it. Here it is in the same directory. This is how it looks for me: ln -s /home/bbrydsoe/exercises/redirects-env-link/libcoolness.2.0.a /home/bbrydsoe/exercises/redirects-env-link/libcoolness.a Create a symbolic link to a library in a different directory Sometimes a program expects a library to be in another directory than it is. An easy way of solving this is with symlinks - then you do not have to copy the library to perhaps several directories, and redo when it is updated. ln -s /usr/lib64/libfancy.a /usr/lib/libfancy.a Remove a symlink You can remove a symbolic link either with unlink <path-to-symlink> or rm <path-to-symlink> The main benefit of rm over unlink is that you can remove multiple symlinks at once, like you can with files. For me, it looks like this if I remove the symbolic link libcoolness.a I created above: bbrydsoe@enterprise:~/exercises/redirects-env-link$ rm libcoolness.a bbrydsoe@enterprise:~/exercises/redirects-env-link$ Warning When removing a symlink to a folder, do not include the / at the end since that will make bash think the symbolic link is a folder that you cannot remove directly like this. Summary \u00b6 Keypoints Symbolic links are pointers to another file or directory there are both soft/symbolic links and hard links they are useful both for ease and to avoid renaming/copying files you can remove symbolic links with rm or unlink","title":"Symbolic links"},{"location":"sessions/symlinks/#symbolic__links","text":"Symbolic links are also called soft links, or just symlinks. It is a pointer to another file or directory (called the \u201ctarget\u201d). It is useful both for ease you avoid using a long path each time you change to a directory, like your project directory As well as to avoid changing hard links within other scripts or programs. This is good if you for instance install a program or use a script that assumes the library it uses is called libcoolness.a and not libcoolness.2.0.a . You can then just update the symlink instead of renaming the library or updating potentially many instances where it is mentioned in the program. Hard links and soft links You may have heard symbolic links referred to as \u201csoft links\u201d. So what is a hard link? Hard links are also shortcuts for files (not directories), but a hard link cannot be created for a file in a different file system.","title":"Symbolic links"},{"location":"sessions/symlinks/#syntax","text":"Soft link/symbolic link: ln -s real-file-folder-or-lib link-name Hard link: ln source-file linked-file","title":"Syntax"},{"location":"sessions/symlinks/#verify","text":"To verify a soft or hard link, run: ls -l source link","title":"Verify"},{"location":"sessions/symlinks/#examples","text":"Hint You can type along to most of this! Use the files in \u201cexercises\u201d -> \u201credirects-env-links\u201d for examples.","title":"Examples"},{"location":"sessions/symlinks/#hard__links","text":"Hint You can code along! Either use one of the files/directories in \u201cexercises\u201d -> \u201credirect-env-link\u201d or create a file to play with. This should work: echo 'This is my test file' > testfile Create a hard link, files ln testfile linkfile To check what happened, do this: ls -li testfile linkfile My output: $ ls -li total 8 808864781 -rw-r--r-- 2 bbrydsoe folk 21 May 27 16 :36 linkfile 808864781 -rw-r--r-- 2 bbrydsoe folk 21 May 27 16 :36 testfile 808864781 is the inode, which is identical. An inode (index node) is a concept in Linux/Unix. Each object in a filesystem is represented by an inode. It is a data structure which stores basic info about files, directories, or other file system objects. More here if you are interested: Understanding UNIX / Linux filesystem Inodes .","title":"Hard links"},{"location":"sessions/symlinks/#softsymbolic__links","text":"Create a symbolic link to a directory ln -s /path/to/home/exercises/redirects-env-link $HOME /exer This creates a symbolic link named \u201cexer\u201d in the home directory, pointing to the location /path/to/home/exercises/redirects-env-link. For me, this would look like this: bbrydsoe@enterprise:~/exercises/redirects-env-link$ pwd /home/bbrydsoe/exercises/redirects-env-link bbrydsoe@enterprise:~/exercises/redirects-env-link$ ln -s /home/bbrydsoe/exercises/redirects-env-link $HOME /exer bbrydsoe@enterprise:~$ cd bbrydsoe@enterprise:~$ ls -l ... drwxrwxr-x 6 bbrydsoe bbrydsoe 4096 nov 13 2023 course-intro-git drwxr-xr-x 8 bbrydsoe bbrydsoe 4096 maj 25 14 :53 Desktop drwxr-xr-x 6 bbrydsoe bbrydsoe 4096 jun 20 2024 Documents drwxr-xr-x 22 bbrydsoe bbrydsoe 20480 maj 26 15 :13 Downloads drwxrwxr-x 2 bbrydsoe bbrydsoe 4096 maj 21 09 :10 examples lrwxrwxrwx 1 bbrydsoe bbrydsoe 43 maj 26 19 :36 exer -> /home/bbrydsoe/exercises/redirects-env-link drwxr-xr-x 8 bbrydsoe bbrydsoe 4096 maj 26 15 :43 exercises -rw-rw-r-- 1 bbrydsoe bbrydsoe 296399 jan 16 23 :33 exercises.tar.gz drwxrwxr-x 31 bbrydsoe bbrydsoe 4096 maj 23 10 :54 hpc2n drwxrwxr-x 5 bbrydsoe bbrydsoe 4096 apr 5 12 :56 HPC2Ndocs -rw-rw-r-- 1 bbrydsoe bbrydsoe 85 okt 23 2023 hpc2n-faktura.txt ... Create a symbolic link to a file in the same directory as the file ln -s /path/to/file/the-file /path/to/file/<new-name> Create a symbolic link to a library This is to give the library the name is is presumably assumed to have in some program that uses it. Here it is in the same directory. This is how it looks for me: ln -s /home/bbrydsoe/exercises/redirects-env-link/libcoolness.2.0.a /home/bbrydsoe/exercises/redirects-env-link/libcoolness.a Create a symbolic link to a library in a different directory Sometimes a program expects a library to be in another directory than it is. An easy way of solving this is with symlinks - then you do not have to copy the library to perhaps several directories, and redo when it is updated. ln -s /usr/lib64/libfancy.a /usr/lib/libfancy.a Remove a symlink You can remove a symbolic link either with unlink <path-to-symlink> or rm <path-to-symlink> The main benefit of rm over unlink is that you can remove multiple symlinks at once, like you can with files. For me, it looks like this if I remove the symbolic link libcoolness.a I created above: bbrydsoe@enterprise:~/exercises/redirects-env-link$ rm libcoolness.a bbrydsoe@enterprise:~/exercises/redirects-env-link$ Warning When removing a symlink to a folder, do not include the / at the end since that will make bash think the symbolic link is a folder that you cannot remove directly like this.","title":"Soft/symbolic links"},{"location":"sessions/symlinks/#summary","text":"Keypoints Symbolic links are pointers to another file or directory there are both soft/symbolic links and hard links they are useful both for ease and to avoid renaming/copying files you can remove symbolic links with rm or unlink","title":"Summary"},{"location":"sessions/wc_cut/","text":"Linux tools - wc and cut \u00b6 Learning objectives learn about wc try some examples with wc learn about cut try some examples with cut wc \u00b6 The Linux wc command calculates a file\u2019s word, line, character, or byte count (returning the values in that order from left to right). Syntax \u00b6 wc <options> file Some common options -l : list number of lines per file -m : list number of characters per file -w : list number of words per file Examples \u00b6 To run the examples, go to the \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d directory where there are files that are suitable to run these examples on. Hint Type along! wc on a file $ wc FILE Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ wc myfile1.txt 4 15 80 myfile1.txt wc counted the number of lines, words, and characters in the file \u201cmyfile1.txt\u201d. It says there are 4 lines , 15 words , and 80 characters . wc on several files Let us run wc on all files with suffix .txt $ wc *.txt Output: 1 9 45 fil2.txt 1 9 43 fil3.txt 2 10 48 fil4.txt 4 22 128 file.txt 1 6 34 fil.txt 0 0 0 myfile0.txt 4 15 80 myfile1.txt 2 10 48 myfile2.txt 7 38 203 myfile3.txt 0 0 0 myfiles.txt 4 22 128 newfile.txt 12 12 33 numbers.txt 0 0 0 thisfile0.txt 0 0 0 thisfile1.txt 0 0 0 thisfile2.txt 0 0 0 thisfile3.txt 0 0 0 thisfile4.txt 0 0 0 thisfile5.txt 0 0 0 thisfile6.txt 0 0 0 thisfile7.txt 0 0 0 thisfile8.txt 0 0 0 thisfile9.txt 0 0 0 thisfile.txt 38 153 790 total All lines, words, characters in the files with the extension .txt. Also sums up the total. wc -l to get only the number of lines in a file $ wc -l FILE Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ wc -l myfile2.txt 2 myfile2.txt wc combined with a pipe and sort to get the files with suffix .txt in a given order $ wc *.txt | sort -n Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ wc *.txt | sort -n 0 0 0 myfile0.txt 0 0 0 myfiles.txt 0 0 0 thisfile0.txt 0 0 0 thisfile1.txt 0 0 0 thisfile2.txt 0 0 0 thisfile3.txt 0 0 0 thisfile4.txt 0 0 0 thisfile5.txt 0 0 0 thisfile6.txt 0 0 0 thisfile7.txt 0 0 0 thisfile8.txt 0 0 0 thisfile9.txt 0 0 0 thisfile.txt 1 6 34 fil.txt 1 9 43 fil3.txt 1 9 45 fil2.txt 2 10 48 fil4.txt 2 10 48 myfile2.txt 4 15 80 myfile1.txt 4 22 128 file.txt 4 22 128 newfile.txt 7 38 203 myfile3.txt 12 12 33 numbers.txt 38 153 790 total wc with no input If you just do wc without giving any files as input, it will assume it should wait for input. If you just want to escape this, you can do it with CTRL-C (Press the CTRL key and hold it down, then press the C key). wc - capturing output Assume you have a large number of files that you want to run wc on. Then it will not work well to just get the output thrown to screen. It would be much better to get the output to a file, and you can do that this way: $ wc -l *.txt > filelength.txt This will take the number of lines for each file and put to the file \u201cfilelength.txt\u201d. You can then look inside that file: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ wc -l *.txt > filelength.txt bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cat filelength.txt 1 fil2.txt 1 fil3.txt 2 fil4.txt 4 file.txt 1 fil.txt 0 myfile0.txt 4 myfile1.txt 2 myfile2.txt 7 myfile3.txt 0 myfiles.txt 4 newfile.txt 12 numbers.txt 0 thisfile0.txt 0 thisfile1.txt 0 thisfile2.txt 0 thisfile3.txt 0 thisfile4.txt 0 thisfile5.txt 0 thisfile6.txt 0 thisfile7.txt 0 thisfile8.txt 0 thisfile9.txt 0 thisfile.txt 38 total If you have a lot if files, and so a lot of entries in the \u201cfilelength.txt\u201d, it might be better to use something like \u201cless\u201d to look in it so you can look through the file instead of getting it all output to screen. Exercise \u00b6 Exercise The \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d directory is where there are files that are suitable to run these examples on. Use the correct option to wc to count the number of words in \u201cfile.txt\u201d Use the correct option to wc to count the number of characters in \u201cnumbers.txt\u201d How many lines are there in total in all the files in the directory \u201cpiping-wc-cut\u201d? cut \u00b6 cut is a command which is used to extract sections from each line of input. Syntax \u00b6 cut [ -b list ] [ -c list ] [ -f list ] [ -n ] [ -d delim ] [ -s ] [ file ] Extraction of line segments can typically be done by options/flags bytes ( -b ) characters ( -c ) fields ( -f ) separated by a delimiter ( -d \u2014 the tab character by default). A range must be provided in each case which consists of one of N , N-M , N- (N to the end of the line), or -M (beginning of the line to M), where N and M are counted from 1 (there is no zeroth value). The options -n in combination with -b suppresses splits of multi-byte characters. -s bypasses lines which contain no field delimiters when -f is specified, unless otherwise indicated. Examples \u00b6 We are again going to use the directory \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d as a source of files that are suitable to run these examples on. cut with the -b flag The -b n option returns the first n bytes of a line. $ cut -b n FILE Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -b 1 newfile.txt T S S M bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -b 2 newfile.txt h o t u bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -b 2 -5 newfile.txt his o ma trin uaha For reference, this is how the file looks: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cat newfile.txt This is a file with some strings. How many instances of string are there? So many times string! String string string! Muahahaha cut with the -c flag A list following -c specifies a range of characters which will be returned bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -c 2 -5 newfile.txt his o ma trin uaha Note! No difference between the -b and -c option right now. However, adding multibyte support is in progress and may enable a different behaviour of these two options in the future! cut with the -f and delimiter flags $ cut -d \"A-DELIMITER\" -f FIELD-LIST Click to see content of file thisfile8.txt bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cat thisfile8.txt Hello:helloe:hello:hi there! What is this! Is this a list: yes, this, is, a, list Weird list? Normal list: 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 Why not? I need a tab I will write a longer sentence: there is a delimiter colon in this line One more line that has a tab and one more and another hahahaha Delimiter \u201d \u201d (space) and fields 2-4: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 2 -4 -d \" \" thisfile8.txt there! is this! Is list? Normal list: not? I need a will write a more line that Delimiter \u201c:\u201d (colon) and fields 2-4: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 2 -4 -d \":\" thisfile8.txt helloe:hello:hi there! yes, this, is, a, list 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 Why not? I need a tab there is a delimiter colon in this line One more line that has a tab and one more and another hahahaha Delimiter \u201c:\u201d (colon) and fields 3- (from 3 to the end): bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 3 - -d \":\" thisfile8.txt hello:hi there! Why not? I need a tab One more line that has a tab and one more and another hahahaha Default delimiter (tab) and fields 3-4: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 3 -4 thisfile8.txt Hello:helloe:hello:hi there! What is this! Is this a list: yes, this, is, a, list Weird list? Normal list: 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 I will write a longer sentence: there is a delimiter colon in this line and one more and another Info -c option is useful for fixed-length lines. Most unix files doesn\u2019t have fixed-length lines. To extract the useful information you need to cut by fields rather than columns. List of the fields number specified must be separated by comma. Ranges are not described with -f option. cut uses tab as a default field delimiter but can also work with other delimiter by using -d option. Example: columns of data Here we work with the file \u201cdata.dat\u201d which is in the same directory as the other files. Content of data.dat - click to reveal bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cat data.dat 123 456 5685 6969 124 346 7322 5732 321 124 1546 1632 111 763 1242 1421 Cutting column 2 and 3: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 2 ,3 -d \" \" data.dat 456 5685 346 7322 124 1546 763 1242 Exercises \u00b6 Exercise The \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d directory is where there are files that are suitable to run these examples on. Use cut and suitable option(s) to print column 1 and 4 of the file \u201cdata.dat\u201d Create a file where you use \u201c:\u201d delimiters in. Use cut for different combination of fields and this delimiter See that you get the same output with options -c and -b for the files you try Output the first 4 characters of each line for a file you pick Summary \u00b6 Keypoints we have learned about wc and tried the options -l (lines), -m (characters), and -w (words) we have learned about cut and tried the options for selecting with bytes , characters , fields , and ysed delimiters","title":"Linux tools (wc, cut)"},{"location":"sessions/wc_cut/#linux__tools__-__wc__and__cut","text":"Learning objectives learn about wc try some examples with wc learn about cut try some examples with cut","title":"Linux tools - wc and cut"},{"location":"sessions/wc_cut/#wc","text":"The Linux wc command calculates a file\u2019s word, line, character, or byte count (returning the values in that order from left to right).","title":"wc"},{"location":"sessions/wc_cut/#syntax","text":"wc <options> file Some common options -l : list number of lines per file -m : list number of characters per file -w : list number of words per file","title":"Syntax"},{"location":"sessions/wc_cut/#examples","text":"To run the examples, go to the \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d directory where there are files that are suitable to run these examples on. Hint Type along! wc on a file $ wc FILE Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ wc myfile1.txt 4 15 80 myfile1.txt wc counted the number of lines, words, and characters in the file \u201cmyfile1.txt\u201d. It says there are 4 lines , 15 words , and 80 characters . wc on several files Let us run wc on all files with suffix .txt $ wc *.txt Output: 1 9 45 fil2.txt 1 9 43 fil3.txt 2 10 48 fil4.txt 4 22 128 file.txt 1 6 34 fil.txt 0 0 0 myfile0.txt 4 15 80 myfile1.txt 2 10 48 myfile2.txt 7 38 203 myfile3.txt 0 0 0 myfiles.txt 4 22 128 newfile.txt 12 12 33 numbers.txt 0 0 0 thisfile0.txt 0 0 0 thisfile1.txt 0 0 0 thisfile2.txt 0 0 0 thisfile3.txt 0 0 0 thisfile4.txt 0 0 0 thisfile5.txt 0 0 0 thisfile6.txt 0 0 0 thisfile7.txt 0 0 0 thisfile8.txt 0 0 0 thisfile9.txt 0 0 0 thisfile.txt 38 153 790 total All lines, words, characters in the files with the extension .txt. Also sums up the total. wc -l to get only the number of lines in a file $ wc -l FILE Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ wc -l myfile2.txt 2 myfile2.txt wc combined with a pipe and sort to get the files with suffix .txt in a given order $ wc *.txt | sort -n Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ wc *.txt | sort -n 0 0 0 myfile0.txt 0 0 0 myfiles.txt 0 0 0 thisfile0.txt 0 0 0 thisfile1.txt 0 0 0 thisfile2.txt 0 0 0 thisfile3.txt 0 0 0 thisfile4.txt 0 0 0 thisfile5.txt 0 0 0 thisfile6.txt 0 0 0 thisfile7.txt 0 0 0 thisfile8.txt 0 0 0 thisfile9.txt 0 0 0 thisfile.txt 1 6 34 fil.txt 1 9 43 fil3.txt 1 9 45 fil2.txt 2 10 48 fil4.txt 2 10 48 myfile2.txt 4 15 80 myfile1.txt 4 22 128 file.txt 4 22 128 newfile.txt 7 38 203 myfile3.txt 12 12 33 numbers.txt 38 153 790 total wc with no input If you just do wc without giving any files as input, it will assume it should wait for input. If you just want to escape this, you can do it with CTRL-C (Press the CTRL key and hold it down, then press the C key). wc - capturing output Assume you have a large number of files that you want to run wc on. Then it will not work well to just get the output thrown to screen. It would be much better to get the output to a file, and you can do that this way: $ wc -l *.txt > filelength.txt This will take the number of lines for each file and put to the file \u201cfilelength.txt\u201d. You can then look inside that file: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ wc -l *.txt > filelength.txt bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cat filelength.txt 1 fil2.txt 1 fil3.txt 2 fil4.txt 4 file.txt 1 fil.txt 0 myfile0.txt 4 myfile1.txt 2 myfile2.txt 7 myfile3.txt 0 myfiles.txt 4 newfile.txt 12 numbers.txt 0 thisfile0.txt 0 thisfile1.txt 0 thisfile2.txt 0 thisfile3.txt 0 thisfile4.txt 0 thisfile5.txt 0 thisfile6.txt 0 thisfile7.txt 0 thisfile8.txt 0 thisfile9.txt 0 thisfile.txt 38 total If you have a lot if files, and so a lot of entries in the \u201cfilelength.txt\u201d, it might be better to use something like \u201cless\u201d to look in it so you can look through the file instead of getting it all output to screen.","title":"Examples"},{"location":"sessions/wc_cut/#exercise","text":"Exercise The \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d directory is where there are files that are suitable to run these examples on. Use the correct option to wc to count the number of words in \u201cfile.txt\u201d Use the correct option to wc to count the number of characters in \u201cnumbers.txt\u201d How many lines are there in total in all the files in the directory \u201cpiping-wc-cut\u201d?","title":"Exercise"},{"location":"sessions/wc_cut/#cut","text":"cut is a command which is used to extract sections from each line of input.","title":"cut"},{"location":"sessions/wc_cut/#syntax_1","text":"cut [ -b list ] [ -c list ] [ -f list ] [ -n ] [ -d delim ] [ -s ] [ file ] Extraction of line segments can typically be done by options/flags bytes ( -b ) characters ( -c ) fields ( -f ) separated by a delimiter ( -d \u2014 the tab character by default). A range must be provided in each case which consists of one of N , N-M , N- (N to the end of the line), or -M (beginning of the line to M), where N and M are counted from 1 (there is no zeroth value). The options -n in combination with -b suppresses splits of multi-byte characters. -s bypasses lines which contain no field delimiters when -f is specified, unless otherwise indicated.","title":"Syntax"},{"location":"sessions/wc_cut/#examples_1","text":"We are again going to use the directory \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d as a source of files that are suitable to run these examples on. cut with the -b flag The -b n option returns the first n bytes of a line. $ cut -b n FILE Output: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -b 1 newfile.txt T S S M bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -b 2 newfile.txt h o t u bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -b 2 -5 newfile.txt his o ma trin uaha For reference, this is how the file looks: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cat newfile.txt This is a file with some strings. How many instances of string are there? So many times string! String string string! Muahahaha cut with the -c flag A list following -c specifies a range of characters which will be returned bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -c 2 -5 newfile.txt his o ma trin uaha Note! No difference between the -b and -c option right now. However, adding multibyte support is in progress and may enable a different behaviour of these two options in the future! cut with the -f and delimiter flags $ cut -d \"A-DELIMITER\" -f FIELD-LIST Click to see content of file thisfile8.txt bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cat thisfile8.txt Hello:helloe:hello:hi there! What is this! Is this a list: yes, this, is, a, list Weird list? Normal list: 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 Why not? I need a tab I will write a longer sentence: there is a delimiter colon in this line One more line that has a tab and one more and another hahahaha Delimiter \u201d \u201d (space) and fields 2-4: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 2 -4 -d \" \" thisfile8.txt there! is this! Is list? Normal list: not? I need a will write a more line that Delimiter \u201c:\u201d (colon) and fields 2-4: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 2 -4 -d \":\" thisfile8.txt helloe:hello:hi there! yes, this, is, a, list 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 Why not? I need a tab there is a delimiter colon in this line One more line that has a tab and one more and another hahahaha Delimiter \u201c:\u201d (colon) and fields 3- (from 3 to the end): bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 3 - -d \":\" thisfile8.txt hello:hi there! Why not? I need a tab One more line that has a tab and one more and another hahahaha Default delimiter (tab) and fields 3-4: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 3 -4 thisfile8.txt Hello:helloe:hello:hi there! What is this! Is this a list: yes, this, is, a, list Weird list? Normal list: 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 I will write a longer sentence: there is a delimiter colon in this line and one more and another Info -c option is useful for fixed-length lines. Most unix files doesn\u2019t have fixed-length lines. To extract the useful information you need to cut by fields rather than columns. List of the fields number specified must be separated by comma. Ranges are not described with -f option. cut uses tab as a default field delimiter but can also work with other delimiter by using -d option. Example: columns of data Here we work with the file \u201cdata.dat\u201d which is in the same directory as the other files. Content of data.dat - click to reveal bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cat data.dat 123 456 5685 6969 124 346 7322 5732 321 124 1546 1632 111 763 1242 1421 Cutting column 2 and 3: bbrydsoe@enterprise:~/exercises/piping-wc-cut$ cut -f 2 ,3 -d \" \" data.dat 456 5685 346 7322 124 1546 763 1242","title":"Examples"},{"location":"sessions/wc_cut/#exercises","text":"Exercise The \u201cexercises\u201d -> \u201cpiping-wc-cut\u201d directory is where there are files that are suitable to run these examples on. Use cut and suitable option(s) to print column 1 and 4 of the file \u201cdata.dat\u201d Create a file where you use \u201c:\u201d delimiters in. Use cut for different combination of fields and this delimiter See that you get the same output with options -c and -b for the files you try Output the first 4 characters of each line for a file you pick","title":"Exercises"},{"location":"sessions/wc_cut/#summary","text":"Keypoints we have learned about wc and tried the options -l (lines), -m (characters), and -w (words) we have learned about cut and tried the options for selecting with bytes , characters , fields , and ysed delimiters","title":"Summary"},{"location":"sessions/awk/","text":"AWK \u00b6 Need a video? Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Feedback Conclusion Learning outcomes Learners can use awk Learners have practiced using a book on AWK Learners can use awk in pipes Learners can use awk to read a specific column Learners can use awk to transform text Learners can use regular expressions in awk Learners have practiced reading bash commands For teachers Lesson plan: Time Minutes Duration Description 11:20-11:25 0-5 5 Prior 11:25-11:30 5-10 5 Present 11:30-11:50 10-30 20 Challenge 11:50-12:00 30-40 10 Feedback Prior: Imagine a file that contains plain-text tabular data. How would you work with it? What is a Turing-complete programming language? What is AWK (in upper case)? What is awk (in lower case)? Why is AWK important? \u00b6 AWK is a programming language for text processing that is included with Linux. As a Turing-complete programming language, it can -by definition- solve any computational problem. The different spellings Spelling Description AWK The programming language awk The program Awk A common misspelling Exercises \u00b6 In these exercises, we\u2019ll be using the Bash Guide for Beginners , because this free online book fits this course well and allows you to continue studying after this course. Exercise 1: printing selected fields \u00b6 Read the text at chapter 6.2.1: \u2018Printing selected fields\u2019 . Exercise 1.1: understanding the first part \u00b6 The single line of code in this subsection uses a pipe. Run the command until the pipe. What do you see? How do you explain in English what this does? Answer This is the full command shows in this subsection: ls -l | awk '{ print $5 $9 }' The command before the pipe is: ls -l When running it, you will see something similar to: $ ls -l total 4 drwxrwxr-x 2 sven sven 4096 Jun 10 2024 bin drwxr-xr-x 2 sven sven 4096 Jan 8 20 :05 Desktop drwxr-xr-x 10 sven sven 4096 Feb 27 09 :44 Documents drwxr-xr-x 3 sven sven 4096 May 28 08 :51 Downloads Searching the manual of ls , using man ls , gives us the following description of the -l flag: -l use a long listing format Hence, ls -l lists files in the current folder using a long listing format. Exercise 1.2: understanding the awk part \u00b6 The single line of code in this subsection forwards its output (from ls ) to awk . Run it. What do you see? How do you explain in English what this does? Answer The command to run is: ls -l | awk '{ print $5 $9 }' When running it, you will see something similar to: $ ls -l | awk '{ print $5 $9 }' 4096bin 4096Desktop 4096Documents 4096Downloads In English: from a list of files (in long format), show the fifth and ninth columns. Exercise 1.3: how awk deals with missing columns \u00b6 The command shows the fifth and ninth columns of a list of files (in long format). How does awk deal with lines that do not have a fifth and/or ninth column? Answer When running the command, we have already seen the empty first line of output: $ ls -l | awk '{ print $5 $9 }' 4096bin 4096Desktop 4096Documents 4096Downloads Hence, if there is no fifth and/or ninth column to display, awk shows an empty line (optional) Exercise 1.4: awk versus cut \u00b6 Try to use cut (and only cut !) to achieve the same, by selecting the same columns. This will not work! Observe and explain what you see. Answer To get the most similar output, we need to use columns 6 and 10: $ ls -l | cut --delimiter \" \" --fields 6 ,10 sven sven 8 4096 Documents This is not because we actually wanted to use columns 6 and 10: Due to the multiple and varying amount of spaces in each line, the counting is off. If you know the tr command, you can remove duplicate spaces: $ ls -l | tr --squeeze-repeats \" \" | cut --delimiter \" \" --fields 5 ,9 4096 bin 4096 Desktop 4096 Documents 4096 Downloads The output does put a space between the columns, we can remove that too: $ ls -l | tr --squeeze-repeats \" \" | cut --delimiter \" \" --fields 5 ,9 | tr --delete \" \" 4096bin 4096Desktop 4096Documents 4096Downloads Exercise 2: printing selected fields \u00b6 Read the text at chapter 6.2.2: \u2018Formatting fields\u2019 Exercise 2.1: understanding the first part \u00b6 The first code example in this subsection uses multiple pipes. Run the command until the first pipe. What do you see? How do you explain in English what this does? Use the ls manual. Answer The first code example in this subsection is: ls -ldh * | grep -v total | awk ' { print \"Size is \" $5 \" bytes for \" $9 } The command until the first pipe is: ls -ldh * Running it shows something similar to this: $ ls -ldh * drwxrwxr-x 2 sven sven 4 .0K Jun 10 2024 bin drwxr-xr-x 2 sven sven 4 .0K Jan 8 20 :05 Desktop drwxr-xr-x 10 sven sven 4 .0K Feb 27 09 :44 Documents drwxr-xr-x 3 sven sven 4 .0K May 28 08 :51 Downloads Using the manual of ls : man ls In English: the command shows the list of files and directories ( ls ) \u2026 in a long format ( -l ) with directories as themselves ( -d , also --directory , i.e. not their contents) in a human-readable format ( -h , also --human-readable ). Exercise 2.2: understanding the second part \u00b6 The first code example in this subsection uses multiple pipes. Run the command until the second pipe. What do you see? How do you explain in English what this does? Answer The first code example in this subsection is: ls -ldh * | grep -v total | awk ' { print \"Size is \" $5 \" bytes for \" $9 } The command until the second pipe is: ls -ldh * | grep -v total Running it shows something similar to this: $ ls -ldh * | grep -v total drwxrwxr-x 2 sven sven 4 .0K Jun 10 2024 bin drwxr-xr-x 2 sven sven 4 .0K Jan 8 20 :05 Desktop drwxr-xr-x 10 sven sven 4 .0K Feb 27 09 :44 Documents drwxr-xr-x 3 sven sven 4 .0K May 28 08 :51 Downloads Note that, for the computer used, there is no difference. In English: the command shows the list of files for lines that have no match ( -v , also --invert-match ) to the regular expression total . Or shorter: it shows the content, excluding a possible final line that shows the total file size. Exercise 2.3: understanding the awk part \u00b6 The first code example in this subsection uses multiple pipes. Run the command in full. What do you see? Answer The first code example in this subsection is: ls -ldh * | grep -v total | awk '{ print \"Size is \" $5 \" bytes for \" $9 }' Running it shows something similar to this: $ ls -ldh * | grep -v total | awk '{ print \"Size is \" $5 \" bytes for \" $9 }' Size is 4 .0K bytes for bin Size is 4 .0K bytes for Desktop Size is 4 .0K bytes for Documents Size is 4 .0K bytes for Downloads Exercise 2.4: understanding the single quote \u00b6 A first thing to notice is that the awk command is put into a single quote ' (instead of a double-quote, \" ). Why is that? Answer Text between single quote is used as-is: $ echo 'He said: \"Hi!\".' He said: \"Hi!\" . Where the other way around, the ! triggers something: $ echo \"He said: 'Hi!'.\" bash: ! ' .: event not found (Optional) Exercise 2.5: using commas between elements to print \u00b6 Zooming in on the printing of awk , i.e. the part print \"Size is \" $5 \" bytes for \" $9 , we can see that the elements to be printed are separated by a space. This is unlike most (?all) modern languages, where elements are separated by a comma. Rewrite the expression to use a comma between the elements. Answer The first attempt would be: ls -ldh * | grep -v total | awk '{ print \"Size is \", $5, \" bytes for \", $9 }' This, however, gives double spaces now: $ ls -ldh * | grep -v total | awk '{ print \"Size is \", $5, \" bytes for \", $9 }' Size is 4 .0K bytes for bin Size is 4 .0K bytes for Desktop Size is 4 .0K bytes for Documents Size is 4 .0K bytes for Downloads Removing the spaces between the double-quotes ( \" ) solves this: ls -ldh * | grep -v total | awk '{ print \"Size is\", $5, \"bytes for\", $9 }' The output will look similar to this: $ ls -ldh * | grep -v total | awk '{ print \"Size is\", $5, \"bytes for\", $9 }' Size is 4 .0K bytes for bin Size is 4 .0K bytes for Desktop Size is 4 .0K bytes for Documents Size is 4 .0K bytes for Downloads Exercise 3: regular expressions \u00b6 Read the text at chapter 6.2.3: \u2018The print command and regular expressions\u2019 Exercise 3.1: understanding the first part \u00b6 The first code example in this subsection uses a pipe. Run the command until the pipe. What do you see? How do you explain in English what this does? Use the df manual. Answer The first code example in this subsection is: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' The command until the pipe is: df -h Running it shows something similar to this: $ df -h Filesystem Size Used Avail Use% Mounted on tmpfs 1 .6G 2 .9M 1 .6G 1 % /run /dev/nvme0n1p2 468G 226G 219G 51 % / tmpfs 7 .6G 29M 7 .6G 1 % /dev/shm tmpfs 5 .0M 8 .0K 5 .0M 1 % /run/lock efivarfs 438K 293K 141K 68 % /sys/firmware/efi/efivars /dev/nvme0n1p1 511M 73M 439M 15 % /boot/efi tmpfs 1 .6G 148K 1 .6G 1 % /run/user/1000 Using the manual of df : man df In English: show the file system space usage ( df ) in a human-readable format ( -h , also --human-readable ). Exercise 3.2: understanding the awk part \u00b6 Run the command in full. What do you see? Tip: if you see nothing, use df -h | awk '/dev\\// { print $6 \"\\t: \" $5 }' Answer The first code example in this subsection is: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' Running it shows something similar to this: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' On the computer used, this shows no output. Running the alternative: $ df -h | awk '/dev\\// { print $6 \"\\t: \" $5 }' / : 51 % /dev/shm : 1 % /boot/efi : 15 % It shows the percentage of disk space in use for all the devices that have dev in the name. Exercise 3.3: understanding the regular expression \u00b6 This awk command uses a regular expression. What is it exactly ? If it is formatted \u2018weirdly\u2019, why is that? Answer The first code example in this subsection is: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' The exact regular expression is the exact text between the (unescaped) slashes: dev \\/ hd This is formatted \u2018weirdly\u2019, as it uses \\/ instead of just / . This is because awk uses / to indicate the start and end of a regular expression. Hence, for the same character to be part of that regular expression, it is escaped using a backslash. Exercise 3.4: understanding the \\t \u00b6 In the awk command, there is a \\t in the printing part. What does it do, and why is it written like that? Answer The first code example in this subsection is: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' The \\t prints a tab. It is written like that, as \\t is simply decided as the way how we write a tab, similar to the convention that \\n is a newline. (optional) Exercise 4: can awk do \u2026? \u00b6 AWK is a Turning complete language, hence the answer to \u2018Can AWK do \u2026?\u2019 (applied to text) is always true. Below are some question you may have and how to solve this in awk . Pick those topics you are interested in. (optional) Exercise 4.1: Can awk display all columns? Can awk display all columns? Or: upon a match, can awk display the whole line? The answer is: yes! Read the text at subsection 6.2.1: \u2018Printing selected fields . Use a pipe to direct the output of ls -l to awk , where the whole line is printed. Answer The symbol $0 is used for \u2018all columns\u2019/\u2019the whole line\u2019: ls -l | awk '{ print $0 }' On its own, this program is not useful: it just echoes its input. $0 becomes useful when used with other awk features, such as matching lines for a regular expression: $ ls -l | awk '/Feb/ { print $0 }' drwxr-xr-x 10 sven sven 4096 Feb 27 09 :44 Documents drwxrwxr-x 6 sven sven 4096 Feb 7 07 :18 inkcut_venv drwxrwxr-x 2 sven sven 4096 Feb 25 11 :38 misc drwx------ 2 sven sven 4096 Feb 25 13 :45 my_folder (optional) Exercise 4.2: Can awk display the line number? Can awk display the line number? Read the text at chapter 6.3.3: \u2018The number of records\u2019 . The answer is: yes! Use a pipe to direct the output of ls -l to awk , where the line number and the values in the first are printed Answer ls -l | awk '{ print NR,$1 }' When printing the content of a file, with number lines, use can use both awk and cat : ls -l | awk '{ print NR,$0 }' ls -l | cat --number (optional) Exercise 4.3: Can awk display the number of columns? Can awk display the number of column? The answer is: yes! To do so, print the variable NF , as shown in the program below: awk '{ print NF }' Use a pipe to direct the output of ls -l to awk , where the number of columns are printed Answer ls -l | awk '{ print NF }' (optional) Exercise 4.4: Can awk display the last column? Can awk display the last column? The answer is: yes! To do so, print the variable $NF , as shown in the program below: awk '{ print $NF }' Use a pipe to direct the output of ls -l to awk , where the value in the first and last column are printed Answer ls -l | awk '{ print $1,$NF }' (optional) Exercise 4.5: Can awk count the number of lines? Can awk count the number of lines? The answer is: yes! Read the text at chapter 6.3.3: \u2018The number of records\u2019 . Use a pipe to direct the output of ls -l to awk , where the number of lines is printed. Answer A good first guess, but incorrect, is to use the command below, which is good for numbering lines: ls -l | awk '{ print NR }' The last number is indeed the number of lines. The AWK way to solve it, is to use the END clause, which is only run at the end: ls -l | awk 'END { print NR }' NR only becomes useful when used with other awk features, such printing a descriptive text around it: ls -l | awk 'END { print \"Number of lines:\", NR }' There are many ways to print the number of lines, such as to combine the incorrect awk way with tail : ls -l | awk '{ print NR }' | tail -n 1 Clumsy, but it works. Alternatively, wc is made exactly for the purpose of counting lines: ls -l | wc --lines (optional) Exercise 4.7: Can awk work on comma-separated files? Can awk work on comma-separated files? The answer is: yes! Read the text at chapter 6.2.4: \u2018The input field separator\u2019 . Here we convert the output of ls -l to its comma-separated equivalent: ls -l | tr -s ' ' ',' Using this input, use a pipe to show the fifth and ninth column. Answer ls -l | tr -s ' ' ',' | awk 'BEGIN { FS=\",\" } { print $5, $9 }' Alternatively; ls -l | tr -s ' ' ',' | awk --field-separator \",\" '{ print $5, $9 }' (optional) Exercise 4.8: Can awk show something once at the start? Can awk show something once at the start? The answer is: yes! Read the text at chapter 6.2.4: \u2018Special patterns\u2019 . Use a pipe to direct the output of ls -l to awk , where the text Permissions: is shown, after which the values in the first column are shown. If the word total shows up in your results, you can ignore it for this exercise. Answer ls -l | awk 'BEGIN { print \"Permissions:\" } { print $1 }' If you do not want total in your results, use a regular expression for \u2018lines starting with a d or a dash\u2019: ls -l | awk 'BEGIN { print \"Permissions:\" } /^[d\\-]/ { print $1 }' (optional) Exercise 4.9: Can awk show something once at the end? Can awk show something once at the end? The answer is: yes! Read the text at chapter 6.2.4: \u20186.2.4. Special patterns\u2019 . Use a pipe to direct the output of ls -l to awk , after which the values in the first column are shown. At the end of the output, it should show the text Done! If the word total shows up in your results, you can ignore it for this exercise. Answer ls -l | awk '{ print $1 } END { print \"Done!\" }' If you do not want total in your results, use a regular expression for \u2018lines starting with a d or a dash\u2019: ls -l | awk '/^[d\\-]/ { print $1 } END { print \"Done!\" }' (optional) Exercise 4.10: Can awk use variables? Can awk use variables? The answer is: yes! Read the text at chapter 6.3.4: \u2018User defined variables\u2019 . Use a pipe to direct the output of ls -l to awk . Sum the values of the fifth column and show it Answer ls -l | awk 'BEGIN { sum = 0 } { sum = sum + $5 } END { print sum }' For teachers What is the difference between AWK and awk ? Answer AWK is the name of the programming language. awk is the name of the program that can run AWK. What can AWK not do? Answer AWK, like any Turning complete language, can solve any computational problem, but cannot do this: run computations at any speed (i.e. a problem may take billions of year to complete) use any amount of memory (i.e. a problem may require billions of gigabytes to solve) When not to use AWK? Answer AWK shines at problems of intermediate complexity. For simple problems, tools such as grep , cut and wc are just as good. For harder problems, use a modern programming language instead, as these have libraries/packages that can, for example, read or analyse an entire table at once. Conclusions \u00b6 Conclusions awk can be used pipes: ls -l | awk '{ print $5 $9 }' awk can be used to read a specific column: ls -l | awk '{ print $5 $9 }' awk can be used to transform text: ls -ldh * | grep -v total | awk '{ print \"Size is \" $5 \" bytes for \" $9 }' awk can use regular expressions: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' awk can do a lot more Learning AWK \u00b6 Learning AWK Learning resource Description A practical guide to learning awk Book about AWK Gawk: Effective AWK Programming Book about AWK Bash Beginners Guide Book with a chapter about AWK Advanced Bash Scripting Guide Book with a chapter about AWK To AWK or not Course about AWK, by Pavlin Mitev AWK course Course about AWK, by Rich\u00e8l Bilderbeek","title":"Using the programming language AWK"},{"location":"sessions/awk/#awk","text":"Need a video? Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Feedback Conclusion Learning outcomes Learners can use awk Learners have practiced using a book on AWK Learners can use awk in pipes Learners can use awk to read a specific column Learners can use awk to transform text Learners can use regular expressions in awk Learners have practiced reading bash commands For teachers Lesson plan: Time Minutes Duration Description 11:20-11:25 0-5 5 Prior 11:25-11:30 5-10 5 Present 11:30-11:50 10-30 20 Challenge 11:50-12:00 30-40 10 Feedback Prior: Imagine a file that contains plain-text tabular data. How would you work with it? What is a Turing-complete programming language? What is AWK (in upper case)? What is awk (in lower case)?","title":"AWK"},{"location":"sessions/awk/#why__is__awk__important","text":"AWK is a programming language for text processing that is included with Linux. As a Turing-complete programming language, it can -by definition- solve any computational problem. The different spellings Spelling Description AWK The programming language awk The program Awk A common misspelling","title":"Why is AWK important?"},{"location":"sessions/awk/#exercises","text":"In these exercises, we\u2019ll be using the Bash Guide for Beginners , because this free online book fits this course well and allows you to continue studying after this course.","title":"Exercises"},{"location":"sessions/awk/#exercise__1__printing__selected__fields","text":"Read the text at chapter 6.2.1: \u2018Printing selected fields\u2019 .","title":"Exercise 1: printing selected fields"},{"location":"sessions/awk/#exercise__11__understanding__the__first__part","text":"The single line of code in this subsection uses a pipe. Run the command until the pipe. What do you see? How do you explain in English what this does? Answer This is the full command shows in this subsection: ls -l | awk '{ print $5 $9 }' The command before the pipe is: ls -l When running it, you will see something similar to: $ ls -l total 4 drwxrwxr-x 2 sven sven 4096 Jun 10 2024 bin drwxr-xr-x 2 sven sven 4096 Jan 8 20 :05 Desktop drwxr-xr-x 10 sven sven 4096 Feb 27 09 :44 Documents drwxr-xr-x 3 sven sven 4096 May 28 08 :51 Downloads Searching the manual of ls , using man ls , gives us the following description of the -l flag: -l use a long listing format Hence, ls -l lists files in the current folder using a long listing format.","title":"Exercise 1.1: understanding the first part"},{"location":"sessions/awk/#exercise__12__understanding__the__awk__part","text":"The single line of code in this subsection forwards its output (from ls ) to awk . Run it. What do you see? How do you explain in English what this does? Answer The command to run is: ls -l | awk '{ print $5 $9 }' When running it, you will see something similar to: $ ls -l | awk '{ print $5 $9 }' 4096bin 4096Desktop 4096Documents 4096Downloads In English: from a list of files (in long format), show the fifth and ninth columns.","title":"Exercise 1.2: understanding the awk part"},{"location":"sessions/awk/#exercise__13__how__awk__deals__with__missing__columns","text":"The command shows the fifth and ninth columns of a list of files (in long format). How does awk deal with lines that do not have a fifth and/or ninth column? Answer When running the command, we have already seen the empty first line of output: $ ls -l | awk '{ print $5 $9 }' 4096bin 4096Desktop 4096Documents 4096Downloads Hence, if there is no fifth and/or ninth column to display, awk shows an empty line","title":"Exercise 1.3: how awk deals with missing columns"},{"location":"sessions/awk/#optional__exercise__14__awk__versus__cut","text":"Try to use cut (and only cut !) to achieve the same, by selecting the same columns. This will not work! Observe and explain what you see. Answer To get the most similar output, we need to use columns 6 and 10: $ ls -l | cut --delimiter \" \" --fields 6 ,10 sven sven 8 4096 Documents This is not because we actually wanted to use columns 6 and 10: Due to the multiple and varying amount of spaces in each line, the counting is off. If you know the tr command, you can remove duplicate spaces: $ ls -l | tr --squeeze-repeats \" \" | cut --delimiter \" \" --fields 5 ,9 4096 bin 4096 Desktop 4096 Documents 4096 Downloads The output does put a space between the columns, we can remove that too: $ ls -l | tr --squeeze-repeats \" \" | cut --delimiter \" \" --fields 5 ,9 | tr --delete \" \" 4096bin 4096Desktop 4096Documents 4096Downloads","title":"(optional) Exercise 1.4: awk versus cut"},{"location":"sessions/awk/#exercise__2__printing__selected__fields","text":"Read the text at chapter 6.2.2: \u2018Formatting fields\u2019","title":"Exercise 2: printing selected fields"},{"location":"sessions/awk/#exercise__21__understanding__the__first__part","text":"The first code example in this subsection uses multiple pipes. Run the command until the first pipe. What do you see? How do you explain in English what this does? Use the ls manual. Answer The first code example in this subsection is: ls -ldh * | grep -v total | awk ' { print \"Size is \" $5 \" bytes for \" $9 } The command until the first pipe is: ls -ldh * Running it shows something similar to this: $ ls -ldh * drwxrwxr-x 2 sven sven 4 .0K Jun 10 2024 bin drwxr-xr-x 2 sven sven 4 .0K Jan 8 20 :05 Desktop drwxr-xr-x 10 sven sven 4 .0K Feb 27 09 :44 Documents drwxr-xr-x 3 sven sven 4 .0K May 28 08 :51 Downloads Using the manual of ls : man ls In English: the command shows the list of files and directories ( ls ) \u2026 in a long format ( -l ) with directories as themselves ( -d , also --directory , i.e. not their contents) in a human-readable format ( -h , also --human-readable ).","title":"Exercise 2.1: understanding the first part"},{"location":"sessions/awk/#exercise__22__understanding__the__second__part","text":"The first code example in this subsection uses multiple pipes. Run the command until the second pipe. What do you see? How do you explain in English what this does? Answer The first code example in this subsection is: ls -ldh * | grep -v total | awk ' { print \"Size is \" $5 \" bytes for \" $9 } The command until the second pipe is: ls -ldh * | grep -v total Running it shows something similar to this: $ ls -ldh * | grep -v total drwxrwxr-x 2 sven sven 4 .0K Jun 10 2024 bin drwxr-xr-x 2 sven sven 4 .0K Jan 8 20 :05 Desktop drwxr-xr-x 10 sven sven 4 .0K Feb 27 09 :44 Documents drwxr-xr-x 3 sven sven 4 .0K May 28 08 :51 Downloads Note that, for the computer used, there is no difference. In English: the command shows the list of files for lines that have no match ( -v , also --invert-match ) to the regular expression total . Or shorter: it shows the content, excluding a possible final line that shows the total file size.","title":"Exercise 2.2: understanding the second part"},{"location":"sessions/awk/#exercise__23__understanding__the__awk__part","text":"The first code example in this subsection uses multiple pipes. Run the command in full. What do you see? Answer The first code example in this subsection is: ls -ldh * | grep -v total | awk '{ print \"Size is \" $5 \" bytes for \" $9 }' Running it shows something similar to this: $ ls -ldh * | grep -v total | awk '{ print \"Size is \" $5 \" bytes for \" $9 }' Size is 4 .0K bytes for bin Size is 4 .0K bytes for Desktop Size is 4 .0K bytes for Documents Size is 4 .0K bytes for Downloads","title":"Exercise 2.3: understanding the awk part"},{"location":"sessions/awk/#exercise__24__understanding__the__single__quote","text":"A first thing to notice is that the awk command is put into a single quote ' (instead of a double-quote, \" ). Why is that? Answer Text between single quote is used as-is: $ echo 'He said: \"Hi!\".' He said: \"Hi!\" . Where the other way around, the ! triggers something: $ echo \"He said: 'Hi!'.\" bash: ! ' .: event not found","title":"Exercise 2.4: understanding the single quote"},{"location":"sessions/awk/#optional__exercise__25__using__commas__between__elements__to__print","text":"Zooming in on the printing of awk , i.e. the part print \"Size is \" $5 \" bytes for \" $9 , we can see that the elements to be printed are separated by a space. This is unlike most (?all) modern languages, where elements are separated by a comma. Rewrite the expression to use a comma between the elements. Answer The first attempt would be: ls -ldh * | grep -v total | awk '{ print \"Size is \", $5, \" bytes for \", $9 }' This, however, gives double spaces now: $ ls -ldh * | grep -v total | awk '{ print \"Size is \", $5, \" bytes for \", $9 }' Size is 4 .0K bytes for bin Size is 4 .0K bytes for Desktop Size is 4 .0K bytes for Documents Size is 4 .0K bytes for Downloads Removing the spaces between the double-quotes ( \" ) solves this: ls -ldh * | grep -v total | awk '{ print \"Size is\", $5, \"bytes for\", $9 }' The output will look similar to this: $ ls -ldh * | grep -v total | awk '{ print \"Size is\", $5, \"bytes for\", $9 }' Size is 4 .0K bytes for bin Size is 4 .0K bytes for Desktop Size is 4 .0K bytes for Documents Size is 4 .0K bytes for Downloads","title":"(Optional) Exercise 2.5: using commas between elements to print"},{"location":"sessions/awk/#exercise__3__regular__expressions","text":"Read the text at chapter 6.2.3: \u2018The print command and regular expressions\u2019","title":"Exercise 3: regular expressions"},{"location":"sessions/awk/#exercise__31__understanding__the__first__part","text":"The first code example in this subsection uses a pipe. Run the command until the pipe. What do you see? How do you explain in English what this does? Use the df manual. Answer The first code example in this subsection is: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' The command until the pipe is: df -h Running it shows something similar to this: $ df -h Filesystem Size Used Avail Use% Mounted on tmpfs 1 .6G 2 .9M 1 .6G 1 % /run /dev/nvme0n1p2 468G 226G 219G 51 % / tmpfs 7 .6G 29M 7 .6G 1 % /dev/shm tmpfs 5 .0M 8 .0K 5 .0M 1 % /run/lock efivarfs 438K 293K 141K 68 % /sys/firmware/efi/efivars /dev/nvme0n1p1 511M 73M 439M 15 % /boot/efi tmpfs 1 .6G 148K 1 .6G 1 % /run/user/1000 Using the manual of df : man df In English: show the file system space usage ( df ) in a human-readable format ( -h , also --human-readable ).","title":"Exercise 3.1: understanding the first part"},{"location":"sessions/awk/#exercise__32__understanding__the__awk__part","text":"Run the command in full. What do you see? Tip: if you see nothing, use df -h | awk '/dev\\// { print $6 \"\\t: \" $5 }' Answer The first code example in this subsection is: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' Running it shows something similar to this: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' On the computer used, this shows no output. Running the alternative: $ df -h | awk '/dev\\// { print $6 \"\\t: \" $5 }' / : 51 % /dev/shm : 1 % /boot/efi : 15 % It shows the percentage of disk space in use for all the devices that have dev in the name.","title":"Exercise 3.2: understanding the awk part"},{"location":"sessions/awk/#exercise__33__understanding__the__regular__expression","text":"This awk command uses a regular expression. What is it exactly ? If it is formatted \u2018weirdly\u2019, why is that? Answer The first code example in this subsection is: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' The exact regular expression is the exact text between the (unescaped) slashes: dev \\/ hd This is formatted \u2018weirdly\u2019, as it uses \\/ instead of just / . This is because awk uses / to indicate the start and end of a regular expression. Hence, for the same character to be part of that regular expression, it is escaped using a backslash.","title":"Exercise 3.3: understanding the regular expression"},{"location":"sessions/awk/#exercise__34__understanding__the__t","text":"In the awk command, there is a \\t in the printing part. What does it do, and why is it written like that? Answer The first code example in this subsection is: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' The \\t prints a tab. It is written like that, as \\t is simply decided as the way how we write a tab, similar to the convention that \\n is a newline.","title":"Exercise 3.4: understanding the \\t"},{"location":"sessions/awk/#optional__exercise__4__can__awk__do","text":"AWK is a Turning complete language, hence the answer to \u2018Can AWK do \u2026?\u2019 (applied to text) is always true. Below are some question you may have and how to solve this in awk . Pick those topics you are interested in. (optional) Exercise 4.1: Can awk display all columns? Can awk display all columns? Or: upon a match, can awk display the whole line? The answer is: yes! Read the text at subsection 6.2.1: \u2018Printing selected fields . Use a pipe to direct the output of ls -l to awk , where the whole line is printed. Answer The symbol $0 is used for \u2018all columns\u2019/\u2019the whole line\u2019: ls -l | awk '{ print $0 }' On its own, this program is not useful: it just echoes its input. $0 becomes useful when used with other awk features, such as matching lines for a regular expression: $ ls -l | awk '/Feb/ { print $0 }' drwxr-xr-x 10 sven sven 4096 Feb 27 09 :44 Documents drwxrwxr-x 6 sven sven 4096 Feb 7 07 :18 inkcut_venv drwxrwxr-x 2 sven sven 4096 Feb 25 11 :38 misc drwx------ 2 sven sven 4096 Feb 25 13 :45 my_folder (optional) Exercise 4.2: Can awk display the line number? Can awk display the line number? Read the text at chapter 6.3.3: \u2018The number of records\u2019 . The answer is: yes! Use a pipe to direct the output of ls -l to awk , where the line number and the values in the first are printed Answer ls -l | awk '{ print NR,$1 }' When printing the content of a file, with number lines, use can use both awk and cat : ls -l | awk '{ print NR,$0 }' ls -l | cat --number (optional) Exercise 4.3: Can awk display the number of columns? Can awk display the number of column? The answer is: yes! To do so, print the variable NF , as shown in the program below: awk '{ print NF }' Use a pipe to direct the output of ls -l to awk , where the number of columns are printed Answer ls -l | awk '{ print NF }' (optional) Exercise 4.4: Can awk display the last column? Can awk display the last column? The answer is: yes! To do so, print the variable $NF , as shown in the program below: awk '{ print $NF }' Use a pipe to direct the output of ls -l to awk , where the value in the first and last column are printed Answer ls -l | awk '{ print $1,$NF }' (optional) Exercise 4.5: Can awk count the number of lines? Can awk count the number of lines? The answer is: yes! Read the text at chapter 6.3.3: \u2018The number of records\u2019 . Use a pipe to direct the output of ls -l to awk , where the number of lines is printed. Answer A good first guess, but incorrect, is to use the command below, which is good for numbering lines: ls -l | awk '{ print NR }' The last number is indeed the number of lines. The AWK way to solve it, is to use the END clause, which is only run at the end: ls -l | awk 'END { print NR }' NR only becomes useful when used with other awk features, such printing a descriptive text around it: ls -l | awk 'END { print \"Number of lines:\", NR }' There are many ways to print the number of lines, such as to combine the incorrect awk way with tail : ls -l | awk '{ print NR }' | tail -n 1 Clumsy, but it works. Alternatively, wc is made exactly for the purpose of counting lines: ls -l | wc --lines (optional) Exercise 4.7: Can awk work on comma-separated files? Can awk work on comma-separated files? The answer is: yes! Read the text at chapter 6.2.4: \u2018The input field separator\u2019 . Here we convert the output of ls -l to its comma-separated equivalent: ls -l | tr -s ' ' ',' Using this input, use a pipe to show the fifth and ninth column. Answer ls -l | tr -s ' ' ',' | awk 'BEGIN { FS=\",\" } { print $5, $9 }' Alternatively; ls -l | tr -s ' ' ',' | awk --field-separator \",\" '{ print $5, $9 }' (optional) Exercise 4.8: Can awk show something once at the start? Can awk show something once at the start? The answer is: yes! Read the text at chapter 6.2.4: \u2018Special patterns\u2019 . Use a pipe to direct the output of ls -l to awk , where the text Permissions: is shown, after which the values in the first column are shown. If the word total shows up in your results, you can ignore it for this exercise. Answer ls -l | awk 'BEGIN { print \"Permissions:\" } { print $1 }' If you do not want total in your results, use a regular expression for \u2018lines starting with a d or a dash\u2019: ls -l | awk 'BEGIN { print \"Permissions:\" } /^[d\\-]/ { print $1 }' (optional) Exercise 4.9: Can awk show something once at the end? Can awk show something once at the end? The answer is: yes! Read the text at chapter 6.2.4: \u20186.2.4. Special patterns\u2019 . Use a pipe to direct the output of ls -l to awk , after which the values in the first column are shown. At the end of the output, it should show the text Done! If the word total shows up in your results, you can ignore it for this exercise. Answer ls -l | awk '{ print $1 } END { print \"Done!\" }' If you do not want total in your results, use a regular expression for \u2018lines starting with a d or a dash\u2019: ls -l | awk '/^[d\\-]/ { print $1 } END { print \"Done!\" }' (optional) Exercise 4.10: Can awk use variables? Can awk use variables? The answer is: yes! Read the text at chapter 6.3.4: \u2018User defined variables\u2019 . Use a pipe to direct the output of ls -l to awk . Sum the values of the fifth column and show it Answer ls -l | awk 'BEGIN { sum = 0 } { sum = sum + $5 } END { print sum }' For teachers What is the difference between AWK and awk ? Answer AWK is the name of the programming language. awk is the name of the program that can run AWK. What can AWK not do? Answer AWK, like any Turning complete language, can solve any computational problem, but cannot do this: run computations at any speed (i.e. a problem may take billions of year to complete) use any amount of memory (i.e. a problem may require billions of gigabytes to solve) When not to use AWK? Answer AWK shines at problems of intermediate complexity. For simple problems, tools such as grep , cut and wc are just as good. For harder problems, use a modern programming language instead, as these have libraries/packages that can, for example, read or analyse an entire table at once.","title":"(optional) Exercise 4: can awk do &hellip;?"},{"location":"sessions/awk/#conclusions","text":"Conclusions awk can be used pipes: ls -l | awk '{ print $5 $9 }' awk can be used to read a specific column: ls -l | awk '{ print $5 $9 }' awk can be used to transform text: ls -ldh * | grep -v total | awk '{ print \"Size is \" $5 \" bytes for \" $9 }' awk can use regular expressions: df -h | awk '/dev\\/hd/ { print $6 \"\\t: \" $5 }' awk can do a lot more","title":"Conclusions"},{"location":"sessions/awk/#learning__awk","text":"Learning AWK Learning resource Description A practical guide to learning awk Book about AWK Gawk: Effective AWK Programming Book about AWK Bash Beginners Guide Book with a chapter about AWK Advanced Bash Scripting Guide Book with a chapter about AWK To AWK or not Course about AWK, by Pavlin Mitev AWK course Course about AWK, by Rich\u00e8l Bilderbeek","title":"Learning AWK"},{"location":"sessions/regular_expressions_and_grep/","text":"Regular expressions and grep \u00b6 Need a video? Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Feedback Conclusion Learning outcomes Learners know there are multiple flavours of regular expressions Learners can use . , * , + , ? , [] , [^] , {} , () in regular expressions Learners can use grep Learners have practiced using the grep manual Learners can use grep to search for a regular expression Learners can send text to grep using a pipe (optional) Learners have seen the flexibility of grep For teachers Lesson plan: Time Minutes Duration Description 10:20-10:30 0-10 10 Prior 10:30-10:35 10-15 5 Present 10:35-10:55 15-35 20 Challenge 10:55-11:05 35-45 10 Feedback and conclusion Prior: How would tell an alien how a human name is made up out of English characters? And a human phone number? Are there more things that have certain features like that? What is a regular expression? What is grep ? What is GNU? In the context of software, what is a parser? In the context of command-line tools, what is a filter? Why use regular expressions? \u00b6 Regular expressions are used to filter for text that contains a pattern, such as a first name, a last name, a phone number, etc. Why use grep ? \u00b6 The tool grep comes installed with Linux. Exercises \u00b6 Exercise 1: use the grep manual \u00b6 In this exercise, we\u2019ll use the grep manual. Exercise 1.1: view the grep manual \u00b6 View the grep manual. Tip: man is the command to view a manual. Answer In the terminal, type: man grep Use the arrow keys to navigate and q to quit Exercise 1.2: what does grep do? \u00b6 According to the grep manual, in a one-liner , what does grep do? Tip: it is at the top. Answer grep is a tool to \u2018print lines that match patterns\u2019 It is in the fourth line: NAME grep, egrep, fgrep, rgrep - print lines that match patterns Exercise 1.3: what are the other grep s? \u00b6 In the fourth line of the grep manual, the grep -like tools egrep , fgrep and rgrep are mentioned. What are these? Tips: it is in the first two screens. The first part of the answer can be found in the DESCRIPTION section, The second part of the answer can be found in the OPTIONS | Pattern syntax section Answer The first part of the answer is in the description: DESCRIPTION grep searches for PATTERNS in each FILE. [...] [...] Debian also includes the variant programs egrep, fgrep and rgrep. These programs are the same as grep -E, grep -F, and grep -r, respectively. [...] Searching for -E , -F and -r takes us to the \u2018OPTIONS | Pattern Syntax\u2019 subsection: Pattern Syntax -E, --extended-regexp Interpret PATTERNS as extended regular expressions [...]. [...] -G, --basic-regexp Interpret PATTERNS as basic regular expressions [...]. -P, --perl-regexp Interpret PATTERNS as Perl-compatible regular expressions [...]. We can conclude from this that the different grep s have different types of regular expressions, such as a regular, extended and Perl-compatible regular expressions. Exercise 2: use grep with a pipe \u00b6 In this exercise, we use grep with a pipe. Exercise 2.1: read a command that has a grep with a pipe \u00b6 How would you explain the command below in English? Use \u2018some regular expression\u2019 if you see a regular expression. man grep | grep \"^[A-Z]\" Answer The manual of grep , send it to grep and let it filter for some regular expression. Exercise 2.2: run a command that has a grep with a pipe \u00b6 Run the command above. What does it show on screen? What did that regular expression do? Answer This is what is shown on screen: $ man grep | grep \"^[A-Z]\" GREP ( 1 ) User Commands GREP ( 1 ) NAME SYNOPSIS DESCRIPTION OPTIONS REGULAR EXPRESSIONS EXIT STATUS ENVIRONMENT NOTES COPYRIGHT BUGS EXAMPLE SEE ALSO GNU grep 3 .11 2019 -12-29 GREP ( 1 ) It shows all lines that start with an uppercase character. Exercise 3: practice regular expressions \u00b6 Go to https://www.regexone.com/ and do lessons 1 to (and including) 11. Overview of these lessons Here is an overview of the regular expression patterns in each lesson: Lesson Pattern 1 None 1.5 \\d 2 . 3 [] 4 [^] 5 [A-Z] 6 {} 7 * (Kleene star) and + (Kleene plus) 8 ? 9 \\s 10 ^ 11 () (optional) Exercise 4: can grep do \u2026? \u00b6 Here we\u2019ll experience the flexibility of grep . Pick those topics you are interested in. (optional) Exercise 4.1: Can grep do a case-insensitive match? Can grep do a case-insensitive match? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --ignore-case allows you to let grep do a case-insensitive search. For example, in the command below, the word \u2018options\u2019 is searched in the manual in a case-insensitive manner. $ man grep | grep --ignore-case \"options\" OPTIONS use -i, to cancel its effects because the two options override each other. options that prefix their output to the actual content: -H,-n, and -b. In options are given, the last matching one wins. If no --include or --exclude options match, a file is included unless the first such option Other Options other GNU programs. POSIX requires that options that follow file names must be treated as file names ; by default, such options are permuted to the front of the operand list and are treated as options. Also, POSIX requires that unrecognized options be diagnosed as \u201cillegal\u201d, but since treats expansions of \u201c*g*.h\u201d starting with \u201c-\u201d as file names not options, and the (optional) Exercise 4.2: Can grep show the lines that do not match? Can grep show the lines that do not match? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --invert-match allows you to let grep show lines that do not match. For example, in the command below, the grep manual is search for lines that do not have a space. man grep | grep --invert-match \" \" (optional) Exercise 4.3: Can grep detect lines in multiple files? Can grep detect lines in multiple files? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --recursive allows you to let grep search in multiple files. For example, in the commands below, the folder /etc is searched for files that contain the text \u2018ubuntu\u2019: cd /etc grep --recursive \"ubuntu\" (optional) Exercise 4.4: Can grep detect which files contain a match? Can grep detect which files contain a match? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --files-with-matches allows you to let grep output which files contained a match. For example, in the commands below, the folder /etc is searched for files that contain the text \u2018ubuntu\u2019, showing the files in which a match is found: cd /etc grep --recursive --files-with-matches \"ubuntu\" (optional) Exercise 4.5: Can grep detect which files-with-a-certain-extension contain a match? Can grep detect which files-with-a-certain-extension contain a match? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --include allows you to let grep only include files in its For example, in the commands below, the folder /etc is searched in configuration ( .conf ) files that contain the text \u2018ubuntu\u2019. cd /etc grep --recursive \"ubuntu\" --include \"*.conf\" For teachers How many regular expression dialects exist? Answer At least 3: grep (basic) egrep (extended) pgrep (Perl-like) We have sent the grep manual to grep using a pipe. Can we use any text? Answer Yes: the grep manual is just text like any other. Can we send the output of grep to grep ? Answer Yes: the grep output is just text like any other. What is a Kleene star and what does it do? Answer The Kleene star is the regular expression pattern * . In English it would be read as: \u2018the thing before it repeated at least zero times\u2019. What is the difference between [^A-Z] and ^[A-Z] ? Answer The first regular expression means: \u2018All characters, except all uppercase letters\u2019. The second regular expression means: \u2018At the start of a line, any uppercase letter\u2019. What is regular expression for \u2018any line of text\u2019 (including empty ones)? Answer The regular expression for \u2018any line of text\u2019 is .* , as . means \u2018Any character\u2019 and * means \u2018repeated at least zero times\u2019. Why does man grep | grep .* not work, where man grep | grep \".*\" does? Answer The double-quotes assure that the regular expression patter .* is read as such. The \u2018naked\u2019 .* is a bash expression of \u2018all hidden files\u2019, as hidden files start with a . (e.g. ls .* ). This meaning can change depending on context (e.g. cat .* ). Knowing that grep --ignore-case ignores case, and grep --invert-match inverts the match (i.e. showing non-matching lines), how to combine these in the same command? Answer Write these one after the other: grep --ignore-case --invert-match For example, the command below shows all lines in the grep manual that do not have the lower-case, nor upper-case letters \u2018a\u2019 to (and including) \u2018f\u2019. man grep | grep --ignore-case --invert-match \"[a-f]\" Conclusions \u00b6 Conclusions grep is used for pattern matching grep has a useful manual grep is a filter grep works well with pipes There are multiple regular expression dialects The pattern . , [] and [^] are used to (not) match a (set of) characters The pattern * , + , ? and {} are used to indicate an amount The pattern () is used to capture a set of a match (optional) grep can do a lot of different things Next session \u00b6 Next session grep is not a programming language: use awk instead.","title":"Searching using regular expressions and grep"},{"location":"sessions/regular_expressions_and_grep/#regular__expressions__and__grep","text":"Need a video? Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Feedback Conclusion Learning outcomes Learners know there are multiple flavours of regular expressions Learners can use . , * , + , ? , [] , [^] , {} , () in regular expressions Learners can use grep Learners have practiced using the grep manual Learners can use grep to search for a regular expression Learners can send text to grep using a pipe (optional) Learners have seen the flexibility of grep For teachers Lesson plan: Time Minutes Duration Description 10:20-10:30 0-10 10 Prior 10:30-10:35 10-15 5 Present 10:35-10:55 15-35 20 Challenge 10:55-11:05 35-45 10 Feedback and conclusion Prior: How would tell an alien how a human name is made up out of English characters? And a human phone number? Are there more things that have certain features like that? What is a regular expression? What is grep ? What is GNU? In the context of software, what is a parser? In the context of command-line tools, what is a filter?","title":"Regular expressions and grep"},{"location":"sessions/regular_expressions_and_grep/#why__use__regular__expressions","text":"Regular expressions are used to filter for text that contains a pattern, such as a first name, a last name, a phone number, etc.","title":"Why use regular expressions?"},{"location":"sessions/regular_expressions_and_grep/#why__use__grep","text":"The tool grep comes installed with Linux.","title":"Why use grep?"},{"location":"sessions/regular_expressions_and_grep/#exercises","text":"","title":"Exercises"},{"location":"sessions/regular_expressions_and_grep/#exercise__1__use__the__grep__manual","text":"In this exercise, we\u2019ll use the grep manual.","title":"Exercise 1: use the grep manual"},{"location":"sessions/regular_expressions_and_grep/#exercise__11__view__the__grep__manual","text":"View the grep manual. Tip: man is the command to view a manual. Answer In the terminal, type: man grep Use the arrow keys to navigate and q to quit","title":"Exercise 1.1: view the grep manual"},{"location":"sessions/regular_expressions_and_grep/#exercise__12__what__does__grep__do","text":"According to the grep manual, in a one-liner , what does grep do? Tip: it is at the top. Answer grep is a tool to \u2018print lines that match patterns\u2019 It is in the fourth line: NAME grep, egrep, fgrep, rgrep - print lines that match patterns","title":"Exercise 1.2: what does grep do?"},{"location":"sessions/regular_expressions_and_grep/#exercise__13__what__are__the__other__greps","text":"In the fourth line of the grep manual, the grep -like tools egrep , fgrep and rgrep are mentioned. What are these? Tips: it is in the first two screens. The first part of the answer can be found in the DESCRIPTION section, The second part of the answer can be found in the OPTIONS | Pattern syntax section Answer The first part of the answer is in the description: DESCRIPTION grep searches for PATTERNS in each FILE. [...] [...] Debian also includes the variant programs egrep, fgrep and rgrep. These programs are the same as grep -E, grep -F, and grep -r, respectively. [...] Searching for -E , -F and -r takes us to the \u2018OPTIONS | Pattern Syntax\u2019 subsection: Pattern Syntax -E, --extended-regexp Interpret PATTERNS as extended regular expressions [...]. [...] -G, --basic-regexp Interpret PATTERNS as basic regular expressions [...]. -P, --perl-regexp Interpret PATTERNS as Perl-compatible regular expressions [...]. We can conclude from this that the different grep s have different types of regular expressions, such as a regular, extended and Perl-compatible regular expressions.","title":"Exercise 1.3: what are the other greps?"},{"location":"sessions/regular_expressions_and_grep/#exercise__2__use__grep__with__a__pipe","text":"In this exercise, we use grep with a pipe.","title":"Exercise 2: use grep with a pipe"},{"location":"sessions/regular_expressions_and_grep/#exercise__21__read__a__command__that__has__a__grep__with__a__pipe","text":"How would you explain the command below in English? Use \u2018some regular expression\u2019 if you see a regular expression. man grep | grep \"^[A-Z]\" Answer The manual of grep , send it to grep and let it filter for some regular expression.","title":"Exercise 2.1: read a command that has a grep with a pipe"},{"location":"sessions/regular_expressions_and_grep/#exercise__22__run__a__command__that__has__a__grep__with__a__pipe","text":"Run the command above. What does it show on screen? What did that regular expression do? Answer This is what is shown on screen: $ man grep | grep \"^[A-Z]\" GREP ( 1 ) User Commands GREP ( 1 ) NAME SYNOPSIS DESCRIPTION OPTIONS REGULAR EXPRESSIONS EXIT STATUS ENVIRONMENT NOTES COPYRIGHT BUGS EXAMPLE SEE ALSO GNU grep 3 .11 2019 -12-29 GREP ( 1 ) It shows all lines that start with an uppercase character.","title":"Exercise 2.2: run a command that has a grep with a pipe"},{"location":"sessions/regular_expressions_and_grep/#exercise__3__practice__regular__expressions","text":"Go to https://www.regexone.com/ and do lessons 1 to (and including) 11. Overview of these lessons Here is an overview of the regular expression patterns in each lesson: Lesson Pattern 1 None 1.5 \\d 2 . 3 [] 4 [^] 5 [A-Z] 6 {} 7 * (Kleene star) and + (Kleene plus) 8 ? 9 \\s 10 ^ 11 ()","title":"Exercise 3: practice regular expressions"},{"location":"sessions/regular_expressions_and_grep/#optional__exercise__4__can__grep__do","text":"Here we\u2019ll experience the flexibility of grep . Pick those topics you are interested in. (optional) Exercise 4.1: Can grep do a case-insensitive match? Can grep do a case-insensitive match? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --ignore-case allows you to let grep do a case-insensitive search. For example, in the command below, the word \u2018options\u2019 is searched in the manual in a case-insensitive manner. $ man grep | grep --ignore-case \"options\" OPTIONS use -i, to cancel its effects because the two options override each other. options that prefix their output to the actual content: -H,-n, and -b. In options are given, the last matching one wins. If no --include or --exclude options match, a file is included unless the first such option Other Options other GNU programs. POSIX requires that options that follow file names must be treated as file names ; by default, such options are permuted to the front of the operand list and are treated as options. Also, POSIX requires that unrecognized options be diagnosed as \u201cillegal\u201d, but since treats expansions of \u201c*g*.h\u201d starting with \u201c-\u201d as file names not options, and the (optional) Exercise 4.2: Can grep show the lines that do not match? Can grep show the lines that do not match? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --invert-match allows you to let grep show lines that do not match. For example, in the command below, the grep manual is search for lines that do not have a space. man grep | grep --invert-match \" \" (optional) Exercise 4.3: Can grep detect lines in multiple files? Can grep detect lines in multiple files? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --recursive allows you to let grep search in multiple files. For example, in the commands below, the folder /etc is searched for files that contain the text \u2018ubuntu\u2019: cd /etc grep --recursive \"ubuntu\" (optional) Exercise 4.4: Can grep detect which files contain a match? Can grep detect which files contain a match? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --files-with-matches allows you to let grep output which files contained a match. For example, in the commands below, the folder /etc is searched for files that contain the text \u2018ubuntu\u2019, showing the files in which a match is found: cd /etc grep --recursive --files-with-matches \"ubuntu\" (optional) Exercise 4.5: Can grep detect which files-with-a-certain-extension contain a match? Can grep detect which files-with-a-certain-extension contain a match? The answer is: yes! Use the grep manual to answer this question. Answer Yes. The --include allows you to let grep only include files in its For example, in the commands below, the folder /etc is searched in configuration ( .conf ) files that contain the text \u2018ubuntu\u2019. cd /etc grep --recursive \"ubuntu\" --include \"*.conf\" For teachers How many regular expression dialects exist? Answer At least 3: grep (basic) egrep (extended) pgrep (Perl-like) We have sent the grep manual to grep using a pipe. Can we use any text? Answer Yes: the grep manual is just text like any other. Can we send the output of grep to grep ? Answer Yes: the grep output is just text like any other. What is a Kleene star and what does it do? Answer The Kleene star is the regular expression pattern * . In English it would be read as: \u2018the thing before it repeated at least zero times\u2019. What is the difference between [^A-Z] and ^[A-Z] ? Answer The first regular expression means: \u2018All characters, except all uppercase letters\u2019. The second regular expression means: \u2018At the start of a line, any uppercase letter\u2019. What is regular expression for \u2018any line of text\u2019 (including empty ones)? Answer The regular expression for \u2018any line of text\u2019 is .* , as . means \u2018Any character\u2019 and * means \u2018repeated at least zero times\u2019. Why does man grep | grep .* not work, where man grep | grep \".*\" does? Answer The double-quotes assure that the regular expression patter .* is read as such. The \u2018naked\u2019 .* is a bash expression of \u2018all hidden files\u2019, as hidden files start with a . (e.g. ls .* ). This meaning can change depending on context (e.g. cat .* ). Knowing that grep --ignore-case ignores case, and grep --invert-match inverts the match (i.e. showing non-matching lines), how to combine these in the same command? Answer Write these one after the other: grep --ignore-case --invert-match For example, the command below shows all lines in the grep manual that do not have the lower-case, nor upper-case letters \u2018a\u2019 to (and including) \u2018f\u2019. man grep | grep --ignore-case --invert-match \"[a-f]\"","title":"(optional) Exercise 4: can grep do &hellip;?"},{"location":"sessions/regular_expressions_and_grep/#conclusions","text":"Conclusions grep is used for pattern matching grep has a useful manual grep is a filter grep works well with pipes There are multiple regular expression dialects The pattern . , [] and [^] are used to (not) match a (set of) characters The pattern * , + , ? and {} are used to indicate an amount The pattern () is used to capture a set of a match (optional) grep can do a lot of different things","title":"Conclusions"},{"location":"sessions/regular_expressions_and_grep/#next__session","text":"Next session grep is not a programming language: use awk instead.","title":"Next session"},{"location":"sessions/scripting/","text":"Scripting \u00b6 Need a video? Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Exercise 5 Exercise 6 Exercise 7 Exercise 8 Exercise 9 Feedback Conclusion Learning outcomes Learners can write Bash scripts Learners have practiced using a book on Bash scripting Learners can write Bash scripts that require user input Learners can use variables in Bash scripts Learners can use if statements in Bash scripts Learners can use for statements in Bash scripts For teachers Lesson plan: Time Duration Description 0-10 10 Prior 10-15 5 Present 15-50 35 Challenge 50-60 10 Feedback Prior: What is script? What is bash? What is meant with \u2018user input\u2019? What is a variable? What is a condition? What is a conditional? What is a for-loop? Why use scripts? \u00b6 Scripts allow you to run you (bash) commands in an easy and reproducible manner. The different spellings Spelling Description Bash The programming language bash The program Exercises \u00b6 In these exercises, we\u2019ll be using the book \u2018Introduction to Bash scripting for developers\u2019, as this book fits this course well, is free and open source and allows you to continue studying after this course Exercise 1: Bash structure \u00b6 Read the text at chapter 2: \u2018Bash structure\u2019 Create a file called greeter.sh with a shebang following that chapter Answer In a terminal, type: touch greeter.sh Add the following line to the file: #!/bin/bash Remember that if this does not work on your computer, use the more flexible shebang: #!/usr/bin/env bash Exercise 2: Hello world \u00b6 Read the text at chapter 3: \u2018Hello world\u2019 Modify your Bash script called greeter.sh in such a way that you can run (\u2018execute\u2019) it. When it runs, it should show \u2018Hello World!\u2019 on the screen. Run the script to verify Answer Edit greeter.sh to: #!/bin/bash echo \"Hello World!\" For the terminal, make greeter.sh executable with: chmod +x greeter.sh You can now run it with: ./greeter.sh Exercise 3: Bash variables \u00b6 Read the text at chapter 4: \u2018Bash Variables\u2019 Modify your Bash script called greeter.sh in such a way that it uses two variables: greeting , which should have value Hello name , which should have value World When it runs, it should (still) show \u2018Hello World!\u2019 on the screen. Run the script to verify Answer Edit greeter.sh to: #!/bin/bash greeting = \"Hello\" name = \"World\" echo \" $greeting $name !\" You can now (still) run it with: ./greeter.sh Exercise 4: counting files \u00b6 Bash can store the output of other tools in variables. Write a script that counts and shows the number of files in our current folder: Create an executable script called count_files.sh . In the script, create a variable called n_files and initialize it like this: n_files = $( ls | wc --lines ) Running the script should show: \u2018You have [n_files] files\u2019, where [n_files] is the number of files Run the script to verify Answer Edit greeter.sh to: #!/bin/bash n_files = $( ls | wc --lines ) echo \"You have ${ n_files } files\" You can now run it with: ./count_files.sh Exercise 5: user input \u00b6 Read the text at chapter 5: \u2018User input\u2019 Modify your Bash script called greeter.sh in such a way that the script asks for a name using the text \u2018Who to greet?\u2019. If the name World is typed it, it should (again) show \u2018Hello World!\u2019 on the screen. Run the script to verify Answer Edit greeter.sh to: #!/bin/bash echo \"Who to greet?\" read name greeting = \"Hello\" echo \" $greeting $name !\" You can (still) run it with: ./greeter.sh Exercise 6: conditional expressions \u00b6 Read the text at chapter 9: \u2018Conditional expressions\u2019 We will modify your Bash script called greeter.sh in such a way that when the name \u2018Bond\u2019 it chosen, the program shows It is Bond. James Bond! , else it shows the regular greeting. Which conditional will you need? Answer [[ ${ string1 } == ${ string2 } ]] Exercise 7: conditionals \u00b6 Read the chapters \u2018If statement\u2019 and \u2018If Else statement\u2019 of chapter 10: \u2018Conditionals\u2019 , do not read \u2018Switch case statements\u2019 Modify your Bash script called greeter.sh in such a way that when the name \u2018Bond\u2019 it chosen, the program shows It is Bond. James Bond! , else it shows the regular greeting. Run the script to verify Answer Edit greeter.sh to the example below. There are multiple solutions. #!/bin/bash echo \"Who to greet?\" read name greeting = \"Hello\" if [[ \" ${ name } \" == \"Bond\" ]] ; then echo \"It is Bond. James Bond!\" else echo \" $greeting $name !\" fi You can (still) run it with: ./greeter.sh Exercise 8: For loops \u00b6 Read only the \u2018For loops\u2019 section of chapter 11: \u2018Bash loops\u2019 Create a new Bash script called greet_names.sh . The script should: Ask who to greet, with the text Who shall I greet? . The expected input are names separated by spaces, e.g. Anna Berndt Cindy Greet all of these people in the form Hello [name]! , using a for loop to go through the names Run the script to verify Answer Edit greet_names to the example below. There are multiple solutions. #!/bin/bash echo \"Who shall I greet?\" read names for name in ${ names } do echo \"Hello ${ name } !\" done You can run it with: ./greet_names.sh Exercise 9: For loops with Bash commands \u00b6 Instead of iterating over names, we can iterate over something useful instead, such as the output of a Bash command. Create a new Bash script called show_files.sh . The script should: Store the output of ls in a variable called filenames Per filename, show I found a file called [filename]! , where [filename] is the name of the file Run the script to verify Answer Edit greeter.sh to the example below. There are multiple solutions. #!/bin/bash filenames = $( ls ) for filename in ${ filenames } do echo \"I found a file called {filename}!\" done You can run it with: ./show_files.sh Conclusions \u00b6 Conclusions Bash can do most things one expects from a programming language A Bash script starts with a shebang: #!/bin/bash A Bash script can be made executable: chmod +x greeter.sh A Bash script can be run by writing ./ in front of the filename: ./greeter.sh A Bash script can use variables: greeting=\"Hello\" A Bash script can run Bash commands and store the result in a variable: n_files=$(ls | wc --lines) A Bash script can ask the user for input: read name A Bash script can do conditionals: if [[ \" ${ name } \" == \"Bond\" ]] ; then echo \"It is Bond. James Bond!\" else echo \" $greeting $name !\" fi A Bash script can use for-loops: for name in ${ names } do echo \"Hello ${ name } !\" done For teachers What is the difference between AWK and Bash? Answer They are different programming languages. What can Bash not do? Answer Bash, like any Turning complete language, can solve any computational problem, but cannot do this: run computations at any speed (i.e. a problem may take billions of year to complete) use any amount of memory (i.e. a problem may require billions of gigabytes to solve) When not to use Bash? Answer Bash shines at problems of low and intermediate complexity, as it can connect all Bash commands. For harder problems, use a modern programming language instead. Next session \u00b6 Next session Bash can do much more","title":"Scripting"},{"location":"sessions/scripting/#scripting","text":"Need a video? Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Exercise 5 Exercise 6 Exercise 7 Exercise 8 Exercise 9 Feedback Conclusion Learning outcomes Learners can write Bash scripts Learners have practiced using a book on Bash scripting Learners can write Bash scripts that require user input Learners can use variables in Bash scripts Learners can use if statements in Bash scripts Learners can use for statements in Bash scripts For teachers Lesson plan: Time Duration Description 0-10 10 Prior 10-15 5 Present 15-50 35 Challenge 50-60 10 Feedback Prior: What is script? What is bash? What is meant with \u2018user input\u2019? What is a variable? What is a condition? What is a conditional? What is a for-loop?","title":"Scripting"},{"location":"sessions/scripting/#why__use__scripts","text":"Scripts allow you to run you (bash) commands in an easy and reproducible manner. The different spellings Spelling Description Bash The programming language bash The program","title":"Why use scripts?"},{"location":"sessions/scripting/#exercises","text":"In these exercises, we\u2019ll be using the book \u2018Introduction to Bash scripting for developers\u2019, as this book fits this course well, is free and open source and allows you to continue studying after this course","title":"Exercises"},{"location":"sessions/scripting/#exercise__1__bash__structure","text":"Read the text at chapter 2: \u2018Bash structure\u2019 Create a file called greeter.sh with a shebang following that chapter Answer In a terminal, type: touch greeter.sh Add the following line to the file: #!/bin/bash Remember that if this does not work on your computer, use the more flexible shebang: #!/usr/bin/env bash","title":"Exercise 1: Bash structure"},{"location":"sessions/scripting/#exercise__2__hello__world","text":"Read the text at chapter 3: \u2018Hello world\u2019 Modify your Bash script called greeter.sh in such a way that you can run (\u2018execute\u2019) it. When it runs, it should show \u2018Hello World!\u2019 on the screen. Run the script to verify Answer Edit greeter.sh to: #!/bin/bash echo \"Hello World!\" For the terminal, make greeter.sh executable with: chmod +x greeter.sh You can now run it with: ./greeter.sh","title":"Exercise 2: Hello world"},{"location":"sessions/scripting/#exercise__3__bash__variables","text":"Read the text at chapter 4: \u2018Bash Variables\u2019 Modify your Bash script called greeter.sh in such a way that it uses two variables: greeting , which should have value Hello name , which should have value World When it runs, it should (still) show \u2018Hello World!\u2019 on the screen. Run the script to verify Answer Edit greeter.sh to: #!/bin/bash greeting = \"Hello\" name = \"World\" echo \" $greeting $name !\" You can now (still) run it with: ./greeter.sh","title":"Exercise 3: Bash variables"},{"location":"sessions/scripting/#exercise__4__counting__files","text":"Bash can store the output of other tools in variables. Write a script that counts and shows the number of files in our current folder: Create an executable script called count_files.sh . In the script, create a variable called n_files and initialize it like this: n_files = $( ls | wc --lines ) Running the script should show: \u2018You have [n_files] files\u2019, where [n_files] is the number of files Run the script to verify Answer Edit greeter.sh to: #!/bin/bash n_files = $( ls | wc --lines ) echo \"You have ${ n_files } files\" You can now run it with: ./count_files.sh","title":"Exercise 4: counting files"},{"location":"sessions/scripting/#exercise__5__user__input","text":"Read the text at chapter 5: \u2018User input\u2019 Modify your Bash script called greeter.sh in such a way that the script asks for a name using the text \u2018Who to greet?\u2019. If the name World is typed it, it should (again) show \u2018Hello World!\u2019 on the screen. Run the script to verify Answer Edit greeter.sh to: #!/bin/bash echo \"Who to greet?\" read name greeting = \"Hello\" echo \" $greeting $name !\" You can (still) run it with: ./greeter.sh","title":"Exercise 5: user input"},{"location":"sessions/scripting/#exercise__6__conditional__expressions","text":"Read the text at chapter 9: \u2018Conditional expressions\u2019 We will modify your Bash script called greeter.sh in such a way that when the name \u2018Bond\u2019 it chosen, the program shows It is Bond. James Bond! , else it shows the regular greeting. Which conditional will you need? Answer [[ ${ string1 } == ${ string2 } ]]","title":"Exercise 6: conditional expressions"},{"location":"sessions/scripting/#exercise__7__conditionals","text":"Read the chapters \u2018If statement\u2019 and \u2018If Else statement\u2019 of chapter 10: \u2018Conditionals\u2019 , do not read \u2018Switch case statements\u2019 Modify your Bash script called greeter.sh in such a way that when the name \u2018Bond\u2019 it chosen, the program shows It is Bond. James Bond! , else it shows the regular greeting. Run the script to verify Answer Edit greeter.sh to the example below. There are multiple solutions. #!/bin/bash echo \"Who to greet?\" read name greeting = \"Hello\" if [[ \" ${ name } \" == \"Bond\" ]] ; then echo \"It is Bond. James Bond!\" else echo \" $greeting $name !\" fi You can (still) run it with: ./greeter.sh","title":"Exercise 7: conditionals"},{"location":"sessions/scripting/#exercise__8__for__loops","text":"Read only the \u2018For loops\u2019 section of chapter 11: \u2018Bash loops\u2019 Create a new Bash script called greet_names.sh . The script should: Ask who to greet, with the text Who shall I greet? . The expected input are names separated by spaces, e.g. Anna Berndt Cindy Greet all of these people in the form Hello [name]! , using a for loop to go through the names Run the script to verify Answer Edit greet_names to the example below. There are multiple solutions. #!/bin/bash echo \"Who shall I greet?\" read names for name in ${ names } do echo \"Hello ${ name } !\" done You can run it with: ./greet_names.sh","title":"Exercise 8: For loops"},{"location":"sessions/scripting/#exercise__9__for__loops__with__bash__commands","text":"Instead of iterating over names, we can iterate over something useful instead, such as the output of a Bash command. Create a new Bash script called show_files.sh . The script should: Store the output of ls in a variable called filenames Per filename, show I found a file called [filename]! , where [filename] is the name of the file Run the script to verify Answer Edit greeter.sh to the example below. There are multiple solutions. #!/bin/bash filenames = $( ls ) for filename in ${ filenames } do echo \"I found a file called {filename}!\" done You can run it with: ./show_files.sh","title":"Exercise 9: For loops with Bash commands"},{"location":"sessions/scripting/#conclusions","text":"Conclusions Bash can do most things one expects from a programming language A Bash script starts with a shebang: #!/bin/bash A Bash script can be made executable: chmod +x greeter.sh A Bash script can be run by writing ./ in front of the filename: ./greeter.sh A Bash script can use variables: greeting=\"Hello\" A Bash script can run Bash commands and store the result in a variable: n_files=$(ls | wc --lines) A Bash script can ask the user for input: read name A Bash script can do conditionals: if [[ \" ${ name } \" == \"Bond\" ]] ; then echo \"It is Bond. James Bond!\" else echo \" $greeting $name !\" fi A Bash script can use for-loops: for name in ${ names } do echo \"Hello ${ name } !\" done For teachers What is the difference between AWK and Bash? Answer They are different programming languages. What can Bash not do? Answer Bash, like any Turning complete language, can solve any computational problem, but cannot do this: run computations at any speed (i.e. a problem may take billions of year to complete) use any amount of memory (i.e. a problem may require billions of gigabytes to solve) When not to use Bash? Answer Bash shines at problems of low and intermediate complexity, as it can connect all Bash commands. For harder problems, use a modern programming language instead.","title":"Conclusions"},{"location":"sessions/scripting/#next__session","text":"Next session Bash can do much more","title":"Next session"}]}